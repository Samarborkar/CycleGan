{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VIGyIus8Vr7"
   },
   "source": [
    "Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRm-USlsHgEV"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt3igws3eiVp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/iiita/Desktop/face_recognition/CycleGan_samar/pytorch-CycleGAN-and-pix2pix/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1EySlOXwwoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.4.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: dominate>=2.4.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (2.9.1)\n",
      "Requirement already satisfied: visdom>=0.1.8.8 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (0.2.4)\n",
      "Requirement already satisfied: wandb in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (0.19.6)\n",
      "Requirement already satisfied: filelock in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (11.1.0)\n",
      "Requirement already satisfied: scipy in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.1)\n",
      "Requirement already satisfied: requests in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: tornado in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.4.2)\n",
      "Requirement already satisfied: six in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: jsonpatch in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.33)\n",
      "Requirement already satisfied: websocket-client in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from wandb->-r requirements.txt (line 5)) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from wandb->-r requirements.txt (line 5)) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from wandb->-r requirements.txt (line 5)) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from wandb->-r requirements.txt (line 5)) (5.29.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from wandb->-r requirements.txt (line 5)) (6.1.1)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from wandb->-r requirements.txt (line 5)) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from wandb->-r requirements.txt (line 5)) (6.0.2)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from wandb->-r requirements.txt (line 5)) (2.20.0)\n",
      "Requirement already satisfied: setproctitle in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from wandb->-r requirements.txt (line 5)) (1.3.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should print True if GPU is available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "Download one of the official datasets with:\n",
    "\n",
    "-   `bash ./datasets/download_cyclegan_dataset.sh [apple2orange, summer2winter_yosemite, horse2zebra, monet2photo, cezanne2photo, ukiyoe2photo, vangogh2photo, maps, cityscapes, facades, iphone2dslr_flower, ae_photos]`\n",
    "\n",
    "Or use your own dataset by creating the appropriate folders and adding in the images.\n",
    "\n",
    "-   Create a dataset folder under `/dataset` for your dataset.\n",
    "-   Create subfolders `testA`, `testB`, `trainA`, and `trainB` under your dataset's folder. Place any images you want to transform from a to b (cat2dog) in the `testA` folder, images you want to transform from b to a (dog2cat) in the `testB` folder, and do the same for the `trainA` and `trainB` folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrdOettJxaCc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified [horse2zebra]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2025-02-05 23:29:50--  http://efrosgans.eecs.berkeley.edu/cyclegan/datasets/horse2zebra.zip\n",
      "Connecting to 172.31.2.4:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 116867962 (111M) [application/zip]\n",
      "Saving to: ‘./datasets/horse2zebra.zip’\n",
      "\n",
      "./datasets/horse2ze 100%[===================>] 111.45M   765KB/s    in 2m 59s  \n",
      "\n",
      "2025-02-05 23:32:50 (637 KB/s) - ‘./datasets/horse2zebra.zip’ saved [116867962/116867962]\n",
      "\n",
      "Archive:  ./datasets/horse2zebra.zip\n",
      "   creating: ./datasets/horse2zebra/trainA/\n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6223.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1567.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3354.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_299.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3001.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4242.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1666.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4396.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4502.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8527.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_14.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_706.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4019.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1478.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3449.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5558.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_969.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1494.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1435.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5927.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_979.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4621.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2412.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4474.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5803.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_276.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1432.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3353.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5538.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2198.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4347.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6944.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4373.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2751.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6089.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2755.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4276.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_322.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3221.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_855.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4141.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_807.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1019.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1319.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2341.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9064.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1939.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1208.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_993.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_863.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1586.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4425.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1226.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3438.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_948.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_736.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1197.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4429.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3754.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1482.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6402.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5805.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2462.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_357.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2476.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1862.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5983.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5944.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2985.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3897.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1105.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8759.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_732.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4729.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3548.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3369.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7515.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1658.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1075.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1501.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8903.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_674.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4687.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4566.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_255.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_908.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1204.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_236.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7689.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_155.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2048.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3601.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1675.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1888.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8325.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4413.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_186.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8735.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9083.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1489.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1874.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3085.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4763.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3483.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7512.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2223.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_668.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_596.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9234.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3393.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6289.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_986.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8668.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2446.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1001.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1624.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3412.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1122.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3175.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4374.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8639.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_528.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_11.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3984.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1135.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3902.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_199.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2967.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_677.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2043.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1337.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1769.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2325.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2032.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_27.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7261.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_852.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5287.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2103.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8944.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7122.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1562.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1365.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_856.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6549.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7495.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_108.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3066.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5442.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1796.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_643.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1487.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1025.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5618.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2578.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8306.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_105.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4748.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4944.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1952.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5721.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_919.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2779.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1422.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7905.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_998.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6743.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2929.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_697.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7876.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_122.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3315.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3946.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1813.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1941.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_242.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_381.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6441.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4701.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4629.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5525.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2014.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3299.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1006.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2061.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7695.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1009.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2793.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1347.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2027.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_591.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6964.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8769.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2449.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4467.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1227.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3424.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_249.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_274.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1288.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1506.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_718.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2649.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5292.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4648.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3365.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4613.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5699.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1901.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1058.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3664.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2758.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3081.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5266.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_903.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3417.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_869.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6204.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_518.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8725.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4645.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3115.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1751.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8241.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3619.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2425.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5241.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9127.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5869.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2484.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3192.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4372.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6294.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7456.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1439.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_754.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4219.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4403.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4118.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4465.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_69.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4674.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_175.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6397.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_386.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4491.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5036.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_503.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8895.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1023.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8157.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4453.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1262.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2402.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2179.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1034.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4417.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_911.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6556.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1038.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_782.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1276.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3447.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6981.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_525.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_331.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1979.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3512.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5087.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1402.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2268.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1387.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2016.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1405.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2465.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_476.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1246.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1003.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1484.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2741.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_671.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1155.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_811.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_739.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2089.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_422.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2706.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1048.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8714.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1132.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5502.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5607.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6873.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9052.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1216.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1665.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_616.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3712.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9243.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2177.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4472.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4991.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1267.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3212.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1519.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2795.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1803.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_222.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3358.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3113.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2627.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5696.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4473.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3018.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6476.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_238.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_627.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3283.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_543.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1027.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4771.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3982.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6792.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4817.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4294.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2339.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6466.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2093.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1651.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5704.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7412.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2936.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4917.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2349.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3694.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_36.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4779.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3942.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1856.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_61.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1614.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6782.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3707.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_541.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_728.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4642.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4018.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9063.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2245.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2563.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7932.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_454.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4551.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2643.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1084.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3911.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1596.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_396.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5406.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8974.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1297.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4059.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4788.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8838.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2374.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7537.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4856.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5029.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4081.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3075.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_411.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4008.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1579.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4815.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_203.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3509.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_631.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_196.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7597.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1713.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2109.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2317.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2753.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4515.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3783.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1578.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1978.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2684.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1458.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_967.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2139.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2019.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_558.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3905.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1581.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2327.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1687.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6987.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2023.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2822.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5708.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3854.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2953.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1521.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5864.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1373.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7919.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_477.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8006.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1045.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3107.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1852.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_125.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4493.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_235.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1507.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2419.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_891.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_521.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5526.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1721.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4999.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1758.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_66.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2517.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1232.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2474.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2259.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2565.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4079.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_391.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3363.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2192.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8437.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1426.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2468.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_968.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4523.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5857.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3661.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5214.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4711.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4513.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4928.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7231.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4927.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5203.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8985.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5411.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2552.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4231.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6152.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2995.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8048.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1191.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2714.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1044.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4665.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4783.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_703.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_278.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2596.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7476.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7297.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4516.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5891.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7571.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6403.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1305.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1991.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1798.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_595.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2083.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_921.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2555.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_858.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4625.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8277.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3366.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2695.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3265.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4053.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_804.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4107.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1995.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3336.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2403.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_424.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4726.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_489.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2605.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1331.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4112.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7803.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2921.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_584.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4402.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3557.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4946.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2615.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_117.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3685.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_854.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6388.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2883.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1583.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_803.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1973.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1525.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5045.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4608.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1703.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1266.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3746.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_971.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4125.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7493.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4538.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8088.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6978.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2217.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1736.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_394.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_757.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7348.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_935.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1711.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_881.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4371.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4593.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4153.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4536.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4785.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4401.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3065.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4528.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_933.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3346.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5355.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4965.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6975.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8013.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3383.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2796.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3546.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_437.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4239.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4009.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_755.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5265.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4476.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5729.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8435.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4117.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1249.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1063.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1916.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8179.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1144.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6876.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6277.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2632.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_788.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3329.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_223.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2799.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2528.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4624.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2499.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1526.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1307.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7942.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5489.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1865.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1648.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1592.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2282.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_135.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4251.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2149.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1258.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1872.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1486.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1612.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1108.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7845.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2305.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3394.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4585.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3924.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1904.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7548.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3149.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5551.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4638.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5892.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1621.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3228.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3551.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4637.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6268.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7126.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1734.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_825.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6721.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1068.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1391.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4086.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7806.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4967.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2226.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3398.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2811.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3811.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_306.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4501.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_177.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1127.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7528.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1835.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3702.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2598.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4661.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2575.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8877.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_767.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1537.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4385.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2581.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7858.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3875.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1635.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1292.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1743.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1388.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7651.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_153.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_897.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_506.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4494.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2433.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_707.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4094.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6946.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_565.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3995.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_384.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2525.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_624.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1915.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5167.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4263.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4305.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3656.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7756.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1847.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_743.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1602.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2754.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3829.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1423.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2294.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_195.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4146.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_182.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2289.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4731.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2594.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6411.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6836.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4168.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_358.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4606.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3051.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8507.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3211.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_902.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3997.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4338.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_323.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8389.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1283.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8575.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1348.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1106.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1645.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3566.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7779.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1384.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_393.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1981.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2269.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_879.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6822.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1498.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3732.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_419.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7622.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7178.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8586.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6761.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_588.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1909.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1957.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2056.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1074.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1418.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_451.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7692.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6297.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_764.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1722.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6335.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3229.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1834.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2703.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3861.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_314.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3108.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3563.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2411.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2366.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5537.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1763.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1959.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1389.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1134.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8104.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4804.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1509.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2421.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3371.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2141.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1696.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1014.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1338.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3182.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1727.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3556.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1052.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8659.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_834.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1336.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1524.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8704.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7613.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1008.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5782.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8765.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_559.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5674.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_941.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5156.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7165.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3956.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3348.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_421.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4482.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4497.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2276.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4395.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2261.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1683.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3286.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2783.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_285.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9095.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8515.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7959.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2116.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9263.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_776.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2488.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3989.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_777.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2872.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5519.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3577.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1533.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5396.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2414.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5915.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6373.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2635.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_598.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1637.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1855.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2275.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4397.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_676.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4542.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2834.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2509.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1905.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4521.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2835.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1083.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4809.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1158.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2091.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_461.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3965.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4055.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3659.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4151.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7634.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1002.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3091.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4446.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2685.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1184.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3928.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5819.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8862.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1101.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2548.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3611.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6258.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3469.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2045.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4668.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1028.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_102.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1816.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_567.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3838.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_654.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4456.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_474.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1921.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1011.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1159.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6995.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_545.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2503.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_398.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1493.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2968.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_395.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4407.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4916.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5374.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_178.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_742.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4657.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_311.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4743.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5386.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4412.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4751.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_452.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_211.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3526.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9184.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1182.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_128.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1674.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4572.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2699.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3309.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4415.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5878.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_901.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4169.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4123.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1557.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2878.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5075.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4103.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5601.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4632.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1098.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7888.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6252.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_58.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8153.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_24.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4598.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4597.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7398.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3935.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1708.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3466.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_747.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4833.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1247.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1563.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6941.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_594.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_601.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1147.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_726.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2444.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3857.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1801.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8626.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3638.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1354.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_849.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3442.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4781.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1051.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4136.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8989.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9223.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3903.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4331.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4975.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1774.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_691.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3842.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2708.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4159.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4195.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6511.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2788.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4483.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1427.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_202.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_553.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5135.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2306.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2806.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4096.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1992.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4228.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1672.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7754.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4602.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7305.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4361.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_976.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5761.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_981.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3588.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7219.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1573.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4639.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2181.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2879.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4571.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_466.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5951.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2848.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2152.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4181.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1766.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5545.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4737.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4766.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5917.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7903.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2572.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_328.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1082.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_939.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2612.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_519.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1425.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4543.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_912.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_582.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1682.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2012.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1361.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5107.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1686.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3355.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6824.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4541.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_769.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2085.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8708.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_509.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8718.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5771.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4816.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1639.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2514.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_836.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5804.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_86.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3028.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8449.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4376.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1793.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3395.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2736.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1053.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3803.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_552.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_798.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1035.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3255.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6922.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8611.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5739.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6267.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1334.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8812.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_73.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1168.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4447.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_778.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4324.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1037.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4348.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1523.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1531.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5408.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2496.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4695.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8479.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3222.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4307.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5034.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4434.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8577.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1804.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1937.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2951.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1761.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1212.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4977.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2539.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8958.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3605.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_629.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_765.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1263.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3226.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1194.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_91.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_5286.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4769.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4312.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2222.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2049.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8052.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4663.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1349.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4529.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_8585.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2726.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_9167.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2732.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2802.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6688.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_501.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2371.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_835.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_675.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3827.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4758.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_1363.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3064.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2564.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_4084.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_376.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_717.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_784.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_2225.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_7033.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_6763.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_3658.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainA/n02381460_19.jpg  \n",
      "   creating: ./datasets/horse2zebra/testB/\n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3130.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_4110.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_640.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_260.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_7060.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2200.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2500.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1270.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_5220.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3220.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_120.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_4610.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_9460.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_10980.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1760.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2470.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2800.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3070.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_980.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2190.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1290.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_10590.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1150.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_9350.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_10910.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1220.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1430.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_6650.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2510.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_790.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_490.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_100.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1300.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_10210.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2600.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1950.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_900.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_270.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2420.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1340.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_890.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2620.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_600.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_4490.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_9900.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_9400.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_6860.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_440.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2970.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2220.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1020.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2380.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3800.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_6180.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3060.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_7740.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1880.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_4570.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2810.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_6890.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_5930.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_10100.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3770.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_410.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1100.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_4730.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_6190.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_390.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_6520.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3840.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_480.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_8340.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_750.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1000.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1630.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_430.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_6780.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_400.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_5670.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3290.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_8000.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_80.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1790.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_690.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_10810.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2290.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2350.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3240.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3310.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2570.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_4990.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_9960.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3320.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3450.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_7190.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_7150.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_6690.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2100.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_8020.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_8830.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2730.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_920.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_8140.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3750.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_7860.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_180.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_1060.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_170.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_4890.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_10160.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_10630.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_5100.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_5240.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_200.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3090.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_9160.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2930.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2890.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2410.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_8080.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_5720.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_5320.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_9740.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3010.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_560.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_9000.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3200.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2990.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_5810.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2480.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_3270.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2460.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_5030.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_9680.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_5990.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_130.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2790.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2760.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_860.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testB/n02391049_2870.jpg  \n",
      "   creating: ./datasets/horse2zebra/trainB/\n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_155.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_165.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3211.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_295.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4692.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8178.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8032.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2709.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2418.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2985.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2612.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2049.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1087.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2476.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2285.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9149.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2232.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7722.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_737.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5509.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_589.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2211.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8061.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5875.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1042.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2446.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2157.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_141.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6184.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_344.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2989.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2005.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2116.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_354.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2999.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_465.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2789.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1104.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7407.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2424.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_415.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10467.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2776.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5366.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8447.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4697.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2628.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1869.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1158.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_11162.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_11195.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3239.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2698.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9675.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2048.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9804.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_544.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2984.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6121.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_744.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_839.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2017.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4569.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3402.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1758.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2289.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_817.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_527.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_56.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6122.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7886.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2541.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2559.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3135.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2816.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5781.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10589.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5982.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_176.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_116.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6511.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10278.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6336.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2131.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7263.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9977.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_351.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9357.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6993.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2921.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5551.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4028.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_254.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_77.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2886.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3092.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3733.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2739.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6524.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_934.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_835.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4775.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6026.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_826.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4077.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_886.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2061.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8764.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1149.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7972.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2889.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3328.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2043.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_554.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4058.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9416.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3654.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2383.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3261.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2907.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_169.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1928.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6902.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_808.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10132.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2511.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2459.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_717.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3071.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4185.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10824.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10497.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6081.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3242.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_437.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2657.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_168.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8856.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_279.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_225.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2821.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7836.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2366.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_71.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_368.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2304.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_341.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_115.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10701.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3778.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_444.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7261.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9136.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_46.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2648.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2644.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_275.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2673.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1752.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_644.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6012.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3199.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1894.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4969.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3229.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1738.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_246.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3872.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6198.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8444.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1679.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7832.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_795.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2239.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_178.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1751.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5695.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8387.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9051.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9593.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_11181.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_173.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7494.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5503.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_248.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9719.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1531.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3022.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8699.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3779.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2806.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4898.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_363.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3173.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3681.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_904.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9398.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_232.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2201.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3947.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7839.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4259.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_226.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1891.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2534.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6834.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_643.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8565.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2182.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2837.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9918.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2718.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6326.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10429.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2508.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_383.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6267.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8347.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6374.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10649.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1532.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2856.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_147.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1126.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7398.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8568.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1076.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6202.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7062.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_308.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6436.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4805.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10681.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10738.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_17.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_935.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2927.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3517.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2364.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_764.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2665.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3084.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8425.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_983.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1731.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1451.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1073.jpg  \n",
      " extracting: ./datasets/horse2zebra/trainB/n02391049_7503.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_712.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9822.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10948.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7567.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1178.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5638.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3397.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8857.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2204.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3296.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10917.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2606.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2916.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4745.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8659.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2995.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1172.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3228.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2275.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_316.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_499.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1296.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7396.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6452.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_11166.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6421.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_907.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2701.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3292.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10825.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2844.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1088.jpg  \n",
      " extracting: ./datasets/horse2zebra/trainB/n02391049_2361.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_192.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1316.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3073.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8214.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2187.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7169.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_19.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1056.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3436.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_574.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_639.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_133.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2596.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3016.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2732.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_538.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1153.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3693.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1147.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1156.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_734.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_956.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9113.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_384.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_695.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5209.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5115.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8859.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3115.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1121.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_635.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3518.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2638.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2162.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_459.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2251.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_343.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2899.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2181.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8793.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9542.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3023.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2786.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_23.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9273.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_274.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_824.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10134.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2847.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3248.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_789.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_125.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3785.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2321.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_964.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1836.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5791.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2982.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6762.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3233.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_474.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1024.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10461.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_557.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4027.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3038.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3755.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7151.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2811.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1523.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1112.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4496.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6015.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10257.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3209.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2603.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10307.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1025.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_228.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4165.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8373.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3631.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3257.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_865.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9193.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1303.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1465.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2098.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10739.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3901.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3303.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8657.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2504.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_419.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3636.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9151.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2506.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7599.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1189.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6163.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2222.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_427.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9964.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6467.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9635.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5217.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8015.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_193.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2591.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3028.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2507.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5344.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3046.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2295.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2355.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4824.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_377.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10432.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1164.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1288.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2523.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10159.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2924.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2242.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3001.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_428.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3465.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_182.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5165.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3754.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5307.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3342.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6475.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5547.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2293.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6947.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9006.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2645.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3154.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1459.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_217.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_33.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10324.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6866.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8844.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_954.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2265.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10269.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3236.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_424.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2623.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5595.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2768.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3235.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7487.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3128.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9698.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4517.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8951.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3348.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_515.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_566.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_37.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6465.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2407.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4176.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_26.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4474.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2273.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3861.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_642.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_98.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9336.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_986.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_148.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7105.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3075.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6396.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2996.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6444.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9919.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_142.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_471.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_711.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_936.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3105.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2723.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_543.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5501.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7188.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2133.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2852.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7911.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10576.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2481.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8028.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3153.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2946.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_608.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3938.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1818.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_251.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_556.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10175.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10342.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1743.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_514.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8075.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8209.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2024.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2627.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7668.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2549.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3165.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6565.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_11.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1817.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4952.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1054.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3174.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_154.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1509.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2465.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_79.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4974.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8878.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4914.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2416.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2687.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2696.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3044.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_329.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2451.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4748.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_743.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8539.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2485.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5291.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9494.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3289.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2155.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10596.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3148.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1046.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_43.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_32.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1095.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3958.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5371.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6655.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7096.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3202.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_487.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8291.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6503.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2218.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10165.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3306.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8526.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5679.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1973.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6804.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2819.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2731.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5788.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4161.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_927.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_35.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1236.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7115.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_796.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2748.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_283.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2036.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3114.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2228.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6818.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1053.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6074.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4329.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6023.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_628.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7368.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_267.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1295.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7589.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5273.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1652.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2805.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_949.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3371.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4863.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3844.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10591.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3339.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2166.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_332.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_915.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6293.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7648.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4644.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1118.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2136.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2057.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3905.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2104.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1946.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_533.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5909.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2034.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6053.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3276.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_909.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6951.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2177.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10158.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6386.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_614.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5189.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2495.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6918.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10398.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1124.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_272.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7418.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_261.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_745.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2656.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_119.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_757.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9421.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2571.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9922.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8201.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10636.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6208.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1908.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_721.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2486.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_638.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2967.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1135.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_164.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3293.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9487.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9443.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7563.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2214.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_234.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4932.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1436.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4351.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1434.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8782.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_851.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_475.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1551.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2926.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3139.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3949.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_944.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1113.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2963.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6469.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3415.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3264.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_345.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_468.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3041.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3034.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9377.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1127.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2836.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1223.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1028.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2146.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3446.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10244.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10027.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1159.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3536.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3291.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5383.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2163.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1012.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_596.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_966.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2466.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3271.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7048.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6631.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1256.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4576.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_633.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1555.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_752.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_929.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_976.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8008.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2229.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_425.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_74.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1725.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9135.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6245.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_496.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_718.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10427.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10339.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5908.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1937.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10209.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9911.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5924.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3937.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10295.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2782.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_925.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2794.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2895.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1004.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_834.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1026.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7466.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7318.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2784.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_333.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5121.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6236.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2457.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_733.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3098.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1479.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1721.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2997.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4704.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5131.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_286.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_58.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_686.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_11128.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1163.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_738.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6413.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8148.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_704.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_276.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9519.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1524.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7319.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4638.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_897.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3085.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2141.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9497.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2478.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6683.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_39.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8301.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_171.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1038.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1417.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9532.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5637.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4677.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2464.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2785.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7851.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7581.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2883.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2781.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3079.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_146.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9062.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_121.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10966.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_314.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6957.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_659.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3365.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6564.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9365.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_788.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5208.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2637.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5985.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2671.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2922.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1992.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2714.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_36.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9441.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3087.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7324.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1188.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_497.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9844.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2111.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4873.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_541.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2818.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_626.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3428.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6922.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_463.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2853.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2825.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7584.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_167.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_152.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4889.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2651.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9427.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3072.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10007.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2341.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3917.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6546.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6582.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4448.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2674.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1309.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2379.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2636.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4747.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9309.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7038.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9656.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_921.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2584.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_932.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_353.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9965.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2758.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1267.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3031.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2659.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2857.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_707.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7512.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_985.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_536.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4682.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_306.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2681.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2333.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_328.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7018.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1852.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_924.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6385.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3426.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7927.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6471.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9478.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2741.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2363.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10322.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2957.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_101.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_87.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1211.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1105.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2663.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_776.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4292.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7645.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3578.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2408.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2258.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1464.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7919.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3081.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3221.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_627.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9747.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1535.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_978.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2824.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6216.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4693.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6159.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_787.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2524.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_11041.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6097.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2579.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_578.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4069.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10047.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2356.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1099.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2941.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4525.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9705.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_841.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1875.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8192.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_999.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2184.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1441.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4901.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4896.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1442.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_45.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6487.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3238.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9499.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2191.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2448.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4034.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5853.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10597.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9524.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7071.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2871.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3749.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10356.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2831.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_993.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_285.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9137.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_719.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2798.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2367.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_629.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_773.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4475.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8488.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2639.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3509.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1314.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2281.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2183.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6962.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2838.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7566.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3253.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2633.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2973.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5295.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6227.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8334.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1174.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3266.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3868.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5633.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4903.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3091.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2879.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7457.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_63.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9979.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_407.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5169.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2593.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2003.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3251.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3333.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6622.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3771.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2964.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8982.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8021.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4965.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3326.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9528.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2877.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1404.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5527.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9864.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1191.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2906.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1064.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1148.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2901.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2231.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1526.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_873.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2597.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1086.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2684.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_725.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8616.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_685.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5782.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_403.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_601.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1846.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6664.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_715.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_483.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2959.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9533.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5789.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6629.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3513.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10063.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8689.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2829.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7683.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_22.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_109.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_406.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_602.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2911.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2691.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3086.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4189.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1199.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10435.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2386.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_786.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8994.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4879.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4734.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2372.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8593.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7258.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_268.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_699.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2905.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10131.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2788.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1063.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6935.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2091.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2875.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9055.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7979.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5618.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2766.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8394.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4839.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6735.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2477.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_85.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2616.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1145.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_857.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3294.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_916.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3324.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_396.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9629.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9626.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5586.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7409.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_108.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1952.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1181.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7416.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1789.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9726.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2803.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1131.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3267.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2817.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_404.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_421.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7236.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8288.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1567.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6517.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7721.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_984.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2747.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2749.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3053.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8831.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_392.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3096.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7306.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2588.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_611.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2935.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2014.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_918.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1184.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_957.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2585.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2888.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3026.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5276.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_161.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10336.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2165.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_501.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3069.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6775.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2405.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1827.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10123.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7847.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2876.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3177.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1195.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10682.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1129.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_675.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3162.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2469.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2631.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2609.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5714.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1742.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10749.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2018.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1855.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_621.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2221.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2702.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7378.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5755.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2437.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2752.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_166.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2337.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_163.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9583.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7557.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_676.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_943.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1097.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10129.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_41.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10754.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1355.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6317.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3319.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3805.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9625.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_587.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2518.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9951.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9317.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_713.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2322.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_127.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6856.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1378.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_605.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3317.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2693.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1419.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8855.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1125.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_25.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_913.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9058.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3187.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_551.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_18.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2771.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_809.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2491.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7364.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4261.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_221.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1884.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3137.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5661.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6919.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2297.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4814.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4445.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3314.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3232.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10122.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_847.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4584.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10239.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3088.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1495.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3158.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_969.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_461.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8158.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9303.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9016.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3149.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2286.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9331.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3262.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9417.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5947.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1844.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6378.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5889.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10837.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10454.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3443.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2733.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3249.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7812.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2756.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4144.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6186.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_249.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8633.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_102.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2375.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8059.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9762.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10504.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_926.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_992.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3043.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6609.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_682.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_224.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2197.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2974.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4413.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_362.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_335.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3623.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2897.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3191.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2266.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1235.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5216.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_358.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5724.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7344.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9219.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7949.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3582.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2642.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_646.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1712.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_866.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2439.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_107.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7848.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3122.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2746.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8182.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2647.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_12.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3054.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8902.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2848.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2381.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6359.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2223.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6561.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8266.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2767.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9387.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7074.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3246.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4528.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6757.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6987.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_11153.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7077.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_565.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_603.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4729.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2951.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3682.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3018.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10613.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_775.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_11063.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_671.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2729.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9002.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4922.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4909.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_122.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2949.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2743.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2704.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_395.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_357.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2842.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2757.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_15.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9555.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1175.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_812.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8321.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5711.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10452.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1183.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9987.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3878.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9777.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4564.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7779.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8149.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5093.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_879.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2311.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_379.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2567.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_111.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_356.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5356.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5367.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1067.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2586.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3219.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5236.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_10426.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1516.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_584.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2814.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8102.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3037.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6512.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3265.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_968.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5333.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1062.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2306.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7678.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2826.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5015.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7434.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2225.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_506.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_5005.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_1198.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9122.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7205.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_875.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_118.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6991.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_202.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3024.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9556.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2117.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8445.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8696.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9027.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9258.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_7521.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_8937.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4218.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_9665.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2294.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_6942.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2813.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_4106.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3247.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_2217.jpg  \n",
      "  inflating: ./datasets/horse2zebra/trainB/n02391049_3119.jpg  \n",
      "   creating: ./datasets/horse2zebra/testA/\n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1110.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1740.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1300.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1260.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4410.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4260.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1690.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_9240.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_670.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4430.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4110.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_6920.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_20.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4010.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2950.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_3120.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2050.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2150.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_5090.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1750.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_6300.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7190.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_3660.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_5500.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1100.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2540.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_6640.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2890.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4630.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7140.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7250.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2120.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4160.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_900.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1350.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2870.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_360.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_8900.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_500.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_440.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1540.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7300.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_3240.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4640.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7170.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_9260.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1000.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_140.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4470.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7620.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1210.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7660.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4370.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1830.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_5940.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_3910.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4450.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2940.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2100.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_6950.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4530.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1360.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_510.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2710.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4550.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2580.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4650.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_3330.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_470.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1870.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_490.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_3040.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2460.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_640.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4800.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2650.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4740.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_950.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_180.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_6790.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1010.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1920.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4790.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_2280.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_530.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_40.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_8980.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1630.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_6290.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_3110.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_50.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1620.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1160.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1090.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_600.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1120.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_690.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7890.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7700.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7400.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_200.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_6690.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_3010.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7230.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1030.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_910.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_5670.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4420.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_800.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4660.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1420.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_840.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4120.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_120.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1820.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_1660.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4310.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7500.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_4240.jpg  \n",
      "  inflating: ./datasets/horse2zebra/testA/n02381460_7970.jpg  \n"
     ]
    }
   ],
   "source": [
    "!bash ./datasets/download_cyclegan_dataset.sh horse2zebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdUz4116xhpm"
   },
   "source": [
    "# Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_cyclegan_model.sh [apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B75UqtKhxznS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: available models are apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower\n",
      "Specified [horse2zebra]\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2025-02-06 02:14:36--  http://efrosgans.eecs.berkeley.edu/cyclegan/pretrained_models/horse2zebra.pth\n",
      "Connecting to 172.31.2.4:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 45575747 (43M)\n",
      "Saving to: ‘./checkpoints/horse2zebra_pretrained/latest_net_G.pth’\n",
      "\n",
      "./checkpoints/horse 100%[===================>]  43.46M  53.3MB/s    in 0.8s    \n",
      "\n",
      "2025-02-06 02:14:39 (53.3 MB/s) - ‘./checkpoints/horse2zebra_pretrained/latest_net_G.pth’ saved [45575747/45575747]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/download_cyclegan_model.sh horse2zebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/horse2zebra --name horse2zebra --model cycle_gan`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. I've found that a batch size of 16 fits onto 4 V100s and can finish training an epoch in ~90s.\n",
    "\n",
    "Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:\n",
    "\n",
    "Use `cp ./checkpoints/horse2zebra/latest_net_G_A.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class A to class B and `cp ./checkpoints/horse2zebra/latest_net_G_B.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class B to class A.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 8                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/students           \t[default: None]\n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: -1                            \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 1                             \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 10.0                          \n",
      "          lambda_identity: 0.5                           \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: students_cycle_gan            \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [UnalignedDataset] was created\n",
      "The number of training images = 1160\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G_A] Total number of parameters : 11.378 M\n",
      "[Network G_B] Total number of parameters : 11.378 M\n",
      "[Network D_A] Total number of parameters : 2.765 M\n",
      "[Network D_B] Total number of parameters : 2.765 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints/students_cycle_gan/web...\n",
      "/home/iiita/miniconda3/envs/cycleGAN/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 200, time: 0.063, data: 0.090) D_A: 0.404 G_A: 0.341 cycle_A: 2.266 idt_A: 0.650 D_B: 0.373 G_B: 0.345 cycle_B: 1.313 idt_B: 1.050 \n",
      "(epoch: 1, iters: 400, time: 0.073, data: 0.002) D_A: 0.333 G_A: 0.348 cycle_A: 2.122 idt_A: 0.554 D_B: 0.846 G_B: 1.024 cycle_B: 1.217 idt_B: 0.805 \n",
      "(epoch: 1, iters: 600, time: 0.062, data: 0.002) D_A: 0.280 G_A: 0.333 cycle_A: 1.915 idt_A: 0.563 D_B: 0.265 G_B: 0.421 cycle_B: 1.275 idt_B: 0.887 \n",
      "(epoch: 1, iters: 800, time: 0.063, data: 0.002) D_A: 0.255 G_A: 0.314 cycle_A: 1.474 idt_A: 0.460 D_B: 0.573 G_B: 0.711 cycle_B: 1.010 idt_B: 0.640 \n",
      "(epoch: 1, iters: 1000, time: 0.063, data: 0.003) D_A: 0.505 G_A: 0.622 cycle_A: 2.394 idt_A: 0.542 D_B: 0.236 G_B: 0.344 cycle_B: 1.157 idt_B: 0.990 \n",
      "End of epoch 1 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 40, time: 0.074, data: 0.002) D_A: 0.189 G_A: 0.377 cycle_A: 1.195 idt_A: 0.530 D_B: 0.426 G_B: 0.664 cycle_B: 1.210 idt_B: 0.634 \n",
      "(epoch: 2, iters: 240, time: 0.063, data: 0.001) D_A: 0.412 G_A: 0.509 cycle_A: 1.540 idt_A: 0.512 D_B: 0.252 G_B: 0.443 cycle_B: 1.161 idt_B: 0.655 \n",
      "(epoch: 2, iters: 440, time: 0.063, data: 0.001) D_A: 0.235 G_A: 0.318 cycle_A: 2.152 idt_A: 0.669 D_B: 0.297 G_B: 0.375 cycle_B: 1.408 idt_B: 0.814 \n",
      "(epoch: 2, iters: 640, time: 0.063, data: 0.002) D_A: 0.253 G_A: 0.388 cycle_A: 1.663 idt_A: 0.548 D_B: 0.250 G_B: 0.366 cycle_B: 1.156 idt_B: 0.619 \n",
      "(epoch: 2, iters: 840, time: 0.074, data: 0.001) D_A: 0.199 G_A: 0.339 cycle_A: 0.941 idt_A: 0.489 D_B: 0.278 G_B: 0.427 cycle_B: 1.036 idt_B: 0.481 \n",
      "(epoch: 2, iters: 1040, time: 0.062, data: 0.002) D_A: 0.226 G_A: 0.332 cycle_A: 1.017 idt_A: 0.498 D_B: 0.213 G_B: 0.374 cycle_B: 1.039 idt_B: 0.616 \n",
      "End of epoch 2 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 80, time: 0.075, data: 0.001) D_A: 0.217 G_A: 0.321 cycle_A: 1.676 idt_A: 0.416 D_B: 0.227 G_B: 0.346 cycle_B: 0.884 idt_B: 0.544 \n",
      "(epoch: 3, iters: 280, time: 0.062, data: 0.001) D_A: 0.239 G_A: 0.443 cycle_A: 1.454 idt_A: 0.498 D_B: 0.236 G_B: 0.353 cycle_B: 1.039 idt_B: 0.677 \n",
      "(epoch: 3, iters: 480, time: 0.063, data: 0.001) D_A: 0.246 G_A: 0.298 cycle_A: 2.217 idt_A: 0.610 D_B: 0.216 G_B: 0.396 cycle_B: 1.383 idt_B: 0.517 \n",
      "(epoch: 3, iters: 680, time: 0.063, data: 0.001) D_A: 0.467 G_A: 0.636 cycle_A: 1.869 idt_A: 0.412 D_B: 0.214 G_B: 0.433 cycle_B: 0.984 idt_B: 0.560 \n",
      "(epoch: 3, iters: 880, time: 0.063, data: 0.002) D_A: 0.223 G_A: 0.352 cycle_A: 0.917 idt_A: 0.462 D_B: 0.272 G_B: 0.410 cycle_B: 0.920 idt_B: 0.428 \n",
      "(epoch: 3, iters: 1080, time: 0.062, data: 0.001) D_A: 0.226 G_A: 0.473 cycle_A: 1.523 idt_A: 0.386 D_B: 0.201 G_B: 0.397 cycle_B: 0.886 idt_B: 0.551 \n",
      "End of epoch 3 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 120, time: 0.075, data: 0.002) D_A: 0.266 G_A: 0.610 cycle_A: 1.272 idt_A: 0.440 D_B: 0.323 G_B: 0.424 cycle_B: 0.984 idt_B: 0.601 \n",
      "(epoch: 4, iters: 320, time: 0.063, data: 0.001) D_A: 0.226 G_A: 0.272 cycle_A: 1.091 idt_A: 0.472 D_B: 0.232 G_B: 0.380 cycle_B: 0.978 idt_B: 0.570 \n",
      "(epoch: 4, iters: 520, time: 0.075, data: 0.001) D_A: 0.258 G_A: 0.334 cycle_A: 1.653 idt_A: 0.459 D_B: 0.210 G_B: 0.371 cycle_B: 0.958 idt_B: 0.596 \n",
      "(epoch: 4, iters: 720, time: 0.063, data: 0.001) D_A: 0.180 G_A: 0.562 cycle_A: 1.176 idt_A: 0.456 D_B: 0.176 G_B: 0.351 cycle_B: 1.044 idt_B: 0.486 \n",
      "(epoch: 4, iters: 920, time: 0.063, data: 0.002) D_A: 0.210 G_A: 0.279 cycle_A: 1.176 idt_A: 0.520 D_B: 0.273 G_B: 0.504 cycle_B: 0.952 idt_B: 0.575 \n",
      "(epoch: 4, iters: 1120, time: 0.063, data: 0.002) D_A: 0.250 G_A: 0.317 cycle_A: 1.223 idt_A: 0.432 D_B: 0.297 G_B: 0.293 cycle_B: 1.088 idt_B: 0.486 \n",
      "End of epoch 4 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 160, time: 0.076, data: 0.001) D_A: 0.205 G_A: 0.391 cycle_A: 1.027 idt_A: 0.515 D_B: 0.239 G_B: 0.407 cycle_B: 0.964 idt_B: 0.506 \n",
      "(epoch: 5, iters: 360, time: 0.063, data: 0.001) D_A: 0.218 G_A: 0.380 cycle_A: 0.979 idt_A: 0.386 D_B: 0.178 G_B: 0.466 cycle_B: 0.749 idt_B: 0.429 \n",
      "saving the latest model (epoch 5, total_iters 5000)\n",
      "(epoch: 5, iters: 560, time: 0.063, data: 0.001) D_A: 0.239 G_A: 0.466 cycle_A: 1.385 idt_A: 0.378 D_B: 0.147 G_B: 0.446 cycle_B: 0.806 idt_B: 0.618 \n",
      "(epoch: 5, iters: 760, time: 0.063, data: 0.002) D_A: 0.240 G_A: 0.452 cycle_A: 1.150 idt_A: 0.416 D_B: 0.219 G_B: 0.413 cycle_B: 0.960 idt_B: 0.467 \n",
      "(epoch: 5, iters: 960, time: 0.063, data: 0.002) D_A: 0.397 G_A: 0.431 cycle_A: 1.179 idt_A: 0.472 D_B: 0.233 G_B: 0.393 cycle_B: 0.930 idt_B: 0.642 \n",
      "(epoch: 5, iters: 1160, time: 0.063, data: 0.002) D_A: 0.176 G_A: 0.343 cycle_A: 1.517 idt_A: 0.387 D_B: 0.280 G_B: 0.328 cycle_B: 1.368 idt_B: 0.684 \n",
      "saving the model at the end of epoch 5, iters 5800\n",
      "End of epoch 5 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 200, time: 0.076, data: 0.142) D_A: 0.189 G_A: 0.500 cycle_A: 1.217 idt_A: 0.411 D_B: 0.239 G_B: 0.479 cycle_B: 0.889 idt_B: 0.503 \n",
      "(epoch: 6, iters: 400, time: 0.063, data: 0.001) D_A: 0.219 G_A: 0.349 cycle_A: 1.398 idt_A: 0.397 D_B: 0.263 G_B: 0.371 cycle_B: 0.844 idt_B: 0.589 \n",
      "(epoch: 6, iters: 600, time: 0.063, data: 0.002) D_A: 0.243 G_A: 0.436 cycle_A: 0.797 idt_A: 0.403 D_B: 0.206 G_B: 0.354 cycle_B: 0.795 idt_B: 0.371 \n",
      "(epoch: 6, iters: 800, time: 0.063, data: 0.001) D_A: 0.192 G_A: 0.319 cycle_A: 1.062 idt_A: 0.482 D_B: 0.308 G_B: 0.545 cycle_B: 0.964 idt_B: 0.541 \n",
      "(epoch: 6, iters: 1000, time: 0.063, data: 0.002) D_A: 0.242 G_A: 0.475 cycle_A: 1.085 idt_A: 0.440 D_B: 0.244 G_B: 0.452 cycle_B: 0.946 idt_B: 0.509 \n",
      "End of epoch 6 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 40, time: 0.063, data: 0.001) D_A: 0.231 G_A: 0.426 cycle_A: 1.093 idt_A: 0.413 D_B: 0.222 G_B: 0.409 cycle_B: 0.911 idt_B: 0.457 \n",
      "(epoch: 7, iters: 240, time: 0.076, data: 0.002) D_A: 0.205 G_A: 0.376 cycle_A: 1.067 idt_A: 0.529 D_B: 0.226 G_B: 0.591 cycle_B: 1.062 idt_B: 0.320 \n",
      "(epoch: 7, iters: 440, time: 0.063, data: 0.001) D_A: 0.156 G_A: 0.569 cycle_A: 0.965 idt_A: 0.464 D_B: 0.170 G_B: 0.411 cycle_B: 0.956 idt_B: 0.379 \n",
      "(epoch: 7, iters: 640, time: 0.063, data: 0.002) D_A: 0.202 G_A: 0.408 cycle_A: 1.119 idt_A: 0.347 D_B: 0.283 G_B: 0.616 cycle_B: 0.774 idt_B: 0.471 \n",
      "(epoch: 7, iters: 840, time: 0.062, data: 0.002) D_A: 0.189 G_A: 0.324 cycle_A: 1.030 idt_A: 0.449 D_B: 0.229 G_B: 0.430 cycle_B: 1.158 idt_B: 0.564 \n",
      "(epoch: 7, iters: 1040, time: 0.077, data: 0.001) D_A: 0.222 G_A: 0.387 cycle_A: 0.943 idt_A: 0.373 D_B: 0.207 G_B: 0.354 cycle_B: 0.819 idt_B: 0.514 \n",
      "End of epoch 7 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 80, time: 0.063, data: 0.001) D_A: 0.184 G_A: 0.349 cycle_A: 0.919 idt_A: 0.405 D_B: 0.179 G_B: 0.449 cycle_B: 0.794 idt_B: 0.397 \n",
      "(epoch: 8, iters: 280, time: 0.077, data: 0.001) D_A: 0.180 G_A: 0.439 cycle_A: 2.216 idt_A: 0.387 D_B: 0.245 G_B: 0.230 cycle_B: 0.870 idt_B: 0.989 \n",
      "(epoch: 8, iters: 480, time: 0.063, data: 0.002) D_A: 0.200 G_A: 0.256 cycle_A: 1.492 idt_A: 0.520 D_B: 0.206 G_B: 0.347 cycle_B: 1.301 idt_B: 0.514 \n",
      "(epoch: 8, iters: 680, time: 0.063, data: 0.002) D_A: 0.150 G_A: 0.459 cycle_A: 0.985 idt_A: 0.340 D_B: 0.227 G_B: 0.441 cycle_B: 0.767 idt_B: 0.464 \n",
      "(epoch: 8, iters: 880, time: 0.063, data: 0.002) D_A: 0.137 G_A: 0.503 cycle_A: 0.865 idt_A: 0.406 D_B: 0.203 G_B: 0.356 cycle_B: 0.839 idt_B: 0.394 \n",
      "(epoch: 8, iters: 1080, time: 0.063, data: 0.002) D_A: 0.222 G_A: 0.296 cycle_A: 1.001 idt_A: 0.465 D_B: 0.226 G_B: 0.477 cycle_B: 0.912 idt_B: 0.372 \n",
      "End of epoch 8 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 120, time: 0.063, data: 0.001) D_A: 0.221 G_A: 0.359 cycle_A: 0.824 idt_A: 0.392 D_B: 0.253 G_B: 0.301 cycle_B: 0.788 idt_B: 0.445 \n",
      "(epoch: 9, iters: 320, time: 0.078, data: 0.001) D_A: 0.137 G_A: 0.439 cycle_A: 1.325 idt_A: 0.524 D_B: 0.236 G_B: 0.419 cycle_B: 1.055 idt_B: 0.571 \n",
      "(epoch: 9, iters: 520, time: 0.063, data: 0.001) D_A: 0.089 G_A: 0.620 cycle_A: 2.044 idt_A: 0.527 D_B: 0.149 G_B: 0.448 cycle_B: 1.121 idt_B: 0.844 \n",
      "(epoch: 9, iters: 720, time: 0.077, data: 0.002) D_A: 0.182 G_A: 0.725 cycle_A: 0.698 idt_A: 0.413 D_B: 0.242 G_B: 0.324 cycle_B: 0.817 idt_B: 0.321 \n",
      "saving the latest model (epoch 9, total_iters 10000)\n",
      "(epoch: 9, iters: 920, time: 0.063, data: 0.001) D_A: 0.270 G_A: 0.551 cycle_A: 1.871 idt_A: 0.480 D_B: 0.225 G_B: 0.289 cycle_B: 1.114 idt_B: 0.437 \n",
      "(epoch: 9, iters: 1120, time: 0.063, data: 0.002) D_A: 0.215 G_A: 0.397 cycle_A: 1.526 idt_A: 0.488 D_B: 0.212 G_B: 0.310 cycle_B: 0.968 idt_B: 0.437 \n",
      "End of epoch 9 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 160, time: 0.063, data: 0.002) D_A: 0.154 G_A: 0.313 cycle_A: 0.776 idt_A: 0.352 D_B: 0.215 G_B: 0.437 cycle_B: 0.724 idt_B: 0.293 \n",
      "(epoch: 10, iters: 360, time: 0.078, data: 0.002) D_A: 0.230 G_A: 0.411 cycle_A: 1.115 idt_A: 0.356 D_B: 0.228 G_B: 0.288 cycle_B: 0.713 idt_B: 0.458 \n",
      "(epoch: 10, iters: 560, time: 0.063, data: 0.001) D_A: 0.174 G_A: 0.410 cycle_A: 0.709 idt_A: 0.448 D_B: 0.230 G_B: 0.251 cycle_B: 1.058 idt_B: 0.312 \n",
      "(epoch: 10, iters: 760, time: 0.063, data: 0.002) D_A: 0.218 G_A: 0.538 cycle_A: 0.900 idt_A: 0.450 D_B: 0.237 G_B: 0.504 cycle_B: 0.914 idt_B: 0.442 \n",
      "(epoch: 10, iters: 960, time: 0.063, data: 0.002) D_A: 0.262 G_A: 0.378 cycle_A: 0.827 idt_A: 0.491 D_B: 0.242 G_B: 0.381 cycle_B: 0.935 idt_B: 0.343 \n",
      "(epoch: 10, iters: 1160, time: 0.063, data: 0.002) D_A: 0.165 G_A: 0.340 cycle_A: 0.839 idt_A: 0.375 D_B: 0.209 G_B: 0.403 cycle_B: 0.857 idt_B: 0.305 \n",
      "saving the model at the end of epoch 10, iters 11600\n",
      "End of epoch 10 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 200, time: 0.063, data: 0.080) D_A: 0.187 G_A: 0.403 cycle_A: 0.981 idt_A: 0.381 D_B: 0.225 G_B: 0.448 cycle_B: 0.830 idt_B: 0.374 \n",
      "(epoch: 11, iters: 400, time: 0.079, data: 0.002) D_A: 0.232 G_A: 0.672 cycle_A: 0.834 idt_A: 0.639 D_B: 0.198 G_B: 0.327 cycle_B: 1.230 idt_B: 0.383 \n",
      "(epoch: 11, iters: 600, time: 0.063, data: 0.001) D_A: 0.406 G_A: 0.890 cycle_A: 0.731 idt_A: 0.360 D_B: 0.208 G_B: 0.361 cycle_B: 0.732 idt_B: 0.387 \n",
      "(epoch: 11, iters: 800, time: 0.063, data: 0.002) D_A: 0.147 G_A: 0.541 cycle_A: 0.850 idt_A: 0.359 D_B: 0.240 G_B: 0.372 cycle_B: 0.690 idt_B: 0.352 \n",
      "(epoch: 11, iters: 1000, time: 0.063, data: 0.001) D_A: 0.371 G_A: 0.181 cycle_A: 0.817 idt_A: 0.403 D_B: 0.252 G_B: 0.456 cycle_B: 0.888 idt_B: 0.392 \n",
      "End of epoch 11 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 40, time: 0.080, data: 0.001) D_A: 0.413 G_A: 0.525 cycle_A: 0.823 idt_A: 0.325 D_B: 0.239 G_B: 0.507 cycle_B: 0.694 idt_B: 0.329 \n",
      "(epoch: 12, iters: 240, time: 0.063, data: 0.001) D_A: 0.202 G_A: 0.303 cycle_A: 1.323 idt_A: 0.405 D_B: 0.225 G_B: 0.371 cycle_B: 0.836 idt_B: 0.412 \n",
      "(epoch: 12, iters: 440, time: 0.063, data: 0.001) D_A: 0.176 G_A: 0.464 cycle_A: 0.740 idt_A: 0.364 D_B: 0.282 G_B: 0.567 cycle_B: 0.719 idt_B: 0.327 \n",
      "(epoch: 12, iters: 640, time: 0.063, data: 0.002) D_A: 0.182 G_A: 0.641 cycle_A: 1.082 idt_A: 0.317 D_B: 0.221 G_B: 0.400 cycle_B: 0.690 idt_B: 0.441 \n",
      "(epoch: 12, iters: 840, time: 0.063, data: 0.002) D_A: 0.256 G_A: 0.718 cycle_A: 0.832 idt_A: 0.422 D_B: 0.194 G_B: 0.343 cycle_B: 0.805 idt_B: 0.394 \n",
      "(epoch: 12, iters: 1040, time: 0.063, data: 0.002) D_A: 0.167 G_A: 0.324 cycle_A: 0.907 idt_A: 0.395 D_B: 0.216 G_B: 0.280 cycle_B: 0.825 idt_B: 0.312 \n",
      "End of epoch 12 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 80, time: 0.081, data: 0.001) D_A: 0.154 G_A: 0.351 cycle_A: 0.894 idt_A: 0.452 D_B: 0.307 G_B: 0.337 cycle_B: 1.031 idt_B: 0.371 \n",
      "(epoch: 13, iters: 280, time: 0.063, data: 0.001) D_A: 0.218 G_A: 0.281 cycle_A: 1.091 idt_A: 0.353 D_B: 0.205 G_B: 0.345 cycle_B: 0.751 idt_B: 0.464 \n",
      "(epoch: 13, iters: 480, time: 0.063, data: 0.002) D_A: 0.188 G_A: 0.463 cycle_A: 0.796 idt_A: 0.328 D_B: 0.185 G_B: 0.298 cycle_B: 0.690 idt_B: 0.313 \n",
      "(epoch: 13, iters: 680, time: 0.063, data: 0.001) D_A: 0.219 G_A: 0.428 cycle_A: 1.158 idt_A: 0.444 D_B: 0.182 G_B: 0.402 cycle_B: 0.979 idt_B: 0.429 \n",
      "(epoch: 13, iters: 880, time: 0.063, data: 0.001) D_A: 0.267 G_A: 0.170 cycle_A: 1.199 idt_A: 0.354 D_B: 0.301 G_B: 0.370 cycle_B: 0.838 idt_B: 0.436 \n",
      "(epoch: 13, iters: 1080, time: 0.063, data: 0.001) D_A: 0.430 G_A: 0.530 cycle_A: 1.965 idt_A: 0.495 D_B: 0.251 G_B: 0.620 cycle_B: 1.162 idt_B: 0.708 \n",
      "saving the latest model (epoch 13, total_iters 15000)\n",
      "End of epoch 13 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 120, time: 0.081, data: 0.002) D_A: 0.171 G_A: 0.264 cycle_A: 0.833 idt_A: 0.342 D_B: 0.179 G_B: 0.520 cycle_B: 0.701 idt_B: 0.314 \n",
      "(epoch: 14, iters: 320, time: 0.063, data: 0.002) D_A: 0.209 G_A: 0.264 cycle_A: 0.973 idt_A: 0.326 D_B: 0.254 G_B: 0.315 cycle_B: 0.718 idt_B: 0.410 \n",
      "(epoch: 14, iters: 520, time: 0.063, data: 0.002) D_A: 0.200 G_A: 0.659 cycle_A: 1.005 idt_A: 0.362 D_B: 0.177 G_B: 0.426 cycle_B: 0.772 idt_B: 0.414 \n",
      "(epoch: 14, iters: 720, time: 0.063, data: 0.002) D_A: 0.146 G_A: 0.493 cycle_A: 0.741 idt_A: 0.371 D_B: 0.199 G_B: 0.456 cycle_B: 0.869 idt_B: 0.343 \n",
      "(epoch: 14, iters: 920, time: 0.080, data: 0.002) D_A: 0.227 G_A: 0.420 cycle_A: 0.722 idt_A: 0.296 D_B: 0.215 G_B: 0.365 cycle_B: 0.662 idt_B: 0.358 \n",
      "(epoch: 14, iters: 1120, time: 0.063, data: 0.001) D_A: 0.158 G_A: 0.402 cycle_A: 0.910 idt_A: 0.368 D_B: 0.239 G_B: 0.319 cycle_B: 0.772 idt_B: 0.361 \n",
      "End of epoch 14 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 15, iters: 160, time: 0.079, data: 0.002) D_A: 0.275 G_A: 0.545 cycle_A: 0.993 idt_A: 0.285 D_B: 0.160 G_B: 0.281 cycle_B: 0.619 idt_B: 0.389 \n",
      "(epoch: 15, iters: 360, time: 0.063, data: 0.001) D_A: 0.188 G_A: 0.431 cycle_A: 1.286 idt_A: 0.415 D_B: 0.149 G_B: 0.407 cycle_B: 0.962 idt_B: 0.462 \n",
      "(epoch: 15, iters: 560, time: 0.063, data: 0.002) D_A: 0.363 G_A: 0.293 cycle_A: 0.662 idt_A: 0.396 D_B: 0.239 G_B: 0.315 cycle_B: 1.027 idt_B: 0.298 \n",
      "(epoch: 15, iters: 760, time: 0.063, data: 0.002) D_A: 0.237 G_A: 0.250 cycle_A: 0.945 idt_A: 0.321 D_B: 0.193 G_B: 0.510 cycle_B: 0.793 idt_B: 0.398 \n",
      "(epoch: 15, iters: 960, time: 0.063, data: 0.002) D_A: 0.249 G_A: 0.309 cycle_A: 0.973 idt_A: 0.405 D_B: 0.163 G_B: 0.397 cycle_B: 0.965 idt_B: 0.446 \n",
      "(epoch: 15, iters: 1160, time: 0.063, data: 0.002) D_A: 0.273 G_A: 0.286 cycle_A: 0.749 idt_A: 0.350 D_B: 0.191 G_B: 0.462 cycle_B: 0.785 idt_B: 0.351 \n",
      "saving the model at the end of epoch 15, iters 17400\n",
      "End of epoch 15 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 16, iters: 200, time: 0.084, data: 0.115) D_A: 0.239 G_A: 0.242 cycle_A: 0.623 idt_A: 0.285 D_B: 0.146 G_B: 0.500 cycle_B: 0.644 idt_B: 0.236 \n",
      "(epoch: 16, iters: 400, time: 0.063, data: 0.002) D_A: 0.256 G_A: 0.265 cycle_A: 0.626 idt_A: 0.276 D_B: 0.180 G_B: 0.738 cycle_B: 0.667 idt_B: 0.295 \n",
      "(epoch: 16, iters: 600, time: 0.083, data: 0.002) D_A: 0.241 G_A: 0.293 cycle_A: 0.841 idt_A: 0.333 D_B: 0.254 G_B: 0.356 cycle_B: 0.647 idt_B: 0.398 \n",
      "(epoch: 16, iters: 800, time: 0.063, data: 0.001) D_A: 0.254 G_A: 0.280 cycle_A: 0.677 idt_A: 0.303 D_B: 0.179 G_B: 0.360 cycle_B: 0.628 idt_B: 0.311 \n",
      "(epoch: 16, iters: 1000, time: 0.063, data: 0.002) D_A: 0.250 G_A: 0.255 cycle_A: 0.716 idt_A: 0.254 D_B: 0.258 G_B: 0.442 cycle_B: 0.595 idt_B: 0.294 \n",
      "End of epoch 16 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 17, iters: 40, time: 0.063, data: 0.002) D_A: 0.253 G_A: 0.274 cycle_A: 0.589 idt_A: 0.277 D_B: 0.294 G_B: 0.691 cycle_B: 0.666 idt_B: 0.262 \n",
      "(epoch: 17, iters: 240, time: 0.084, data: 0.002) D_A: 0.271 G_A: 0.285 cycle_A: 0.522 idt_A: 0.291 D_B: 0.180 G_B: 0.416 cycle_B: 0.708 idt_B: 0.269 \n",
      "(epoch: 17, iters: 440, time: 0.062, data: 0.001) D_A: 0.263 G_A: 0.255 cycle_A: 0.801 idt_A: 0.243 D_B: 0.280 G_B: 0.323 cycle_B: 0.613 idt_B: 0.412 \n",
      "(epoch: 17, iters: 640, time: 0.063, data: 0.002) D_A: 0.224 G_A: 0.260 cycle_A: 0.756 idt_A: 0.385 D_B: 0.194 G_B: 0.363 cycle_B: 0.818 idt_B: 0.322 \n",
      "(epoch: 17, iters: 840, time: 0.063, data: 0.001) D_A: 0.242 G_A: 0.277 cycle_A: 0.877 idt_A: 0.366 D_B: 0.277 G_B: 0.841 cycle_B: 0.816 idt_B: 0.355 \n",
      "(epoch: 17, iters: 1040, time: 0.063, data: 0.002) D_A: 0.310 G_A: 0.310 cycle_A: 0.872 idt_A: 0.229 D_B: 0.198 G_B: 0.485 cycle_B: 0.609 idt_B: 0.453 \n",
      "End of epoch 17 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 18, iters: 80, time: 0.063, data: 0.002) D_A: 0.235 G_A: 0.273 cycle_A: 0.672 idt_A: 0.337 D_B: 0.163 G_B: 0.430 cycle_B: 0.731 idt_B: 0.354 \n",
      "(epoch: 18, iters: 280, time: 0.085, data: 0.001) D_A: 0.238 G_A: 0.257 cycle_A: 0.624 idt_A: 0.409 D_B: 0.163 G_B: 0.506 cycle_B: 0.899 idt_B: 0.295 \n",
      "saving the latest model (epoch 18, total_iters 20000)\n",
      "(epoch: 18, iters: 480, time: 0.063, data: 0.001) D_A: 0.243 G_A: 0.269 cycle_A: 1.017 idt_A: 0.280 D_B: 0.184 G_B: 0.397 cycle_B: 0.688 idt_B: 0.411 \n",
      "(epoch: 18, iters: 680, time: 0.063, data: 0.002) D_A: 0.240 G_A: 0.252 cycle_A: 0.655 idt_A: 0.460 D_B: 0.242 G_B: 0.331 cycle_B: 0.935 idt_B: 0.331 \n",
      "(epoch: 18, iters: 880, time: 0.063, data: 0.001) D_A: 0.247 G_A: 0.319 cycle_A: 0.639 idt_A: 0.235 D_B: 0.219 G_B: 0.250 cycle_B: 0.573 idt_B: 0.322 \n",
      "(epoch: 18, iters: 1080, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.268 cycle_A: 0.840 idt_A: 0.312 D_B: 0.268 G_B: 0.281 cycle_B: 0.694 idt_B: 0.436 \n",
      "End of epoch 18 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 19, iters: 120, time: 0.063, data: 0.001) D_A: 0.258 G_A: 0.357 cycle_A: 0.624 idt_A: 0.276 D_B: 0.187 G_B: 0.206 cycle_B: 0.814 idt_B: 0.277 \n",
      "(epoch: 19, iters: 320, time: 0.086, data: 0.002) D_A: 0.253 G_A: 0.367 cycle_A: 0.634 idt_A: 0.330 D_B: 0.206 G_B: 0.550 cycle_B: 0.774 idt_B: 0.262 \n",
      "(epoch: 19, iters: 520, time: 0.063, data: 0.001) D_A: 0.254 G_A: 0.219 cycle_A: 0.680 idt_A: 0.395 D_B: 0.192 G_B: 0.399 cycle_B: 0.915 idt_B: 0.316 \n",
      "(epoch: 19, iters: 720, time: 0.063, data: 0.002) D_A: 0.320 G_A: 0.314 cycle_A: 0.636 idt_A: 0.408 D_B: 0.376 G_B: 0.194 cycle_B: 0.922 idt_B: 0.306 \n",
      "(epoch: 19, iters: 920, time: 0.063, data: 0.002) D_A: 0.233 G_A: 0.270 cycle_A: 0.573 idt_A: 0.328 D_B: 0.202 G_B: 0.399 cycle_B: 0.673 idt_B: 0.281 \n",
      "(epoch: 19, iters: 1120, time: 0.084, data: 0.002) D_A: 0.222 G_A: 0.282 cycle_A: 0.618 idt_A: 0.308 D_B: 0.157 G_B: 0.417 cycle_B: 0.689 idt_B: 0.315 \n",
      "End of epoch 19 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 20, iters: 160, time: 0.063, data: 0.001) D_A: 0.225 G_A: 0.419 cycle_A: 0.629 idt_A: 0.364 D_B: 0.183 G_B: 0.438 cycle_B: 0.693 idt_B: 0.269 \n",
      "(epoch: 20, iters: 360, time: 0.087, data: 0.001) D_A: 0.202 G_A: 0.349 cycle_A: 0.718 idt_A: 0.318 D_B: 0.154 G_B: 0.672 cycle_B: 0.653 idt_B: 0.338 \n",
      "(epoch: 20, iters: 560, time: 0.063, data: 0.001) D_A: 0.292 G_A: 0.351 cycle_A: 0.666 idt_A: 0.280 D_B: 0.259 G_B: 0.218 cycle_B: 0.628 idt_B: 0.265 \n",
      "(epoch: 20, iters: 760, time: 0.063, data: 0.002) D_A: 0.272 G_A: 0.308 cycle_A: 0.627 idt_A: 0.293 D_B: 0.140 G_B: 0.395 cycle_B: 0.758 idt_B: 0.268 \n",
      "(epoch: 20, iters: 960, time: 0.063, data: 0.002) D_A: 0.228 G_A: 0.307 cycle_A: 0.770 idt_A: 0.286 D_B: 0.178 G_B: 0.418 cycle_B: 0.713 idt_B: 0.305 \n",
      "(epoch: 20, iters: 1160, time: 0.063, data: 0.002) D_A: 0.331 G_A: 0.396 cycle_A: 0.797 idt_A: 0.301 D_B: 0.177 G_B: 0.538 cycle_B: 0.671 idt_B: 0.328 \n",
      "saving the model at the end of epoch 20, iters 23200\n",
      "End of epoch 20 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 21, iters: 200, time: 0.063, data: 0.078) D_A: 0.217 G_A: 0.263 cycle_A: 0.802 idt_A: 0.391 D_B: 0.233 G_B: 0.402 cycle_B: 0.916 idt_B: 0.420 \n",
      "(epoch: 21, iters: 400, time: 0.089, data: 0.002) D_A: 0.215 G_A: 0.364 cycle_A: 0.699 idt_A: 0.361 D_B: 0.165 G_B: 0.300 cycle_B: 0.786 idt_B: 0.349 \n",
      "(epoch: 21, iters: 600, time: 0.063, data: 0.001) D_A: 0.233 G_A: 0.420 cycle_A: 0.611 idt_A: 0.296 D_B: 0.238 G_B: 0.249 cycle_B: 0.772 idt_B: 0.279 \n",
      "(epoch: 21, iters: 800, time: 0.086, data: 0.002) D_A: 0.233 G_A: 0.298 cycle_A: 0.795 idt_A: 0.296 D_B: 0.216 G_B: 0.197 cycle_B: 0.691 idt_B: 0.336 \n",
      "(epoch: 21, iters: 1000, time: 0.062, data: 0.001) D_A: 0.266 G_A: 0.349 cycle_A: 0.518 idt_A: 0.248 D_B: 0.336 G_B: 0.555 cycle_B: 0.593 idt_B: 0.249 \n",
      "End of epoch 21 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 22, iters: 40, time: 0.087, data: 0.002) D_A: 0.227 G_A: 0.295 cycle_A: 0.794 idt_A: 0.344 D_B: 0.189 G_B: 0.322 cycle_B: 0.954 idt_B: 0.381 \n",
      "(epoch: 22, iters: 240, time: 0.063, data: 0.001) D_A: 0.227 G_A: 0.292 cycle_A: 0.672 idt_A: 0.287 D_B: 0.211 G_B: 0.252 cycle_B: 0.675 idt_B: 0.292 \n",
      "(epoch: 22, iters: 440, time: 0.063, data: 0.002) D_A: 0.224 G_A: 0.297 cycle_A: 0.723 idt_A: 0.267 D_B: 0.200 G_B: 0.525 cycle_B: 0.625 idt_B: 0.316 \n",
      "(epoch: 22, iters: 640, time: 0.063, data: 0.001) D_A: 0.229 G_A: 0.408 cycle_A: 0.830 idt_A: 0.330 D_B: 0.156 G_B: 0.485 cycle_B: 0.848 idt_B: 0.388 \n",
      "saving the latest model (epoch 22, total_iters 25000)\n",
      "(epoch: 22, iters: 840, time: 0.062, data: 0.001) D_A: 0.194 G_A: 0.359 cycle_A: 0.798 idt_A: 0.274 D_B: 0.218 G_B: 0.472 cycle_B: 0.590 idt_B: 0.382 \n",
      "(epoch: 22, iters: 1040, time: 0.063, data: 0.002) D_A: 0.204 G_A: 0.517 cycle_A: 0.742 idt_A: 0.250 D_B: 0.109 G_B: 0.438 cycle_B: 0.571 idt_B: 0.382 \n",
      "End of epoch 22 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 23, iters: 80, time: 0.088, data: 0.002) D_A: 0.218 G_A: 0.355 cycle_A: 0.657 idt_A: 0.304 D_B: 0.150 G_B: 0.377 cycle_B: 0.716 idt_B: 0.304 \n",
      "(epoch: 23, iters: 280, time: 0.063, data: 0.002) D_A: 0.212 G_A: 0.394 cycle_A: 1.134 idt_A: 0.298 D_B: 0.344 G_B: 0.733 cycle_B: 0.767 idt_B: 0.424 \n",
      "(epoch: 23, iters: 480, time: 0.087, data: 0.002) D_A: 0.155 G_A: 0.485 cycle_A: 0.819 idt_A: 0.256 D_B: 0.159 G_B: 0.550 cycle_B: 0.632 idt_B: 0.416 \n",
      "(epoch: 23, iters: 680, time: 0.063, data: 0.001) D_A: 0.157 G_A: 0.360 cycle_A: 0.632 idt_A: 0.343 D_B: 0.229 G_B: 0.292 cycle_B: 0.769 idt_B: 0.285 \n",
      "(epoch: 23, iters: 880, time: 0.063, data: 0.002) D_A: 0.196 G_A: 0.657 cycle_A: 0.945 idt_A: 0.295 D_B: 0.339 G_B: 0.719 cycle_B: 0.628 idt_B: 0.393 \n",
      "(epoch: 23, iters: 1080, time: 0.063, data: 0.002) D_A: 0.184 G_A: 0.386 cycle_A: 0.622 idt_A: 0.284 D_B: 0.157 G_B: 0.392 cycle_B: 0.628 idt_B: 0.280 \n",
      "End of epoch 23 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 24, iters: 120, time: 0.087, data: 0.002) D_A: 0.185 G_A: 0.461 cycle_A: 0.762 idt_A: 0.401 D_B: 0.228 G_B: 0.303 cycle_B: 0.934 idt_B: 0.330 \n",
      "(epoch: 24, iters: 320, time: 0.063, data: 0.002) D_A: 0.205 G_A: 0.269 cycle_A: 0.800 idt_A: 0.290 D_B: 0.173 G_B: 0.287 cycle_B: 0.588 idt_B: 0.302 \n",
      "(epoch: 24, iters: 520, time: 0.063, data: 0.002) D_A: 0.313 G_A: 0.498 cycle_A: 0.785 idt_A: 0.402 D_B: 0.173 G_B: 0.327 cycle_B: 0.919 idt_B: 0.258 \n",
      "(epoch: 24, iters: 720, time: 0.063, data: 0.001) D_A: 0.144 G_A: 0.376 cycle_A: 0.662 idt_A: 0.354 D_B: 0.215 G_B: 0.370 cycle_B: 0.862 idt_B: 0.296 \n",
      "(epoch: 24, iters: 920, time: 0.063, data: 0.002) D_A: 0.195 G_A: 0.248 cycle_A: 0.699 idt_A: 0.325 D_B: 0.192 G_B: 0.200 cycle_B: 0.766 idt_B: 0.290 \n",
      "(epoch: 24, iters: 1120, time: 0.063, data: 0.002) D_A: 0.159 G_A: 0.407 cycle_A: 0.929 idt_A: 0.322 D_B: 0.161 G_B: 0.457 cycle_B: 0.656 idt_B: 0.380 \n",
      "End of epoch 24 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 25, iters: 160, time: 0.089, data: 0.002) D_A: 0.194 G_A: 0.326 cycle_A: 0.813 idt_A: 0.359 D_B: 0.187 G_B: 0.560 cycle_B: 0.741 idt_B: 0.396 \n",
      "(epoch: 25, iters: 360, time: 0.063, data: 0.001) D_A: 0.186 G_A: 0.242 cycle_A: 0.680 idt_A: 0.341 D_B: 0.154 G_B: 0.378 cycle_B: 0.729 idt_B: 0.280 \n",
      "(epoch: 25, iters: 560, time: 0.063, data: 0.002) D_A: 0.291 G_A: 0.467 cycle_A: 0.709 idt_A: 0.271 D_B: 0.216 G_B: 0.341 cycle_B: 0.613 idt_B: 0.293 \n",
      "(epoch: 25, iters: 760, time: 0.063, data: 0.002) D_A: 0.128 G_A: 0.599 cycle_A: 0.888 idt_A: 0.400 D_B: 0.140 G_B: 0.695 cycle_B: 0.870 idt_B: 0.315 \n",
      "(epoch: 25, iters: 960, time: 0.063, data: 0.002) D_A: 0.145 G_A: 0.651 cycle_A: 0.685 idt_A: 0.281 D_B: 0.223 G_B: 0.259 cycle_B: 0.646 idt_B: 0.321 \n",
      "(epoch: 25, iters: 1160, time: 0.063, data: 0.002) D_A: 0.217 G_A: 0.399 cycle_A: 0.752 idt_A: 0.303 D_B: 0.158 G_B: 0.376 cycle_B: 0.691 idt_B: 0.380 \n",
      "saving the model at the end of epoch 25, iters 29000\n",
      "End of epoch 25 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 26, iters: 200, time: 0.088, data: 0.083) D_A: 0.293 G_A: 0.835 cycle_A: 0.655 idt_A: 0.316 D_B: 0.177 G_B: 0.411 cycle_B: 0.683 idt_B: 0.279 \n",
      "(epoch: 26, iters: 400, time: 0.063, data: 0.001) D_A: 0.210 G_A: 0.291 cycle_A: 0.673 idt_A: 0.283 D_B: 0.232 G_B: 0.787 cycle_B: 0.707 idt_B: 0.242 \n",
      "(epoch: 26, iters: 600, time: 0.063, data: 0.001) D_A: 0.162 G_A: 0.247 cycle_A: 0.890 idt_A: 0.268 D_B: 0.217 G_B: 0.551 cycle_B: 0.597 idt_B: 0.414 \n",
      "(epoch: 26, iters: 800, time: 0.063, data: 0.001) D_A: 0.207 G_A: 0.305 cycle_A: 0.782 idt_A: 0.283 D_B: 0.217 G_B: 0.708 cycle_B: 0.639 idt_B: 0.314 \n",
      "(epoch: 26, iters: 1000, time: 0.091, data: 0.002) D_A: 0.247 G_A: 0.355 cycle_A: 0.783 idt_A: 0.367 D_B: 0.219 G_B: 0.220 cycle_B: 0.847 idt_B: 0.342 \n",
      "saving the latest model (epoch 26, total_iters 30000)\n",
      "End of epoch 26 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 27, iters: 40, time: 0.063, data: 0.001) D_A: 0.362 G_A: 0.146 cycle_A: 1.218 idt_A: 0.359 D_B: 0.234 G_B: 0.135 cycle_B: 0.845 idt_B: 0.345 \n",
      "(epoch: 27, iters: 240, time: 0.086, data: 0.001) D_A: 0.162 G_A: 0.318 cycle_A: 1.017 idt_A: 0.339 D_B: 0.142 G_B: 0.318 cycle_B: 0.729 idt_B: 0.352 \n",
      "(epoch: 27, iters: 440, time: 0.063, data: 0.001) D_A: 0.159 G_A: 0.320 cycle_A: 0.726 idt_A: 0.276 D_B: 0.215 G_B: 0.585 cycle_B: 0.624 idt_B: 0.334 \n",
      "(epoch: 27, iters: 640, time: 0.062, data: 0.002) D_A: 0.199 G_A: 0.275 cycle_A: 0.663 idt_A: 0.282 D_B: 0.179 G_B: 0.606 cycle_B: 0.645 idt_B: 0.332 \n",
      "(epoch: 27, iters: 840, time: 0.063, data: 0.001) D_A: 0.193 G_A: 0.390 cycle_A: 0.760 idt_A: 0.266 D_B: 0.147 G_B: 0.377 cycle_B: 0.578 idt_B: 0.313 \n",
      "(epoch: 27, iters: 1040, time: 0.063, data: 0.002) D_A: 0.195 G_A: 0.639 cycle_A: 0.785 idt_A: 0.357 D_B: 0.302 G_B: 0.208 cycle_B: 0.875 idt_B: 0.250 \n",
      "End of epoch 27 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 28, iters: 80, time: 0.062, data: 0.002) D_A: 0.171 G_A: 0.427 cycle_A: 0.831 idt_A: 0.324 D_B: 0.235 G_B: 0.485 cycle_B: 0.695 idt_B: 0.290 \n",
      "(epoch: 28, iters: 280, time: 0.090, data: 0.002) D_A: 0.360 G_A: 0.507 cycle_A: 0.791 idt_A: 0.254 D_B: 0.208 G_B: 0.333 cycle_B: 0.606 idt_B: 0.339 \n",
      "(epoch: 28, iters: 480, time: 0.063, data: 0.001) D_A: 0.328 G_A: 0.382 cycle_A: 0.686 idt_A: 0.297 D_B: 0.125 G_B: 0.535 cycle_B: 0.633 idt_B: 0.318 \n",
      "(epoch: 28, iters: 680, time: 0.091, data: 0.002) D_A: 0.297 G_A: 0.195 cycle_A: 0.670 idt_A: 0.281 D_B: 0.229 G_B: 0.431 cycle_B: 0.738 idt_B: 0.256 \n",
      "(epoch: 28, iters: 880, time: 0.063, data: 0.001) D_A: 0.222 G_A: 0.261 cycle_A: 0.578 idt_A: 0.291 D_B: 0.185 G_B: 0.429 cycle_B: 0.646 idt_B: 0.287 \n",
      "(epoch: 28, iters: 1080, time: 0.063, data: 0.001) D_A: 0.193 G_A: 0.492 cycle_A: 0.651 idt_A: 0.254 D_B: 0.191 G_B: 0.497 cycle_B: 0.634 idt_B: 0.292 \n",
      "End of epoch 28 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 29, iters: 120, time: 0.063, data: 0.002) D_A: 0.176 G_A: 0.352 cycle_A: 0.794 idt_A: 0.410 D_B: 0.187 G_B: 0.363 cycle_B: 1.152 idt_B: 0.392 \n",
      "(epoch: 29, iters: 320, time: 0.092, data: 0.001) D_A: 0.232 G_A: 0.483 cycle_A: 0.683 idt_A: 0.371 D_B: 0.340 G_B: 0.410 cycle_B: 0.849 idt_B: 0.282 \n",
      "(epoch: 29, iters: 520, time: 0.063, data: 0.001) D_A: 0.292 G_A: 0.300 cycle_A: 0.758 idt_A: 0.345 D_B: 0.266 G_B: 0.501 cycle_B: 0.736 idt_B: 0.324 \n",
      "(epoch: 29, iters: 720, time: 0.063, data: 0.002) D_A: 0.224 G_A: 0.198 cycle_A: 1.014 idt_A: 0.481 D_B: 0.193 G_B: 0.452 cycle_B: 0.957 idt_B: 0.430 \n",
      "(epoch: 29, iters: 920, time: 0.063, data: 0.002) D_A: 0.216 G_A: 0.293 cycle_A: 0.687 idt_A: 0.293 D_B: 0.224 G_B: 0.213 cycle_B: 0.715 idt_B: 0.318 \n",
      "(epoch: 29, iters: 1120, time: 0.063, data: 0.002) D_A: 0.233 G_A: 0.288 cycle_A: 0.623 idt_A: 0.281 D_B: 0.189 G_B: 0.318 cycle_B: 0.609 idt_B: 0.258 \n",
      "End of epoch 29 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 30, iters: 160, time: 0.063, data: 0.002) D_A: 0.187 G_A: 0.340 cycle_A: 0.842 idt_A: 0.296 D_B: 0.187 G_B: 0.224 cycle_B: 0.774 idt_B: 0.289 \n",
      "(epoch: 30, iters: 360, time: 0.089, data: 0.002) D_A: 0.211 G_A: 0.733 cycle_A: 0.801 idt_A: 0.348 D_B: 0.261 G_B: 0.292 cycle_B: 0.751 idt_B: 0.300 \n",
      "(epoch: 30, iters: 560, time: 0.063, data: 0.001) D_A: 0.205 G_A: 0.583 cycle_A: 0.694 idt_A: 0.247 D_B: 0.199 G_B: 0.658 cycle_B: 0.586 idt_B: 0.302 \n",
      "(epoch: 30, iters: 760, time: 0.063, data: 0.002) D_A: 0.252 G_A: 0.347 cycle_A: 0.564 idt_A: 0.301 D_B: 0.201 G_B: 0.354 cycle_B: 0.651 idt_B: 0.232 \n",
      "(epoch: 30, iters: 960, time: 0.063, data: 0.002) D_A: 0.231 G_A: 0.141 cycle_A: 0.662 idt_A: 0.304 D_B: 0.304 G_B: 0.609 cycle_B: 0.806 idt_B: 0.292 \n",
      "(epoch: 30, iters: 1160, time: 0.063, data: 0.002) D_A: 0.280 G_A: 0.943 cycle_A: 0.744 idt_A: 0.254 D_B: 0.294 G_B: 0.143 cycle_B: 0.789 idt_B: 0.344 \n",
      "saving the model at the end of epoch 30, iters 34800\n",
      "End of epoch 30 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 31, iters: 200, time: 0.063, data: 0.107) D_A: 0.302 G_A: 0.549 cycle_A: 0.624 idt_A: 0.335 D_B: 0.225 G_B: 0.451 cycle_B: 0.635 idt_B: 0.280 \n",
      "saving the latest model (epoch 31, total_iters 35000)\n",
      "(epoch: 31, iters: 400, time: 0.092, data: 0.001) D_A: 0.191 G_A: 0.363 cycle_A: 0.811 idt_A: 0.304 D_B: 0.168 G_B: 0.602 cycle_B: 0.697 idt_B: 0.328 \n",
      "(epoch: 31, iters: 600, time: 0.063, data: 0.001) D_A: 0.206 G_A: 0.438 cycle_A: 0.786 idt_A: 0.341 D_B: 0.238 G_B: 0.312 cycle_B: 0.718 idt_B: 0.356 \n",
      "(epoch: 31, iters: 800, time: 0.063, data: 0.002) D_A: 0.231 G_A: 0.454 cycle_A: 0.592 idt_A: 0.281 D_B: 0.178 G_B: 0.248 cycle_B: 0.602 idt_B: 0.244 \n",
      "(epoch: 31, iters: 1000, time: 0.063, data: 0.002) D_A: 0.216 G_A: 0.540 cycle_A: 0.959 idt_A: 0.254 D_B: 0.170 G_B: 0.294 cycle_B: 0.773 idt_B: 0.342 \n",
      "End of epoch 31 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 32, iters: 40, time: 0.092, data: 0.002) D_A: 0.229 G_A: 0.762 cycle_A: 0.749 idt_A: 0.314 D_B: 0.165 G_B: 0.351 cycle_B: 0.783 idt_B: 0.288 \n",
      "(epoch: 32, iters: 240, time: 0.063, data: 0.001) D_A: 0.185 G_A: 0.449 cycle_A: 0.600 idt_A: 0.250 D_B: 0.248 G_B: 0.534 cycle_B: 0.655 idt_B: 0.284 \n",
      "(epoch: 32, iters: 440, time: 0.063, data: 0.001) D_A: 0.241 G_A: 0.465 cycle_A: 0.641 idt_A: 0.298 D_B: 0.205 G_B: 0.273 cycle_B: 0.724 idt_B: 0.302 \n",
      "(epoch: 32, iters: 640, time: 0.063, data: 0.002) D_A: 0.166 G_A: 0.372 cycle_A: 0.884 idt_A: 0.292 D_B: 0.230 G_B: 0.565 cycle_B: 0.739 idt_B: 0.379 \n",
      "(epoch: 32, iters: 840, time: 0.063, data: 0.001) D_A: 0.209 G_A: 0.451 cycle_A: 0.687 idt_A: 0.278 D_B: 0.218 G_B: 0.444 cycle_B: 0.607 idt_B: 0.296 \n",
      "(epoch: 32, iters: 1040, time: 0.063, data: 0.002) D_A: 0.177 G_A: 0.289 cycle_A: 0.777 idt_A: 0.395 D_B: 0.243 G_B: 0.478 cycle_B: 1.027 idt_B: 0.298 \n",
      "End of epoch 32 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 33, iters: 80, time: 0.093, data: 0.001) D_A: 0.181 G_A: 0.334 cycle_A: 0.590 idt_A: 0.316 D_B: 0.152 G_B: 0.259 cycle_B: 0.745 idt_B: 0.246 \n",
      "(epoch: 33, iters: 280, time: 0.063, data: 0.001) D_A: 0.236 G_A: 0.683 cycle_A: 0.805 idt_A: 0.259 D_B: 0.207 G_B: 0.485 cycle_B: 0.798 idt_B: 0.236 \n",
      "(epoch: 33, iters: 480, time: 0.063, data: 0.002) D_A: 0.189 G_A: 0.399 cycle_A: 0.844 idt_A: 0.290 D_B: 0.169 G_B: 0.385 cycle_B: 0.802 idt_B: 0.282 \n",
      "(epoch: 33, iters: 680, time: 0.063, data: 0.002) D_A: 0.202 G_A: 0.230 cycle_A: 0.575 idt_A: 0.315 D_B: 0.187 G_B: 0.452 cycle_B: 0.753 idt_B: 0.237 \n",
      "(epoch: 33, iters: 880, time: 0.094, data: 0.001) D_A: 0.184 G_A: 0.282 cycle_A: 0.881 idt_A: 0.318 D_B: 0.220 G_B: 0.493 cycle_B: 0.677 idt_B: 0.417 \n",
      "(epoch: 33, iters: 1080, time: 0.063, data: 0.001) D_A: 0.233 G_A: 0.343 cycle_A: 0.689 idt_A: 0.274 D_B: 0.179 G_B: 0.359 cycle_B: 0.657 idt_B: 0.321 \n",
      "End of epoch 33 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 34, iters: 120, time: 0.093, data: 0.001) D_A: 0.197 G_A: 0.213 cycle_A: 0.964 idt_A: 0.334 D_B: 0.229 G_B: 0.281 cycle_B: 0.714 idt_B: 0.524 \n",
      "(epoch: 34, iters: 320, time: 0.063, data: 0.001) D_A: 0.272 G_A: 0.071 cycle_A: 0.633 idt_A: 0.262 D_B: 0.222 G_B: 0.286 cycle_B: 0.623 idt_B: 0.280 \n",
      "(epoch: 34, iters: 520, time: 0.062, data: 0.001) D_A: 0.169 G_A: 0.424 cycle_A: 0.774 idt_A: 0.272 D_B: 0.179 G_B: 0.242 cycle_B: 0.618 idt_B: 0.318 \n",
      "(epoch: 34, iters: 720, time: 0.062, data: 0.002) D_A: 0.316 G_A: 0.370 cycle_A: 0.639 idt_A: 0.324 D_B: 0.156 G_B: 0.460 cycle_B: 0.793 idt_B: 0.272 \n",
      "(epoch: 34, iters: 920, time: 0.063, data: 0.002) D_A: 0.187 G_A: 0.235 cycle_A: 0.624 idt_A: 0.215 D_B: 0.318 G_B: 0.846 cycle_B: 0.570 idt_B: 0.230 \n",
      "(epoch: 34, iters: 1120, time: 0.063, data: 0.001) D_A: 0.223 G_A: 0.676 cycle_A: 1.062 idt_A: 0.384 D_B: 0.277 G_B: 0.420 cycle_B: 0.930 idt_B: 0.331 \n",
      "End of epoch 34 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 35, iters: 160, time: 0.093, data: 0.002) D_A: 0.181 G_A: 0.403 cycle_A: 0.876 idt_A: 0.238 D_B: 0.182 G_B: 0.373 cycle_B: 0.645 idt_B: 0.333 \n",
      "(epoch: 35, iters: 360, time: 0.063, data: 0.001) D_A: 0.176 G_A: 0.478 cycle_A: 0.647 idt_A: 0.291 D_B: 0.241 G_B: 0.262 cycle_B: 0.592 idt_B: 0.235 \n",
      "(epoch: 35, iters: 560, time: 0.092, data: 0.002) D_A: 0.216 G_A: 0.439 cycle_A: 0.793 idt_A: 0.264 D_B: 0.218 G_B: 0.450 cycle_B: 0.590 idt_B: 0.327 \n",
      "saving the latest model (epoch 35, total_iters 40000)\n",
      "(epoch: 35, iters: 760, time: 0.063, data: 0.001) D_A: 0.248 G_A: 0.155 cycle_A: 0.723 idt_A: 0.322 D_B: 0.223 G_B: 0.498 cycle_B: 0.732 idt_B: 0.274 \n",
      "(epoch: 35, iters: 960, time: 0.063, data: 0.002) D_A: 0.219 G_A: 0.368 cycle_A: 0.677 idt_A: 0.231 D_B: 0.248 G_B: 0.584 cycle_B: 0.691 idt_B: 0.272 \n",
      "(epoch: 35, iters: 1160, time: 0.063, data: 0.002) D_A: 0.222 G_A: 0.388 cycle_A: 0.786 idt_A: 0.314 D_B: 0.255 G_B: 0.142 cycle_B: 0.779 idt_B: 0.330 \n",
      "saving the model at the end of epoch 35, iters 40600\n",
      "End of epoch 35 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 36, iters: 200, time: 0.095, data: 0.086) D_A: 0.161 G_A: 0.241 cycle_A: 0.816 idt_A: 0.263 D_B: 0.261 G_B: 0.864 cycle_B: 0.775 idt_B: 0.255 \n",
      "(epoch: 36, iters: 400, time: 0.063, data: 0.001) D_A: 0.189 G_A: 0.279 cycle_A: 1.034 idt_A: 0.298 D_B: 0.204 G_B: 0.468 cycle_B: 0.671 idt_B: 0.407 \n",
      "(epoch: 36, iters: 600, time: 0.063, data: 0.002) D_A: 0.172 G_A: 0.404 cycle_A: 0.580 idt_A: 0.323 D_B: 0.215 G_B: 0.363 cycle_B: 0.723 idt_B: 0.271 \n",
      "(epoch: 36, iters: 800, time: 0.063, data: 0.002) D_A: 0.245 G_A: 0.293 cycle_A: 0.611 idt_A: 0.243 D_B: 0.187 G_B: 0.369 cycle_B: 0.578 idt_B: 0.277 \n",
      "(epoch: 36, iters: 1000, time: 0.063, data: 0.002) D_A: 0.270 G_A: 0.599 cycle_A: 0.722 idt_A: 0.264 D_B: 0.371 G_B: 0.099 cycle_B: 0.688 idt_B: 0.287 \n",
      "End of epoch 36 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 37, iters: 40, time: 0.063, data: 0.001) D_A: 0.198 G_A: 0.612 cycle_A: 0.833 idt_A: 0.309 D_B: 0.208 G_B: 0.354 cycle_B: 0.719 idt_B: 0.303 \n",
      "(epoch: 37, iters: 240, time: 0.092, data: 0.001) D_A: 0.220 G_A: 0.174 cycle_A: 0.691 idt_A: 0.330 D_B: 0.220 G_B: 0.359 cycle_B: 0.670 idt_B: 0.281 \n",
      "(epoch: 37, iters: 440, time: 0.063, data: 0.001) D_A: 0.242 G_A: 0.517 cycle_A: 0.687 idt_A: 0.249 D_B: 0.186 G_B: 0.236 cycle_B: 0.574 idt_B: 0.256 \n",
      "(epoch: 37, iters: 640, time: 0.063, data: 0.002) D_A: 0.186 G_A: 0.173 cycle_A: 0.606 idt_A: 0.231 D_B: 0.301 G_B: 0.512 cycle_B: 0.571 idt_B: 0.264 \n",
      "(epoch: 37, iters: 840, time: 0.063, data: 0.002) D_A: 0.300 G_A: 0.875 cycle_A: 0.766 idt_A: 0.301 D_B: 0.200 G_B: 0.399 cycle_B: 0.653 idt_B: 0.304 \n",
      "(epoch: 37, iters: 1040, time: 0.063, data: 0.001) D_A: 0.181 G_A: 0.433 cycle_A: 0.599 idt_A: 0.224 D_B: 0.338 G_B: 0.136 cycle_B: 0.633 idt_B: 0.238 \n",
      "End of epoch 37 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 38, iters: 80, time: 0.063, data: 0.001) D_A: 0.230 G_A: 0.207 cycle_A: 0.852 idt_A: 0.295 D_B: 0.246 G_B: 0.124 cycle_B: 0.717 idt_B: 0.317 \n",
      "(epoch: 38, iters: 280, time: 0.095, data: 0.002) D_A: 0.228 G_A: 0.363 cycle_A: 0.884 idt_A: 0.263 D_B: 0.185 G_B: 0.421 cycle_B: 0.625 idt_B: 0.278 \n",
      "(epoch: 38, iters: 480, time: 0.063, data: 0.001) D_A: 0.152 G_A: 0.365 cycle_A: 0.864 idt_A: 0.297 D_B: 0.358 G_B: 0.446 cycle_B: 0.776 idt_B: 0.345 \n",
      "(epoch: 38, iters: 680, time: 0.063, data: 0.001) D_A: 0.188 G_A: 0.216 cycle_A: 0.577 idt_A: 0.330 D_B: 0.225 G_B: 0.305 cycle_B: 0.619 idt_B: 0.232 \n",
      "(epoch: 38, iters: 880, time: 0.063, data: 0.002) D_A: 0.211 G_A: 0.212 cycle_A: 0.608 idt_A: 0.249 D_B: 0.211 G_B: 0.303 cycle_B: 0.593 idt_B: 0.240 \n",
      "(epoch: 38, iters: 1080, time: 0.095, data: 0.002) D_A: 0.215 G_A: 0.263 cycle_A: 0.762 idt_A: 0.308 D_B: 0.166 G_B: 0.306 cycle_B: 0.620 idt_B: 0.360 \n",
      "End of epoch 38 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 39, iters: 120, time: 0.063, data: 0.001) D_A: 0.184 G_A: 0.387 cycle_A: 0.884 idt_A: 0.255 D_B: 0.242 G_B: 0.194 cycle_B: 0.650 idt_B: 0.363 \n",
      "(epoch: 39, iters: 320, time: 0.094, data: 0.001) D_A: 0.177 G_A: 0.232 cycle_A: 0.699 idt_A: 0.243 D_B: 0.203 G_B: 0.539 cycle_B: 0.560 idt_B: 0.295 \n",
      "(epoch: 39, iters: 520, time: 0.063, data: 0.001) D_A: 0.217 G_A: 0.233 cycle_A: 0.592 idt_A: 0.230 D_B: 0.229 G_B: 0.552 cycle_B: 0.543 idt_B: 0.254 \n",
      "(epoch: 39, iters: 720, time: 0.063, data: 0.001) D_A: 0.176 G_A: 0.501 cycle_A: 0.719 idt_A: 0.334 D_B: 0.189 G_B: 0.403 cycle_B: 0.747 idt_B: 0.342 \n",
      "(epoch: 39, iters: 920, time: 0.063, data: 0.002) D_A: 0.190 G_A: 0.208 cycle_A: 0.591 idt_A: 0.218 D_B: 0.272 G_B: 0.178 cycle_B: 0.566 idt_B: 0.245 \n",
      "saving the latest model (epoch 39, total_iters 45000)\n",
      "(epoch: 39, iters: 1120, time: 0.063, data: 0.001) D_A: 0.219 G_A: 0.436 cycle_A: 0.578 idt_A: 0.250 D_B: 0.199 G_B: 0.463 cycle_B: 0.536 idt_B: 0.257 \n",
      "End of epoch 39 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 40, iters: 160, time: 0.063, data: 0.002) D_A: 0.208 G_A: 0.210 cycle_A: 0.799 idt_A: 0.226 D_B: 0.180 G_B: 0.215 cycle_B: 0.615 idt_B: 0.330 \n",
      "(epoch: 40, iters: 360, time: 0.095, data: 0.002) D_A: 0.244 G_A: 0.430 cycle_A: 0.676 idt_A: 0.335 D_B: 0.200 G_B: 0.326 cycle_B: 0.681 idt_B: 0.333 \n",
      "(epoch: 40, iters: 560, time: 0.063, data: 0.001) D_A: 0.177 G_A: 0.382 cycle_A: 0.791 idt_A: 0.233 D_B: 0.220 G_B: 0.555 cycle_B: 0.643 idt_B: 0.320 \n",
      "(epoch: 40, iters: 760, time: 0.096, data: 0.002) D_A: 0.176 G_A: 0.413 cycle_A: 0.743 idt_A: 0.238 D_B: 0.204 G_B: 0.304 cycle_B: 0.690 idt_B: 0.316 \n",
      "(epoch: 40, iters: 960, time: 0.063, data: 0.001) D_A: 0.196 G_A: 0.434 cycle_A: 0.702 idt_A: 0.224 D_B: 0.193 G_B: 0.370 cycle_B: 0.545 idt_B: 0.323 \n",
      "(epoch: 40, iters: 1160, time: 0.063, data: 0.002) D_A: 0.131 G_A: 0.413 cycle_A: 0.711 idt_A: 0.234 D_B: 0.226 G_B: 0.392 cycle_B: 0.632 idt_B: 0.317 \n",
      "saving the model at the end of epoch 40, iters 46400\n",
      "End of epoch 40 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 41, iters: 200, time: 0.063, data: 0.087) D_A: 0.187 G_A: 0.338 cycle_A: 0.661 idt_A: 0.253 D_B: 0.176 G_B: 0.338 cycle_B: 0.637 idt_B: 0.246 \n",
      "(epoch: 41, iters: 400, time: 0.094, data: 0.002) D_A: 0.168 G_A: 0.356 cycle_A: 0.683 idt_A: 0.245 D_B: 0.175 G_B: 0.478 cycle_B: 0.597 idt_B: 0.240 \n",
      "(epoch: 41, iters: 600, time: 0.063, data: 0.001) D_A: 0.186 G_A: 0.415 cycle_A: 0.620 idt_A: 0.271 D_B: 0.213 G_B: 0.415 cycle_B: 0.660 idt_B: 0.251 \n",
      "(epoch: 41, iters: 800, time: 0.063, data: 0.001) D_A: 0.221 G_A: 0.146 cycle_A: 0.615 idt_A: 0.265 D_B: 0.193 G_B: 0.424 cycle_B: 0.631 idt_B: 0.219 \n",
      "(epoch: 41, iters: 1000, time: 0.063, data: 0.002) D_A: 0.215 G_A: 0.263 cycle_A: 0.741 idt_A: 0.241 D_B: 0.179 G_B: 0.235 cycle_B: 0.617 idt_B: 0.336 \n",
      "End of epoch 41 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 42, iters: 40, time: 0.096, data: 0.002) D_A: 0.197 G_A: 0.274 cycle_A: 0.612 idt_A: 0.226 D_B: 0.231 G_B: 0.441 cycle_B: 0.567 idt_B: 0.235 \n",
      "(epoch: 42, iters: 240, time: 0.062, data: 0.001) D_A: 0.150 G_A: 0.302 cycle_A: 0.699 idt_A: 0.221 D_B: 0.243 G_B: 0.402 cycle_B: 0.633 idt_B: 0.270 \n",
      "(epoch: 42, iters: 440, time: 0.098, data: 0.001) D_A: 0.225 G_A: 0.486 cycle_A: 0.756 idt_A: 0.222 D_B: 0.191 G_B: 0.358 cycle_B: 0.608 idt_B: 0.321 \n",
      "(epoch: 42, iters: 640, time: 0.063, data: 0.001) D_A: 0.226 G_A: 0.629 cycle_A: 0.606 idt_A: 0.294 D_B: 0.194 G_B: 0.241 cycle_B: 0.640 idt_B: 0.281 \n",
      "(epoch: 42, iters: 840, time: 0.063, data: 0.002) D_A: 0.221 G_A: 0.319 cycle_A: 0.694 idt_A: 0.209 D_B: 0.193 G_B: 0.197 cycle_B: 0.581 idt_B: 0.255 \n",
      "(epoch: 42, iters: 1040, time: 0.063, data: 0.002) D_A: 0.314 G_A: 0.949 cycle_A: 0.630 idt_A: 0.302 D_B: 0.161 G_B: 0.286 cycle_B: 0.846 idt_B: 0.246 \n",
      "End of epoch 42 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 43, iters: 80, time: 0.097, data: 0.002) D_A: 0.138 G_A: 0.466 cycle_A: 0.749 idt_A: 0.364 D_B: 0.190 G_B: 0.273 cycle_B: 0.753 idt_B: 0.238 \n",
      "(epoch: 43, iters: 280, time: 0.063, data: 0.001) D_A: 0.219 G_A: 0.182 cycle_A: 0.730 idt_A: 0.195 D_B: 0.198 G_B: 0.281 cycle_B: 0.572 idt_B: 0.319 \n",
      "(epoch: 43, iters: 480, time: 0.063, data: 0.002) D_A: 0.175 G_A: 0.273 cycle_A: 0.749 idt_A: 0.256 D_B: 0.196 G_B: 0.324 cycle_B: 0.657 idt_B: 0.258 \n",
      "(epoch: 43, iters: 680, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.633 cycle_A: 0.880 idt_A: 0.297 D_B: 0.154 G_B: 0.254 cycle_B: 0.573 idt_B: 0.383 \n",
      "(epoch: 43, iters: 880, time: 0.063, data: 0.002) D_A: 0.181 G_A: 0.308 cycle_A: 0.655 idt_A: 0.318 D_B: 0.191 G_B: 0.376 cycle_B: 0.669 idt_B: 0.262 \n",
      "(epoch: 43, iters: 1080, time: 0.063, data: 0.002) D_A: 0.186 G_A: 0.347 cycle_A: 0.708 idt_A: 0.379 D_B: 0.239 G_B: 0.507 cycle_B: 0.729 idt_B: 0.324 \n",
      "End of epoch 43 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 44, iters: 120, time: 0.098, data: 0.002) D_A: 0.181 G_A: 0.527 cycle_A: 0.648 idt_A: 0.218 D_B: 0.200 G_B: 0.274 cycle_B: 0.521 idt_B: 0.246 \n",
      "saving the latest model (epoch 44, total_iters 50000)\n",
      "(epoch: 44, iters: 320, time: 0.063, data: 0.002) D_A: 0.844 G_A: 0.956 cycle_A: 0.901 idt_A: 0.211 D_B: 0.168 G_B: 0.676 cycle_B: 0.701 idt_B: 0.363 \n",
      "(epoch: 44, iters: 520, time: 0.063, data: 0.002) D_A: 0.260 G_A: 0.249 cycle_A: 0.466 idt_A: 0.232 D_B: 0.178 G_B: 0.533 cycle_B: 0.580 idt_B: 0.214 \n",
      "(epoch: 44, iters: 720, time: 0.063, data: 0.001) D_A: 0.248 G_A: 0.275 cycle_A: 0.670 idt_A: 0.314 D_B: 0.319 G_B: 0.173 cycle_B: 0.860 idt_B: 0.339 \n",
      "(epoch: 44, iters: 920, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.272 cycle_A: 0.577 idt_A: 0.177 D_B: 0.249 G_B: 0.314 cycle_B: 0.470 idt_B: 0.281 \n",
      "(epoch: 44, iters: 1120, time: 0.063, data: 0.002) D_A: 0.238 G_A: 0.236 cycle_A: 0.510 idt_A: 0.408 D_B: 0.221 G_B: 0.583 cycle_B: 0.789 idt_B: 0.217 \n",
      "End of epoch 44 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 45, iters: 160, time: 0.098, data: 0.002) D_A: 0.245 G_A: 0.272 cycle_A: 0.527 idt_A: 0.236 D_B: 0.187 G_B: 0.290 cycle_B: 0.640 idt_B: 0.238 \n",
      "(epoch: 45, iters: 360, time: 0.063, data: 0.002) D_A: 0.243 G_A: 0.254 cycle_A: 0.473 idt_A: 0.265 D_B: 0.168 G_B: 0.422 cycle_B: 0.544 idt_B: 0.189 \n",
      "(epoch: 45, iters: 560, time: 0.063, data: 0.002) D_A: 0.224 G_A: 0.331 cycle_A: 0.557 idt_A: 0.215 D_B: 0.215 G_B: 0.272 cycle_B: 0.607 idt_B: 0.292 \n",
      "(epoch: 45, iters: 760, time: 0.063, data: 0.001) D_A: 0.323 G_A: 0.463 cycle_A: 0.639 idt_A: 0.199 D_B: 0.207 G_B: 0.384 cycle_B: 0.519 idt_B: 0.313 \n",
      "(epoch: 45, iters: 960, time: 0.098, data: 0.001) D_A: 0.194 G_A: 0.370 cycle_A: 0.600 idt_A: 0.214 D_B: 0.216 G_B: 0.388 cycle_B: 0.547 idt_B: 0.291 \n",
      "(epoch: 45, iters: 1160, time: 0.062, data: 0.001) D_A: 0.251 G_A: 0.205 cycle_A: 0.617 idt_A: 0.262 D_B: 0.182 G_B: 0.393 cycle_B: 0.670 idt_B: 0.300 \n",
      "saving the model at the end of epoch 45, iters 52200\n",
      "End of epoch 45 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 46, iters: 200, time: 0.097, data: 0.117) D_A: 0.235 G_A: 0.274 cycle_A: 0.550 idt_A: 0.210 D_B: 0.352 G_B: 0.593 cycle_B: 0.644 idt_B: 0.212 \n",
      "(epoch: 46, iters: 400, time: 0.063, data: 0.002) D_A: 0.166 G_A: 0.344 cycle_A: 0.474 idt_A: 0.191 D_B: 0.193 G_B: 0.619 cycle_B: 0.588 idt_B: 0.220 \n",
      "(epoch: 46, iters: 600, time: 0.063, data: 0.002) D_A: 0.197 G_A: 0.332 cycle_A: 0.650 idt_A: 0.231 D_B: 0.224 G_B: 0.200 cycle_B: 0.571 idt_B: 0.274 \n",
      "(epoch: 46, iters: 800, time: 0.063, data: 0.002) D_A: 0.164 G_A: 0.314 cycle_A: 0.590 idt_A: 0.237 D_B: 0.205 G_B: 0.705 cycle_B: 0.588 idt_B: 0.227 \n",
      "(epoch: 46, iters: 1000, time: 0.063, data: 0.002) D_A: 0.206 G_A: 0.306 cycle_A: 0.534 idt_A: 0.315 D_B: 0.222 G_B: 0.252 cycle_B: 0.810 idt_B: 0.232 \n",
      "End of epoch 46 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 47, iters: 40, time: 0.063, data: 0.002) D_A: 0.232 G_A: 0.246 cycle_A: 0.519 idt_A: 0.299 D_B: 0.191 G_B: 0.393 cycle_B: 0.703 idt_B: 0.271 \n",
      "(epoch: 47, iters: 240, time: 0.100, data: 0.001) D_A: 0.150 G_A: 0.409 cycle_A: 0.664 idt_A: 0.244 D_B: 0.231 G_B: 0.489 cycle_B: 0.598 idt_B: 0.323 \n",
      "(epoch: 47, iters: 440, time: 0.063, data: 0.001) D_A: 0.188 G_A: 0.323 cycle_A: 1.049 idt_A: 0.404 D_B: 0.179 G_B: 0.203 cycle_B: 1.110 idt_B: 0.284 \n",
      "(epoch: 47, iters: 640, time: 0.098, data: 0.001) D_A: 0.178 G_A: 0.230 cycle_A: 0.724 idt_A: 0.264 D_B: 0.145 G_B: 0.458 cycle_B: 0.633 idt_B: 0.265 \n",
      "(epoch: 47, iters: 840, time: 0.063, data: 0.001) D_A: 0.131 G_A: 0.335 cycle_A: 0.697 idt_A: 0.232 D_B: 0.132 G_B: 0.516 cycle_B: 0.644 idt_B: 0.235 \n",
      "(epoch: 47, iters: 1040, time: 0.063, data: 0.002) D_A: 0.168 G_A: 0.231 cycle_A: 0.608 idt_A: 0.230 D_B: 0.152 G_B: 0.473 cycle_B: 0.515 idt_B: 0.260 \n",
      "End of epoch 47 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 48, iters: 80, time: 0.063, data: 0.002) D_A: 0.164 G_A: 0.415 cycle_A: 0.614 idt_A: 0.281 D_B: 0.156 G_B: 0.303 cycle_B: 0.605 idt_B: 0.265 \n",
      "(epoch: 48, iters: 280, time: 0.098, data: 0.002) D_A: 0.192 G_A: 0.347 cycle_A: 0.613 idt_A: 0.266 D_B: 0.182 G_B: 0.288 cycle_B: 0.591 idt_B: 0.214 \n",
      "(epoch: 48, iters: 480, time: 0.063, data: 0.002) D_A: 0.182 G_A: 0.422 cycle_A: 0.580 idt_A: 0.237 D_B: 0.171 G_B: 0.356 cycle_B: 0.517 idt_B: 0.188 \n",
      "saving the latest model (epoch 48, total_iters 55000)\n",
      "(epoch: 48, iters: 680, time: 0.063, data: 0.002) D_A: 0.179 G_A: 0.389 cycle_A: 0.595 idt_A: 0.225 D_B: 0.205 G_B: 0.207 cycle_B: 0.739 idt_B: 0.219 \n",
      "(epoch: 48, iters: 880, time: 0.063, data: 0.001) D_A: 0.213 G_A: 0.486 cycle_A: 0.679 idt_A: 0.265 D_B: 0.235 G_B: 0.553 cycle_B: 0.562 idt_B: 0.237 \n",
      "(epoch: 48, iters: 1080, time: 0.063, data: 0.001) D_A: 0.176 G_A: 0.436 cycle_A: 0.563 idt_A: 0.240 D_B: 0.187 G_B: 0.461 cycle_B: 0.510 idt_B: 0.223 \n",
      "End of epoch 48 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 49, iters: 120, time: 0.063, data: 0.001) D_A: 0.204 G_A: 0.421 cycle_A: 0.756 idt_A: 0.225 D_B: 0.200 G_B: 0.480 cycle_B: 0.545 idt_B: 0.256 \n",
      "(epoch: 49, iters: 320, time: 0.099, data: 0.002) D_A: 0.177 G_A: 0.347 cycle_A: 0.454 idt_A: 0.263 D_B: 0.206 G_B: 0.496 cycle_B: 0.587 idt_B: 0.212 \n",
      "(epoch: 49, iters: 520, time: 0.063, data: 0.001) D_A: 0.196 G_A: 0.490 cycle_A: 0.541 idt_A: 0.253 D_B: 0.239 G_B: 0.717 cycle_B: 0.617 idt_B: 0.212 \n",
      "(epoch: 49, iters: 720, time: 0.063, data: 0.001) D_A: 0.182 G_A: 0.556 cycle_A: 0.590 idt_A: 0.242 D_B: 0.268 G_B: 0.138 cycle_B: 0.563 idt_B: 0.236 \n",
      "(epoch: 49, iters: 920, time: 0.063, data: 0.002) D_A: 0.161 G_A: 0.433 cycle_A: 0.647 idt_A: 0.293 D_B: 0.138 G_B: 0.337 cycle_B: 0.707 idt_B: 0.232 \n",
      "(epoch: 49, iters: 1120, time: 0.063, data: 0.002) D_A: 0.224 G_A: 0.519 cycle_A: 0.848 idt_A: 0.268 D_B: 0.237 G_B: 0.375 cycle_B: 0.809 idt_B: 0.308 \n",
      "End of epoch 49 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 50, iters: 160, time: 0.063, data: 0.001) D_A: 0.194 G_A: 0.228 cycle_A: 0.696 idt_A: 0.321 D_B: 0.239 G_B: 0.506 cycle_B: 0.697 idt_B: 0.288 \n",
      "(epoch: 50, iters: 360, time: 0.099, data: 0.002) D_A: 0.165 G_A: 0.429 cycle_A: 0.699 idt_A: 0.281 D_B: 0.143 G_B: 0.346 cycle_B: 0.651 idt_B: 0.263 \n",
      "(epoch: 50, iters: 560, time: 0.063, data: 0.001) D_A: 0.207 G_A: 0.211 cycle_A: 0.593 idt_A: 0.331 D_B: 0.198 G_B: 0.355 cycle_B: 0.616 idt_B: 0.211 \n",
      "(epoch: 50, iters: 760, time: 0.063, data: 0.002) D_A: 0.172 G_A: 0.570 cycle_A: 0.572 idt_A: 0.263 D_B: 0.097 G_B: 0.487 cycle_B: 0.606 idt_B: 0.218 \n",
      "(epoch: 50, iters: 960, time: 0.063, data: 0.002) D_A: 0.210 G_A: 0.657 cycle_A: 0.432 idt_A: 0.284 D_B: 0.291 G_B: 0.161 cycle_B: 0.666 idt_B: 0.190 \n",
      "(epoch: 50, iters: 1160, time: 0.099, data: 0.001) D_A: 0.205 G_A: 0.410 cycle_A: 0.522 idt_A: 0.302 D_B: 0.266 G_B: 0.484 cycle_B: 0.804 idt_B: 0.197 \n",
      "saving the model at the end of epoch 50, iters 58000\n",
      "End of epoch 50 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 51, iters: 200, time: 0.063, data: 0.107) D_A: 0.208 G_A: 0.319 cycle_A: 0.642 idt_A: 0.196 D_B: 0.145 G_B: 0.349 cycle_B: 0.659 idt_B: 0.275 \n",
      "(epoch: 51, iters: 400, time: 0.098, data: 0.001) D_A: 0.242 G_A: 0.187 cycle_A: 0.542 idt_A: 0.322 D_B: 0.176 G_B: 0.357 cycle_B: 0.586 idt_B: 0.214 \n",
      "(epoch: 51, iters: 600, time: 0.063, data: 0.001) D_A: 0.187 G_A: 0.280 cycle_A: 0.589 idt_A: 0.229 D_B: 0.218 G_B: 0.296 cycle_B: 0.543 idt_B: 0.248 \n",
      "(epoch: 51, iters: 800, time: 0.063, data: 0.002) D_A: 0.194 G_A: 0.516 cycle_A: 0.604 idt_A: 0.234 D_B: 0.167 G_B: 0.452 cycle_B: 0.588 idt_B: 0.274 \n",
      "(epoch: 51, iters: 1000, time: 0.062, data: 0.001) D_A: 0.201 G_A: 0.464 cycle_A: 0.647 idt_A: 0.246 D_B: 0.199 G_B: 0.246 cycle_B: 0.653 idt_B: 0.208 \n",
      "End of epoch 51 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 52, iters: 40, time: 0.100, data: 0.002) D_A: 0.166 G_A: 0.351 cycle_A: 0.591 idt_A: 0.327 D_B: 0.194 G_B: 0.389 cycle_B: 0.740 idt_B: 0.228 \n",
      "(epoch: 52, iters: 240, time: 0.063, data: 0.001) D_A: 0.170 G_A: 0.472 cycle_A: 0.610 idt_A: 0.247 D_B: 0.238 G_B: 0.457 cycle_B: 0.630 idt_B: 0.202 \n",
      "(epoch: 52, iters: 440, time: 0.063, data: 0.002) D_A: 0.169 G_A: 0.438 cycle_A: 1.036 idt_A: 0.228 D_B: 0.167 G_B: 0.487 cycle_B: 0.690 idt_B: 0.329 \n",
      "(epoch: 52, iters: 640, time: 0.063, data: 0.002) D_A: 0.182 G_A: 0.292 cycle_A: 0.692 idt_A: 0.255 D_B: 0.148 G_B: 0.462 cycle_B: 0.714 idt_B: 0.265 \n",
      "(epoch: 52, iters: 840, time: 0.097, data: 0.002) D_A: 0.275 G_A: 0.330 cycle_A: 0.957 idt_A: 0.424 D_B: 0.424 G_B: 0.651 cycle_B: 0.855 idt_B: 0.436 \n",
      "saving the latest model (epoch 52, total_iters 60000)\n",
      "(epoch: 52, iters: 1040, time: 0.063, data: 0.001) D_A: 0.247 G_A: 0.285 cycle_A: 0.648 idt_A: 0.263 D_B: 0.257 G_B: 0.273 cycle_B: 0.595 idt_B: 0.298 \n",
      "End of epoch 52 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 53, iters: 80, time: 0.102, data: 0.001) D_A: 0.247 G_A: 0.260 cycle_A: 0.453 idt_A: 0.225 D_B: 0.247 G_B: 0.262 cycle_B: 0.518 idt_B: 0.205 \n",
      "(epoch: 53, iters: 280, time: 0.063, data: 0.001) D_A: 0.234 G_A: 0.290 cycle_A: 0.586 idt_A: 0.306 D_B: 0.254 G_B: 0.238 cycle_B: 0.707 idt_B: 0.267 \n",
      "(epoch: 53, iters: 480, time: 0.063, data: 0.002) D_A: 0.218 G_A: 0.296 cycle_A: 0.535 idt_A: 0.339 D_B: 0.269 G_B: 0.212 cycle_B: 0.752 idt_B: 0.251 \n",
      "(epoch: 53, iters: 680, time: 0.063, data: 0.002) D_A: 0.248 G_A: 0.227 cycle_A: 0.600 idt_A: 0.252 D_B: 0.250 G_B: 0.272 cycle_B: 0.494 idt_B: 0.262 \n",
      "(epoch: 53, iters: 880, time: 0.063, data: 0.001) D_A: 0.248 G_A: 0.249 cycle_A: 0.501 idt_A: 0.243 D_B: 0.256 G_B: 0.250 cycle_B: 0.523 idt_B: 0.227 \n",
      "(epoch: 53, iters: 1080, time: 0.063, data: 0.001) D_A: 0.248 G_A: 0.262 cycle_A: 0.525 idt_A: 0.236 D_B: 0.259 G_B: 0.248 cycle_B: 0.566 idt_B: 0.222 \n",
      "End of epoch 53 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 54, iters: 120, time: 0.101, data: 0.002) D_A: 0.242 G_A: 0.251 cycle_A: 0.412 idt_A: 0.183 D_B: 0.246 G_B: 0.264 cycle_B: 0.441 idt_B: 0.188 \n",
      "(epoch: 54, iters: 320, time: 0.062, data: 0.001) D_A: 0.254 G_A: 0.290 cycle_A: 0.537 idt_A: 0.209 D_B: 0.258 G_B: 0.271 cycle_B: 0.457 idt_B: 0.202 \n",
      "(epoch: 54, iters: 520, time: 0.100, data: 0.002) D_A: 0.252 G_A: 0.260 cycle_A: 0.539 idt_A: 0.294 D_B: 0.260 G_B: 0.260 cycle_B: 0.622 idt_B: 0.283 \n",
      "(epoch: 54, iters: 720, time: 0.063, data: 0.001) D_A: 0.241 G_A: 0.276 cycle_A: 0.427 idt_A: 0.175 D_B: 0.252 G_B: 0.272 cycle_B: 0.368 idt_B: 0.201 \n",
      "(epoch: 54, iters: 920, time: 0.062, data: 0.001) D_A: 0.247 G_A: 0.223 cycle_A: 0.549 idt_A: 0.204 D_B: 0.251 G_B: 0.287 cycle_B: 0.464 idt_B: 0.226 \n",
      "(epoch: 54, iters: 1120, time: 0.063, data: 0.002) D_A: 0.255 G_A: 0.228 cycle_A: 0.651 idt_A: 0.204 D_B: 0.256 G_B: 0.257 cycle_B: 0.513 idt_B: 0.271 \n",
      "End of epoch 54 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 55, iters: 160, time: 0.101, data: 0.002) D_A: 0.255 G_A: 0.231 cycle_A: 0.452 idt_A: 0.195 D_B: 0.250 G_B: 0.282 cycle_B: 0.469 idt_B: 0.185 \n",
      "(epoch: 55, iters: 360, time: 0.063, data: 0.001) D_A: 0.247 G_A: 0.242 cycle_A: 0.392 idt_A: 0.216 D_B: 0.251 G_B: 0.256 cycle_B: 0.364 idt_B: 0.159 \n",
      "(epoch: 55, iters: 560, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.258 cycle_A: 0.445 idt_A: 0.278 D_B: 0.254 G_B: 0.289 cycle_B: 0.569 idt_B: 0.216 \n",
      "(epoch: 55, iters: 760, time: 0.063, data: 0.001) D_A: 0.241 G_A: 0.283 cycle_A: 0.435 idt_A: 0.280 D_B: 0.247 G_B: 0.274 cycle_B: 0.602 idt_B: 0.187 \n",
      "(epoch: 55, iters: 960, time: 0.063, data: 0.002) D_A: 0.245 G_A: 0.257 cycle_A: 0.582 idt_A: 0.211 D_B: 0.244 G_B: 0.261 cycle_B: 0.378 idt_B: 0.243 \n",
      "(epoch: 55, iters: 1160, time: 0.063, data: 0.001) D_A: 0.251 G_A: 0.252 cycle_A: 0.614 idt_A: 0.203 D_B: 0.255 G_B: 0.261 cycle_B: 0.452 idt_B: 0.294 \n",
      "saving the model at the end of epoch 55, iters 63800\n",
      "End of epoch 55 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 56, iters: 200, time: 0.101, data: 0.134) D_A: 0.238 G_A: 0.273 cycle_A: 0.448 idt_A: 0.283 D_B: 0.245 G_B: 0.264 cycle_B: 0.549 idt_B: 0.225 \n",
      "(epoch: 56, iters: 400, time: 0.063, data: 0.001) D_A: 0.254 G_A: 0.298 cycle_A: 0.837 idt_A: 0.198 D_B: 0.255 G_B: 0.256 cycle_B: 0.466 idt_B: 0.358 \n",
      "(epoch: 56, iters: 600, time: 0.063, data: 0.002) D_A: 0.241 G_A: 0.260 cycle_A: 0.423 idt_A: 0.194 D_B: 0.248 G_B: 0.261 cycle_B: 0.519 idt_B: 0.274 \n",
      "(epoch: 56, iters: 800, time: 0.063, data: 0.001) D_A: 0.259 G_A: 0.272 cycle_A: 0.592 idt_A: 0.192 D_B: 0.257 G_B: 0.245 cycle_B: 0.512 idt_B: 0.265 \n",
      "(epoch: 56, iters: 1000, time: 0.063, data: 0.002) D_A: 0.238 G_A: 0.268 cycle_A: 0.544 idt_A: 0.198 D_B: 0.253 G_B: 0.275 cycle_B: 0.473 idt_B: 0.254 \n",
      "End of epoch 56 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 57, iters: 40, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.262 cycle_A: 0.462 idt_A: 0.230 D_B: 0.247 G_B: 0.268 cycle_B: 0.497 idt_B: 0.213 \n",
      "saving the latest model (epoch 57, total_iters 65000)\n",
      "(epoch: 57, iters: 240, time: 0.103, data: 0.001) D_A: 0.244 G_A: 0.267 cycle_A: 0.484 idt_A: 0.260 D_B: 0.242 G_B: 0.268 cycle_B: 0.501 idt_B: 0.233 \n",
      "(epoch: 57, iters: 440, time: 0.063, data: 0.001) D_A: 0.256 G_A: 0.277 cycle_A: 0.488 idt_A: 0.180 D_B: 0.256 G_B: 0.250 cycle_B: 0.400 idt_B: 0.253 \n",
      "(epoch: 57, iters: 640, time: 0.062, data: 0.002) D_A: 0.240 G_A: 0.276 cycle_A: 0.463 idt_A: 0.214 D_B: 0.248 G_B: 0.278 cycle_B: 0.561 idt_B: 0.200 \n",
      "(epoch: 57, iters: 840, time: 0.063, data: 0.001) D_A: 0.248 G_A: 0.268 cycle_A: 0.488 idt_A: 0.283 D_B: 0.241 G_B: 0.245 cycle_B: 0.672 idt_B: 0.195 \n",
      "(epoch: 57, iters: 1040, time: 0.102, data: 0.002) D_A: 0.248 G_A: 0.255 cycle_A: 0.463 idt_A: 0.214 D_B: 0.251 G_B: 0.229 cycle_B: 0.449 idt_B: 0.204 \n",
      "End of epoch 57 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 58, iters: 80, time: 0.063, data: 0.001) D_A: 0.239 G_A: 0.365 cycle_A: 0.496 idt_A: 0.243 D_B: 0.249 G_B: 0.249 cycle_B: 0.429 idt_B: 0.225 \n",
      "(epoch: 58, iters: 280, time: 0.112, data: 0.002) D_A: 0.248 G_A: 0.268 cycle_A: 0.459 idt_A: 0.225 D_B: 0.258 G_B: 0.275 cycle_B: 0.452 idt_B: 0.215 \n",
      "(epoch: 58, iters: 480, time: 0.063, data: 0.001) D_A: 0.243 G_A: 0.330 cycle_A: 0.477 idt_A: 0.198 D_B: 0.256 G_B: 0.206 cycle_B: 0.430 idt_B: 0.207 \n",
      "(epoch: 58, iters: 680, time: 0.063, data: 0.002) D_A: 0.254 G_A: 0.251 cycle_A: 0.384 idt_A: 0.203 D_B: 0.249 G_B: 0.267 cycle_B: 0.427 idt_B: 0.187 \n",
      "(epoch: 58, iters: 880, time: 0.063, data: 0.001) D_A: 0.245 G_A: 0.271 cycle_A: 0.465 idt_A: 0.214 D_B: 0.246 G_B: 0.246 cycle_B: 0.518 idt_B: 0.207 \n",
      "(epoch: 58, iters: 1080, time: 0.063, data: 0.002) D_A: 0.242 G_A: 0.239 cycle_A: 0.540 idt_A: 0.224 D_B: 0.259 G_B: 0.284 cycle_B: 0.515 idt_B: 0.248 \n",
      "End of epoch 58 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 59, iters: 120, time: 0.063, data: 0.002) D_A: 0.284 G_A: 0.320 cycle_A: 0.668 idt_A: 0.225 D_B: 0.251 G_B: 0.263 cycle_B: 0.571 idt_B: 0.311 \n",
      "(epoch: 59, iters: 320, time: 0.102, data: 0.002) D_A: 0.240 G_A: 0.289 cycle_A: 0.470 idt_A: 0.184 D_B: 0.253 G_B: 0.228 cycle_B: 0.455 idt_B: 0.242 \n",
      "(epoch: 59, iters: 520, time: 0.063, data: 0.001) D_A: 0.229 G_A: 0.314 cycle_A: 0.383 idt_A: 0.209 D_B: 0.252 G_B: 0.229 cycle_B: 0.432 idt_B: 0.158 \n",
      "(epoch: 59, iters: 720, time: 0.103, data: 0.002) D_A: 0.246 G_A: 0.258 cycle_A: 0.401 idt_A: 0.238 D_B: 0.247 G_B: 0.246 cycle_B: 0.511 idt_B: 0.185 \n",
      "(epoch: 59, iters: 920, time: 0.062, data: 0.001) D_A: 0.275 G_A: 0.343 cycle_A: 0.423 idt_A: 0.270 D_B: 0.247 G_B: 0.265 cycle_B: 0.448 idt_B: 0.182 \n",
      "(epoch: 59, iters: 1120, time: 0.063, data: 0.002) D_A: 0.233 G_A: 0.274 cycle_A: 0.444 idt_A: 0.198 D_B: 0.255 G_B: 0.296 cycle_B: 0.388 idt_B: 0.237 \n",
      "End of epoch 59 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 60, iters: 160, time: 0.063, data: 0.001) D_A: 0.377 G_A: 0.301 cycle_A: 0.551 idt_A: 0.184 D_B: 0.306 G_B: 0.320 cycle_B: 0.382 idt_B: 0.230 \n",
      "(epoch: 60, iters: 360, time: 0.103, data: 0.002) D_A: 0.228 G_A: 0.329 cycle_A: 0.525 idt_A: 0.219 D_B: 0.242 G_B: 0.243 cycle_B: 0.473 idt_B: 0.197 \n",
      "(epoch: 60, iters: 560, time: 0.063, data: 0.002) D_A: 0.259 G_A: 0.256 cycle_A: 0.441 idt_A: 0.197 D_B: 0.259 G_B: 0.305 cycle_B: 0.389 idt_B: 0.172 \n",
      "(epoch: 60, iters: 760, time: 0.062, data: 0.002) D_A: 0.218 G_A: 0.302 cycle_A: 0.433 idt_A: 0.188 D_B: 0.252 G_B: 0.262 cycle_B: 0.409 idt_B: 0.185 \n",
      "(epoch: 60, iters: 960, time: 0.063, data: 0.002) D_A: 0.242 G_A: 0.232 cycle_A: 0.458 idt_A: 0.172 D_B: 0.255 G_B: 0.267 cycle_B: 0.399 idt_B: 0.200 \n",
      "(epoch: 60, iters: 1160, time: 0.063, data: 0.001) D_A: 0.242 G_A: 0.269 cycle_A: 0.394 idt_A: 0.244 D_B: 0.319 G_B: 0.414 cycle_B: 0.500 idt_B: 0.155 \n",
      "saving the model at the end of epoch 60, iters 69600\n",
      "End of epoch 60 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 61, iters: 200, time: 0.063, data: 0.089) D_A: 0.224 G_A: 0.317 cycle_A: 0.364 idt_A: 0.221 D_B: 0.251 G_B: 0.290 cycle_B: 0.445 idt_B: 0.152 \n",
      "(epoch: 61, iters: 400, time: 0.103, data: 0.002) D_A: 0.242 G_A: 0.390 cycle_A: 0.600 idt_A: 0.287 D_B: 0.236 G_B: 0.255 cycle_B: 0.591 idt_B: 0.266 \n",
      "saving the latest model (epoch 61, total_iters 70000)\n",
      "(epoch: 61, iters: 600, time: 0.063, data: 0.001) D_A: 0.250 G_A: 0.374 cycle_A: 0.422 idt_A: 0.197 D_B: 0.258 G_B: 0.239 cycle_B: 0.414 idt_B: 0.182 \n",
      "(epoch: 61, iters: 800, time: 0.063, data: 0.002) D_A: 0.211 G_A: 0.313 cycle_A: 0.442 idt_A: 0.201 D_B: 0.240 G_B: 0.268 cycle_B: 0.413 idt_B: 0.190 \n",
      "(epoch: 61, iters: 1000, time: 0.063, data: 0.002) D_A: 0.226 G_A: 0.306 cycle_A: 0.461 idt_A: 0.200 D_B: 0.252 G_B: 0.235 cycle_B: 0.475 idt_B: 0.193 \n",
      "End of epoch 61 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 62, iters: 40, time: 0.104, data: 0.002) D_A: 0.222 G_A: 0.359 cycle_A: 0.427 idt_A: 0.221 D_B: 0.248 G_B: 0.259 cycle_B: 0.402 idt_B: 0.168 \n",
      "(epoch: 62, iters: 240, time: 0.063, data: 0.002) D_A: 0.188 G_A: 0.345 cycle_A: 0.551 idt_A: 0.321 D_B: 0.252 G_B: 0.272 cycle_B: 0.629 idt_B: 0.261 \n",
      "(epoch: 62, iters: 440, time: 0.063, data: 0.002) D_A: 0.240 G_A: 0.247 cycle_A: 0.618 idt_A: 0.283 D_B: 0.300 G_B: 0.258 cycle_B: 0.496 idt_B: 0.248 \n",
      "(epoch: 62, iters: 640, time: 0.063, data: 0.001) D_A: 0.213 G_A: 0.244 cycle_A: 0.446 idt_A: 0.236 D_B: 0.244 G_B: 0.254 cycle_B: 0.501 idt_B: 0.196 \n",
      "(epoch: 62, iters: 840, time: 0.063, data: 0.002) D_A: 0.216 G_A: 0.296 cycle_A: 0.589 idt_A: 0.335 D_B: 0.257 G_B: 0.245 cycle_B: 0.643 idt_B: 0.213 \n",
      "(epoch: 62, iters: 1040, time: 0.063, data: 0.001) D_A: 0.216 G_A: 0.310 cycle_A: 0.509 idt_A: 0.206 D_B: 0.263 G_B: 0.232 cycle_B: 0.452 idt_B: 0.200 \n",
      "End of epoch 62 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 63, iters: 80, time: 0.103, data: 0.002) D_A: 0.248 G_A: 0.415 cycle_A: 0.572 idt_A: 0.231 D_B: 0.250 G_B: 0.262 cycle_B: 0.439 idt_B: 0.201 \n",
      "(epoch: 63, iters: 280, time: 0.063, data: 0.001) D_A: 0.225 G_A: 0.345 cycle_A: 0.575 idt_A: 0.213 D_B: 0.246 G_B: 0.250 cycle_B: 0.448 idt_B: 0.225 \n",
      "(epoch: 63, iters: 480, time: 0.063, data: 0.001) D_A: 0.182 G_A: 0.332 cycle_A: 0.498 idt_A: 0.207 D_B: 0.251 G_B: 0.245 cycle_B: 0.486 idt_B: 0.183 \n",
      "(epoch: 63, iters: 680, time: 0.063, data: 0.002) D_A: 0.179 G_A: 0.309 cycle_A: 0.507 idt_A: 0.260 D_B: 0.250 G_B: 0.260 cycle_B: 0.559 idt_B: 0.175 \n",
      "(epoch: 63, iters: 880, time: 0.063, data: 0.002) D_A: 0.275 G_A: 0.100 cycle_A: 0.587 idt_A: 0.338 D_B: 0.253 G_B: 0.267 cycle_B: 0.727 idt_B: 0.245 \n",
      "(epoch: 63, iters: 1080, time: 0.063, data: 0.002) D_A: 0.191 G_A: 0.255 cycle_A: 0.488 idt_A: 0.150 D_B: 0.247 G_B: 0.270 cycle_B: 0.394 idt_B: 0.193 \n",
      "End of epoch 63 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 64, iters: 120, time: 0.103, data: 0.002) D_A: 0.257 G_A: 0.548 cycle_A: 0.586 idt_A: 0.261 D_B: 0.242 G_B: 0.288 cycle_B: 0.526 idt_B: 0.253 \n",
      "(epoch: 64, iters: 320, time: 0.063, data: 0.001) D_A: 0.210 G_A: 0.409 cycle_A: 0.539 idt_A: 0.205 D_B: 0.253 G_B: 0.261 cycle_B: 0.440 idt_B: 0.210 \n",
      "(epoch: 64, iters: 520, time: 0.063, data: 0.002) D_A: 0.198 G_A: 0.456 cycle_A: 0.561 idt_A: 0.230 D_B: 0.253 G_B: 0.324 cycle_B: 0.536 idt_B: 0.188 \n",
      "(epoch: 64, iters: 720, time: 0.063, data: 0.002) D_A: 0.204 G_A: 0.510 cycle_A: 0.594 idt_A: 0.233 D_B: 0.252 G_B: 0.234 cycle_B: 0.515 idt_B: 0.222 \n",
      "(epoch: 64, iters: 920, time: 0.106, data: 0.002) D_A: 0.236 G_A: 0.152 cycle_A: 0.560 idt_A: 0.204 D_B: 0.273 G_B: 0.257 cycle_B: 0.444 idt_B: 0.198 \n",
      "(epoch: 64, iters: 1120, time: 0.063, data: 0.001) D_A: 0.229 G_A: 0.197 cycle_A: 0.467 idt_A: 0.263 D_B: 0.245 G_B: 0.256 cycle_B: 0.533 idt_B: 0.211 \n",
      "End of epoch 64 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 65, iters: 160, time: 0.105, data: 0.002) D_A: 0.157 G_A: 0.331 cycle_A: 0.387 idt_A: 0.218 D_B: 0.235 G_B: 0.282 cycle_B: 0.466 idt_B: 0.165 \n",
      "(epoch: 65, iters: 360, time: 0.063, data: 0.001) D_A: 0.224 G_A: 0.276 cycle_A: 0.488 idt_A: 0.164 D_B: 0.238 G_B: 0.300 cycle_B: 0.384 idt_B: 0.179 \n",
      "(epoch: 65, iters: 560, time: 0.063, data: 0.002) D_A: 0.218 G_A: 0.712 cycle_A: 0.501 idt_A: 0.210 D_B: 0.241 G_B: 0.303 cycle_B: 0.425 idt_B: 0.192 \n",
      "(epoch: 65, iters: 760, time: 0.063, data: 0.002) D_A: 0.184 G_A: 0.263 cycle_A: 0.616 idt_A: 0.154 D_B: 0.253 G_B: 0.315 cycle_B: 0.360 idt_B: 0.246 \n",
      "saving the latest model (epoch 65, total_iters 75000)\n",
      "(epoch: 65, iters: 960, time: 0.063, data: 0.001) D_A: 0.256 G_A: 0.516 cycle_A: 0.425 idt_A: 0.205 D_B: 0.263 G_B: 0.248 cycle_B: 0.452 idt_B: 0.146 \n",
      "(epoch: 65, iters: 1160, time: 0.062, data: 0.001) D_A: 0.195 G_A: 0.123 cycle_A: 0.675 idt_A: 0.181 D_B: 0.267 G_B: 0.307 cycle_B: 0.467 idt_B: 0.223 \n",
      "saving the model at the end of epoch 65, iters 75400\n",
      "End of epoch 65 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 66, iters: 200, time: 0.106, data: 0.134) D_A: 0.190 G_A: 0.240 cycle_A: 0.760 idt_A: 0.261 D_B: 0.239 G_B: 0.294 cycle_B: 0.495 idt_B: 0.312 \n",
      "(epoch: 66, iters: 400, time: 0.063, data: 0.001) D_A: 0.261 G_A: 0.302 cycle_A: 0.468 idt_A: 0.279 D_B: 0.236 G_B: 0.237 cycle_B: 0.474 idt_B: 0.190 \n",
      "(epoch: 66, iters: 600, time: 0.103, data: 0.002) D_A: 0.197 G_A: 0.285 cycle_A: 0.733 idt_A: 0.259 D_B: 0.258 G_B: 0.265 cycle_B: 0.477 idt_B: 0.252 \n",
      "(epoch: 66, iters: 800, time: 0.063, data: 0.001) D_A: 0.230 G_A: 0.217 cycle_A: 0.599 idt_A: 0.242 D_B: 0.258 G_B: 0.223 cycle_B: 0.528 idt_B: 0.184 \n",
      "(epoch: 66, iters: 1000, time: 0.063, data: 0.002) D_A: 0.174 G_A: 0.466 cycle_A: 0.442 idt_A: 0.209 D_B: 0.273 G_B: 0.354 cycle_B: 0.393 idt_B: 0.184 \n",
      "End of epoch 66 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 67, iters: 40, time: 0.063, data: 0.001) D_A: 0.198 G_A: 0.283 cycle_A: 0.456 idt_A: 0.194 D_B: 0.271 G_B: 0.271 cycle_B: 0.438 idt_B: 0.207 \n",
      "(epoch: 67, iters: 240, time: 0.106, data: 0.001) D_A: 0.185 G_A: 0.325 cycle_A: 0.417 idt_A: 0.249 D_B: 0.239 G_B: 0.281 cycle_B: 0.495 idt_B: 0.144 \n",
      "(epoch: 67, iters: 440, time: 0.063, data: 0.001) D_A: 0.183 G_A: 0.213 cycle_A: 0.513 idt_A: 0.159 D_B: 0.284 G_B: 0.254 cycle_B: 0.405 idt_B: 0.174 \n",
      "(epoch: 67, iters: 640, time: 0.063, data: 0.002) D_A: 0.312 G_A: 0.804 cycle_A: 0.530 idt_A: 0.183 D_B: 0.239 G_B: 0.260 cycle_B: 0.447 idt_B: 0.204 \n",
      "(epoch: 67, iters: 840, time: 0.063, data: 0.001) D_A: 0.219 G_A: 0.232 cycle_A: 0.515 idt_A: 0.203 D_B: 0.236 G_B: 0.277 cycle_B: 0.401 idt_B: 0.191 \n",
      "(epoch: 67, iters: 1040, time: 0.063, data: 0.002) D_A: 0.221 G_A: 0.162 cycle_A: 0.498 idt_A: 0.195 D_B: 0.253 G_B: 0.257 cycle_B: 0.457 idt_B: 0.215 \n",
      "End of epoch 67 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 68, iters: 80, time: 0.063, data: 0.002) D_A: 0.269 G_A: 0.153 cycle_A: 0.505 idt_A: 0.205 D_B: 0.254 G_B: 0.326 cycle_B: 0.483 idt_B: 0.190 \n",
      "(epoch: 68, iters: 280, time: 0.106, data: 0.001) D_A: 0.206 G_A: 0.376 cycle_A: 0.479 idt_A: 0.210 D_B: 0.273 G_B: 0.264 cycle_B: 0.428 idt_B: 0.204 \n",
      "(epoch: 68, iters: 480, time: 0.062, data: 0.001) D_A: 0.186 G_A: 0.281 cycle_A: 0.596 idt_A: 0.196 D_B: 0.238 G_B: 0.321 cycle_B: 0.393 idt_B: 0.221 \n",
      "(epoch: 68, iters: 680, time: 0.063, data: 0.001) D_A: 0.278 G_A: 0.328 cycle_A: 0.475 idt_A: 0.155 D_B: 0.243 G_B: 0.218 cycle_B: 0.363 idt_B: 0.149 \n",
      "(epoch: 68, iters: 880, time: 0.063, data: 0.002) D_A: 0.194 G_A: 0.271 cycle_A: 0.476 idt_A: 0.223 D_B: 0.298 G_B: 0.333 cycle_B: 0.513 idt_B: 0.189 \n",
      "(epoch: 68, iters: 1080, time: 0.063, data: 0.001) D_A: 0.162 G_A: 0.552 cycle_A: 0.441 idt_A: 0.224 D_B: 0.233 G_B: 0.258 cycle_B: 0.414 idt_B: 0.158 \n",
      "End of epoch 68 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 69, iters: 120, time: 0.063, data: 0.002) D_A: 0.265 G_A: 0.092 cycle_A: 0.555 idt_A: 0.183 D_B: 0.243 G_B: 0.305 cycle_B: 0.399 idt_B: 0.195 \n",
      "(epoch: 69, iters: 320, time: 0.105, data: 0.002) D_A: 0.175 G_A: 0.328 cycle_A: 0.506 idt_A: 0.200 D_B: 0.255 G_B: 0.296 cycle_B: 0.408 idt_B: 0.164 \n",
      "(epoch: 69, iters: 520, time: 0.063, data: 0.001) D_A: 0.183 G_A: 0.304 cycle_A: 0.467 idt_A: 0.182 D_B: 0.252 G_B: 0.285 cycle_B: 0.412 idt_B: 0.161 \n",
      "(epoch: 69, iters: 720, time: 0.063, data: 0.002) D_A: 0.212 G_A: 0.311 cycle_A: 0.569 idt_A: 0.165 D_B: 0.247 G_B: 0.345 cycle_B: 0.384 idt_B: 0.197 \n",
      "(epoch: 69, iters: 920, time: 0.063, data: 0.001) D_A: 0.195 G_A: 0.214 cycle_A: 0.544 idt_A: 0.231 D_B: 0.233 G_B: 0.257 cycle_B: 0.472 idt_B: 0.185 \n",
      "(epoch: 69, iters: 1120, time: 0.107, data: 0.002) D_A: 0.193 G_A: 0.277 cycle_A: 0.593 idt_A: 0.192 D_B: 0.256 G_B: 0.331 cycle_B: 0.489 idt_B: 0.241 \n",
      "saving the latest model (epoch 69, total_iters 80000)\n",
      "End of epoch 69 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 70, iters: 160, time: 0.063, data: 0.001) D_A: 0.173 G_A: 0.347 cycle_A: 0.478 idt_A: 0.305 D_B: 0.220 G_B: 0.268 cycle_B: 0.585 idt_B: 0.181 \n",
      "(epoch: 70, iters: 360, time: 0.107, data: 0.002) D_A: 0.503 G_A: 0.825 cycle_A: 0.630 idt_A: 0.210 D_B: 0.248 G_B: 0.308 cycle_B: 0.537 idt_B: 0.160 \n",
      "(epoch: 70, iters: 560, time: 0.062, data: 0.002) D_A: 0.249 G_A: 0.271 cycle_A: 0.546 idt_A: 0.327 D_B: 0.276 G_B: 0.244 cycle_B: 0.661 idt_B: 0.167 \n",
      "(epoch: 70, iters: 760, time: 0.063, data: 0.001) D_A: 0.252 G_A: 0.276 cycle_A: 0.550 idt_A: 0.258 D_B: 0.244 G_B: 0.536 cycle_B: 0.581 idt_B: 0.218 \n",
      "(epoch: 70, iters: 960, time: 0.062, data: 0.002) D_A: 0.265 G_A: 0.261 cycle_A: 0.626 idt_A: 0.167 D_B: 0.247 G_B: 0.276 cycle_B: 0.396 idt_B: 0.231 \n",
      "(epoch: 70, iters: 1160, time: 0.063, data: 0.002) D_A: 0.258 G_A: 0.260 cycle_A: 0.461 idt_A: 0.198 D_B: 0.212 G_B: 0.384 cycle_B: 0.512 idt_B: 0.220 \n",
      "saving the model at the end of epoch 70, iters 81200\n",
      "End of epoch 70 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 71, iters: 200, time: 0.063, data: 0.119) D_A: 0.243 G_A: 0.268 cycle_A: 0.535 idt_A: 0.212 D_B: 0.274 G_B: 0.381 cycle_B: 0.472 idt_B: 0.202 \n",
      "(epoch: 71, iters: 400, time: 0.120, data: 0.002) D_A: 0.251 G_A: 0.252 cycle_A: 0.495 idt_A: 0.183 D_B: 0.239 G_B: 0.283 cycle_B: 0.423 idt_B: 0.201 \n",
      "(epoch: 71, iters: 600, time: 0.063, data: 0.001) D_A: 0.254 G_A: 0.273 cycle_A: 0.539 idt_A: 0.243 D_B: 0.239 G_B: 0.243 cycle_B: 0.427 idt_B: 0.243 \n",
      "(epoch: 71, iters: 800, time: 0.107, data: 0.001) D_A: 0.249 G_A: 0.257 cycle_A: 0.414 idt_A: 0.195 D_B: 0.211 G_B: 0.344 cycle_B: 0.451 idt_B: 0.182 \n",
      "(epoch: 71, iters: 1000, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.256 cycle_A: 0.478 idt_A: 0.241 D_B: 0.237 G_B: 0.302 cycle_B: 0.449 idt_B: 0.192 \n",
      "End of epoch 71 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 72, iters: 40, time: 0.107, data: 0.002) D_A: 0.256 G_A: 0.252 cycle_A: 0.414 idt_A: 0.194 D_B: 0.251 G_B: 0.408 cycle_B: 0.464 idt_B: 0.183 \n",
      "(epoch: 72, iters: 240, time: 0.063, data: 0.002) D_A: 0.256 G_A: 0.253 cycle_A: 0.479 idt_A: 0.212 D_B: 0.294 G_B: 0.166 cycle_B: 0.482 idt_B: 0.261 \n",
      "(epoch: 72, iters: 440, time: 0.063, data: 0.002) D_A: 0.255 G_A: 0.247 cycle_A: 0.405 idt_A: 0.187 D_B: 0.264 G_B: 0.398 cycle_B: 0.443 idt_B: 0.176 \n",
      "(epoch: 72, iters: 640, time: 0.063, data: 0.002) D_A: 0.248 G_A: 0.253 cycle_A: 0.448 idt_A: 0.231 D_B: 0.235 G_B: 0.309 cycle_B: 0.653 idt_B: 0.184 \n",
      "(epoch: 72, iters: 840, time: 0.063, data: 0.001) D_A: 0.256 G_A: 0.241 cycle_A: 0.559 idt_A: 0.214 D_B: 0.263 G_B: 0.339 cycle_B: 0.555 idt_B: 0.211 \n",
      "(epoch: 72, iters: 1040, time: 0.063, data: 0.002) D_A: 0.254 G_A: 0.249 cycle_A: 0.409 idt_A: 0.171 D_B: 0.236 G_B: 0.293 cycle_B: 0.404 idt_B: 0.189 \n",
      "End of epoch 72 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 73, iters: 80, time: 0.107, data: 0.002) D_A: 0.254 G_A: 0.254 cycle_A: 0.553 idt_A: 0.166 D_B: 0.233 G_B: 0.276 cycle_B: 0.512 idt_B: 0.178 \n",
      "(epoch: 73, iters: 280, time: 0.063, data: 0.001) D_A: 0.251 G_A: 0.250 cycle_A: 0.369 idt_A: 0.189 D_B: 0.221 G_B: 0.343 cycle_B: 0.385 idt_B: 0.168 \n",
      "(epoch: 73, iters: 480, time: 0.107, data: 0.002) D_A: 0.249 G_A: 0.257 cycle_A: 0.454 idt_A: 0.163 D_B: 0.223 G_B: 0.264 cycle_B: 0.469 idt_B: 0.196 \n",
      "(epoch: 73, iters: 680, time: 0.063, data: 0.002) D_A: 0.254 G_A: 0.263 cycle_A: 0.468 idt_A: 0.289 D_B: 0.240 G_B: 0.288 cycle_B: 0.703 idt_B: 0.182 \n",
      "(epoch: 73, iters: 880, time: 0.063, data: 0.001) D_A: 0.249 G_A: 0.263 cycle_A: 0.448 idt_A: 0.265 D_B: 0.230 G_B: 0.286 cycle_B: 0.507 idt_B: 0.214 \n",
      "(epoch: 73, iters: 1080, time: 0.063, data: 0.002) D_A: 0.251 G_A: 0.249 cycle_A: 0.539 idt_A: 0.210 D_B: 0.265 G_B: 0.198 cycle_B: 0.491 idt_B: 0.220 \n",
      "End of epoch 73 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 74, iters: 120, time: 0.108, data: 0.002) D_A: 0.246 G_A: 0.262 cycle_A: 0.486 idt_A: 0.260 D_B: 0.227 G_B: 0.380 cycle_B: 0.540 idt_B: 0.205 \n",
      "(epoch: 74, iters: 320, time: 0.062, data: 0.002) D_A: 0.254 G_A: 0.257 cycle_A: 0.452 idt_A: 0.191 D_B: 0.226 G_B: 0.337 cycle_B: 0.395 idt_B: 0.218 \n",
      "saving the latest model (epoch 74, total_iters 85000)\n",
      "(epoch: 74, iters: 520, time: 0.063, data: 0.003) D_A: 0.253 G_A: 0.251 cycle_A: 0.377 idt_A: 0.288 D_B: 0.275 G_B: 0.540 cycle_B: 0.576 idt_B: 0.168 \n",
      "(epoch: 74, iters: 720, time: 0.063, data: 0.002) D_A: 0.251 G_A: 0.262 cycle_A: 0.572 idt_A: 0.231 D_B: 0.246 G_B: 0.372 cycle_B: 0.425 idt_B: 0.288 \n",
      "(epoch: 74, iters: 920, time: 0.063, data: 0.002) D_A: 0.254 G_A: 0.270 cycle_A: 0.466 idt_A: 0.179 D_B: 0.260 G_B: 0.329 cycle_B: 0.461 idt_B: 0.203 \n",
      "(epoch: 74, iters: 1120, time: 0.063, data: 0.002) D_A: 0.253 G_A: 0.256 cycle_A: 0.549 idt_A: 0.220 D_B: 0.218 G_B: 0.344 cycle_B: 0.430 idt_B: 0.218 \n",
      "End of epoch 74 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 75, iters: 160, time: 0.109, data: 0.001) D_A: 0.246 G_A: 0.258 cycle_A: 0.462 idt_A: 0.149 D_B: 0.224 G_B: 0.209 cycle_B: 0.444 idt_B: 0.210 \n",
      "(epoch: 75, iters: 360, time: 0.062, data: 0.001) D_A: 0.261 G_A: 0.236 cycle_A: 0.492 idt_A: 0.201 D_B: 0.215 G_B: 0.451 cycle_B: 0.502 idt_B: 0.231 \n",
      "(epoch: 75, iters: 560, time: 0.063, data: 0.002) D_A: 0.253 G_A: 0.267 cycle_A: 0.578 idt_A: 0.205 D_B: 0.210 G_B: 0.286 cycle_B: 0.528 idt_B: 0.218 \n",
      "(epoch: 75, iters: 760, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.269 cycle_A: 0.521 idt_A: 0.191 D_B: 0.226 G_B: 0.448 cycle_B: 0.509 idt_B: 0.245 \n",
      "(epoch: 75, iters: 960, time: 0.063, data: 0.001) D_A: 0.250 G_A: 0.274 cycle_A: 0.491 idt_A: 0.323 D_B: 0.199 G_B: 0.318 cycle_B: 0.625 idt_B: 0.181 \n",
      "(epoch: 75, iters: 1160, time: 0.063, data: 0.001) D_A: 0.253 G_A: 0.245 cycle_A: 0.429 idt_A: 0.238 D_B: 0.212 G_B: 0.367 cycle_B: 0.534 idt_B: 0.163 \n",
      "saving the model at the end of epoch 75, iters 87000\n",
      "End of epoch 75 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 76, iters: 200, time: 0.108, data: 0.101) D_A: 0.249 G_A: 0.256 cycle_A: 0.401 idt_A: 0.226 D_B: 0.205 G_B: 0.349 cycle_B: 0.461 idt_B: 0.187 \n",
      "(epoch: 76, iters: 400, time: 0.063, data: 0.002) D_A: 0.260 G_A: 0.303 cycle_A: 0.334 idt_A: 0.192 D_B: 0.293 G_B: 0.122 cycle_B: 0.493 idt_B: 0.133 \n",
      "(epoch: 76, iters: 600, time: 0.062, data: 0.002) D_A: 0.254 G_A: 0.255 cycle_A: 0.390 idt_A: 0.181 D_B: 0.191 G_B: 0.301 cycle_B: 0.379 idt_B: 0.152 \n",
      "(epoch: 76, iters: 800, time: 0.063, data: 0.001) D_A: 0.252 G_A: 0.255 cycle_A: 0.422 idt_A: 0.197 D_B: 0.228 G_B: 0.354 cycle_B: 0.546 idt_B: 0.212 \n",
      "(epoch: 76, iters: 1000, time: 0.109, data: 0.001) D_A: 0.275 G_A: 0.317 cycle_A: 0.506 idt_A: 0.207 D_B: 0.181 G_B: 0.336 cycle_B: 0.529 idt_B: 0.255 \n",
      "End of epoch 76 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 77, iters: 40, time: 0.063, data: 0.001) D_A: 0.253 G_A: 0.252 cycle_A: 0.531 idt_A: 0.189 D_B: 0.229 G_B: 0.295 cycle_B: 0.466 idt_B: 0.208 \n",
      "(epoch: 77, iters: 240, time: 0.110, data: 0.002) D_A: 0.251 G_A: 0.284 cycle_A: 0.466 idt_A: 0.167 D_B: 0.202 G_B: 0.383 cycle_B: 0.373 idt_B: 0.185 \n",
      "(epoch: 77, iters: 440, time: 0.063, data: 0.002) D_A: 0.250 G_A: 0.248 cycle_A: 0.418 idt_A: 0.194 D_B: 0.222 G_B: 0.327 cycle_B: 0.434 idt_B: 0.167 \n",
      "(epoch: 77, iters: 640, time: 0.063, data: 0.002) D_A: 0.262 G_A: 0.248 cycle_A: 0.402 idt_A: 0.177 D_B: 0.214 G_B: 0.235 cycle_B: 0.458 idt_B: 0.212 \n",
      "(epoch: 77, iters: 840, time: 0.063, data: 0.002) D_A: 0.248 G_A: 0.264 cycle_A: 0.379 idt_A: 0.201 D_B: 0.194 G_B: 0.460 cycle_B: 0.476 idt_B: 0.178 \n",
      "(epoch: 77, iters: 1040, time: 0.063, data: 0.002) D_A: 0.252 G_A: 0.254 cycle_A: 0.385 idt_A: 0.183 D_B: 0.288 G_B: 0.458 cycle_B: 0.416 idt_B: 0.163 \n",
      "End of epoch 77 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 78, iters: 80, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.248 cycle_A: 0.446 idt_A: 0.190 D_B: 0.173 G_B: 0.391 cycle_B: 0.450 idt_B: 0.175 \n",
      "(epoch: 78, iters: 280, time: 0.109, data: 0.001) D_A: 0.294 G_A: 0.326 cycle_A: 0.362 idt_A: 0.217 D_B: 0.247 G_B: 0.393 cycle_B: 0.459 idt_B: 0.143 \n",
      "(epoch: 78, iters: 480, time: 0.063, data: 0.001) D_A: 0.247 G_A: 0.235 cycle_A: 0.592 idt_A: 0.189 D_B: 0.231 G_B: 0.572 cycle_B: 0.483 idt_B: 0.252 \n",
      "(epoch: 78, iters: 680, time: 0.109, data: 0.002) D_A: 0.249 G_A: 0.254 cycle_A: 0.391 idt_A: 0.282 D_B: 0.233 G_B: 0.598 cycle_B: 0.634 idt_B: 0.170 \n",
      "saving the latest model (epoch 78, total_iters 90000)\n",
      "(epoch: 78, iters: 880, time: 0.063, data: 0.001) D_A: 0.259 G_A: 0.273 cycle_A: 0.416 idt_A: 0.179 D_B: 0.221 G_B: 0.324 cycle_B: 0.489 idt_B: 0.217 \n",
      "(epoch: 78, iters: 1080, time: 0.063, data: 0.002) D_A: 0.250 G_A: 0.261 cycle_A: 0.371 idt_A: 0.239 D_B: 0.255 G_B: 0.437 cycle_B: 0.471 idt_B: 0.174 \n",
      "End of epoch 78 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 79, iters: 120, time: 0.063, data: 0.002) D_A: 0.259 G_A: 0.250 cycle_A: 0.412 idt_A: 0.161 D_B: 0.330 G_B: 0.127 cycle_B: 0.400 idt_B: 0.170 \n",
      "(epoch: 79, iters: 320, time: 0.109, data: 0.002) D_A: 0.251 G_A: 0.263 cycle_A: 0.374 idt_A: 0.186 D_B: 0.196 G_B: 0.276 cycle_B: 0.415 idt_B: 0.182 \n",
      "(epoch: 79, iters: 520, time: 0.063, data: 0.001) D_A: 0.252 G_A: 0.256 cycle_A: 0.441 idt_A: 0.259 D_B: 0.184 G_B: 0.425 cycle_B: 0.673 idt_B: 0.189 \n",
      "(epoch: 79, iters: 720, time: 0.063, data: 0.002) D_A: 0.252 G_A: 0.238 cycle_A: 0.406 idt_A: 0.137 D_B: 0.213 G_B: 0.465 cycle_B: 0.380 idt_B: 0.186 \n",
      "(epoch: 79, iters: 920, time: 0.063, data: 0.002) D_A: 0.272 G_A: 0.290 cycle_A: 0.421 idt_A: 0.173 D_B: 0.187 G_B: 0.293 cycle_B: 0.447 idt_B: 0.180 \n",
      "(epoch: 79, iters: 1120, time: 0.063, data: 0.001) D_A: 0.263 G_A: 0.234 cycle_A: 0.401 idt_A: 0.155 D_B: 0.212 G_B: 0.301 cycle_B: 0.443 idt_B: 0.206 \n",
      "End of epoch 79 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 80, iters: 160, time: 0.063, data: 0.002) D_A: 0.251 G_A: 0.238 cycle_A: 0.408 idt_A: 0.171 D_B: 0.188 G_B: 0.381 cycle_B: 0.440 idt_B: 0.197 \n",
      "(epoch: 80, iters: 360, time: 0.110, data: 0.002) D_A: 0.250 G_A: 0.274 cycle_A: 0.539 idt_A: 0.184 D_B: 1.919 G_B: 1.889 cycle_B: 0.676 idt_B: 0.280 \n",
      "(epoch: 80, iters: 560, time: 0.062, data: 0.002) D_A: 0.249 G_A: 0.249 cycle_A: 0.375 idt_A: 0.209 D_B: 0.286 G_B: 0.257 cycle_B: 0.504 idt_B: 0.166 \n",
      "(epoch: 80, iters: 760, time: 0.063, data: 0.002) D_A: 0.266 G_A: 0.279 cycle_A: 0.632 idt_A: 0.287 D_B: 0.239 G_B: 0.259 cycle_B: 0.536 idt_B: 0.238 \n",
      "(epoch: 80, iters: 960, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.251 cycle_A: 0.445 idt_A: 0.282 D_B: 0.243 G_B: 0.289 cycle_B: 0.513 idt_B: 0.178 \n",
      "(epoch: 80, iters: 1160, time: 0.063, data: 0.002) D_A: 0.250 G_A: 0.264 cycle_A: 0.442 idt_A: 0.151 D_B: 0.223 G_B: 0.271 cycle_B: 0.373 idt_B: 0.165 \n",
      "saving the model at the end of epoch 80, iters 92800\n",
      "End of epoch 80 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 81, iters: 200, time: 0.063, data: 0.103) D_A: 0.244 G_A: 0.254 cycle_A: 0.391 idt_A: 0.175 D_B: 0.237 G_B: 0.341 cycle_B: 0.403 idt_B: 0.155 \n",
      "(epoch: 81, iters: 400, time: 0.120, data: 0.002) D_A: 0.274 G_A: 0.293 cycle_A: 0.490 idt_A: 0.278 D_B: 0.231 G_B: 0.272 cycle_B: 0.570 idt_B: 0.180 \n",
      "(epoch: 81, iters: 600, time: 0.063, data: 0.001) D_A: 0.253 G_A: 0.264 cycle_A: 0.413 idt_A: 0.256 D_B: 0.201 G_B: 0.316 cycle_B: 0.617 idt_B: 0.168 \n",
      "(epoch: 81, iters: 800, time: 0.063, data: 0.002) D_A: 0.253 G_A: 0.259 cycle_A: 0.368 idt_A: 0.174 D_B: 0.215 G_B: 0.296 cycle_B: 0.430 idt_B: 0.167 \n",
      "(epoch: 81, iters: 1000, time: 0.063, data: 0.002) D_A: 0.256 G_A: 0.287 cycle_A: 0.397 idt_A: 0.152 D_B: 0.202 G_B: 0.287 cycle_B: 0.426 idt_B: 0.172 \n",
      "End of epoch 81 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 82, iters: 40, time: 0.111, data: 0.002) D_A: 0.290 G_A: 0.274 cycle_A: 0.361 idt_A: 0.209 D_B: 0.166 G_B: 0.280 cycle_B: 0.446 idt_B: 0.162 \n",
      "(epoch: 82, iters: 240, time: 0.063, data: 0.002) D_A: 0.243 G_A: 0.243 cycle_A: 0.422 idt_A: 0.227 D_B: 0.211 G_B: 0.244 cycle_B: 0.509 idt_B: 0.194 \n",
      "(epoch: 82, iters: 440, time: 0.063, data: 0.001) D_A: 0.253 G_A: 0.258 cycle_A: 0.367 idt_A: 0.191 D_B: 0.200 G_B: 0.331 cycle_B: 0.453 idt_B: 0.166 \n",
      "(epoch: 82, iters: 640, time: 0.063, data: 0.002) D_A: 0.254 G_A: 0.272 cycle_A: 0.616 idt_A: 0.232 D_B: 0.165 G_B: 0.330 cycle_B: 0.585 idt_B: 0.277 \n",
      "(epoch: 82, iters: 840, time: 0.062, data: 0.002) D_A: 0.250 G_A: 0.272 cycle_A: 0.477 idt_A: 0.315 D_B: 0.229 G_B: 0.330 cycle_B: 0.686 idt_B: 0.254 \n",
      "(epoch: 82, iters: 1040, time: 0.063, data: 0.001) D_A: 0.291 G_A: 0.330 cycle_A: 0.464 idt_A: 0.340 D_B: 0.213 G_B: 0.392 cycle_B: 0.640 idt_B: 0.205 \n",
      "saving the latest model (epoch 82, total_iters 95000)\n",
      "End of epoch 82 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 83, iters: 80, time: 0.111, data: 0.002) D_A: 0.248 G_A: 0.270 cycle_A: 0.428 idt_A: 0.207 D_B: 0.225 G_B: 0.553 cycle_B: 0.515 idt_B: 0.213 \n",
      "(epoch: 83, iters: 280, time: 0.063, data: 0.002) D_A: 0.304 G_A: 0.325 cycle_A: 0.431 idt_A: 0.218 D_B: 0.248 G_B: 0.264 cycle_B: 0.498 idt_B: 0.193 \n",
      "(epoch: 83, iters: 480, time: 0.063, data: 0.002) D_A: 0.250 G_A: 0.266 cycle_A: 0.597 idt_A: 0.213 D_B: 0.248 G_B: 0.528 cycle_B: 0.549 idt_B: 0.263 \n",
      "(epoch: 83, iters: 680, time: 0.063, data: 0.002) D_A: 0.277 G_A: 0.251 cycle_A: 0.401 idt_A: 0.173 D_B: 0.158 G_B: 0.308 cycle_B: 0.369 idt_B: 0.181 \n",
      "(epoch: 83, iters: 880, time: 0.109, data: 0.001) D_A: 0.254 G_A: 0.283 cycle_A: 0.386 idt_A: 0.143 D_B: 0.245 G_B: 0.209 cycle_B: 0.369 idt_B: 0.164 \n",
      "(epoch: 83, iters: 1080, time: 0.063, data: 0.001) D_A: 0.252 G_A: 0.251 cycle_A: 0.417 idt_A: 0.174 D_B: 0.215 G_B: 0.322 cycle_B: 0.396 idt_B: 0.202 \n",
      "End of epoch 83 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 84, iters: 120, time: 0.110, data: 0.002) D_A: 0.273 G_A: 0.295 cycle_A: 0.409 idt_A: 0.259 D_B: 0.227 G_B: 0.210 cycle_B: 0.478 idt_B: 0.193 \n",
      "(epoch: 84, iters: 320, time: 0.063, data: 0.002) D_A: 0.257 G_A: 0.246 cycle_A: 0.382 idt_A: 0.155 D_B: 0.200 G_B: 0.287 cycle_B: 0.394 idt_B: 0.161 \n",
      "(epoch: 84, iters: 520, time: 0.063, data: 0.002) D_A: 0.259 G_A: 0.259 cycle_A: 0.420 idt_A: 0.210 D_B: 0.257 G_B: 0.452 cycle_B: 0.425 idt_B: 0.215 \n",
      "(epoch: 84, iters: 720, time: 0.063, data: 0.002) D_A: 0.248 G_A: 0.272 cycle_A: 0.380 idt_A: 0.194 D_B: 0.168 G_B: 0.386 cycle_B: 0.415 idt_B: 0.130 \n",
      "(epoch: 84, iters: 920, time: 0.063, data: 0.002) D_A: 0.259 G_A: 0.271 cycle_A: 0.415 idt_A: 0.159 D_B: 0.220 G_B: 0.355 cycle_B: 0.447 idt_B: 0.172 \n",
      "(epoch: 84, iters: 1120, time: 0.063, data: 0.002) D_A: 0.260 G_A: 0.248 cycle_A: 0.444 idt_A: 0.172 D_B: 0.219 G_B: 0.249 cycle_B: 0.506 idt_B: 0.221 \n",
      "End of epoch 84 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 85, iters: 160, time: 0.111, data: 0.001) D_A: 0.266 G_A: 0.328 cycle_A: 0.448 idt_A: 0.142 D_B: 0.212 G_B: 0.571 cycle_B: 0.470 idt_B: 0.188 \n",
      "(epoch: 85, iters: 360, time: 0.063, data: 0.001) D_A: 0.251 G_A: 0.258 cycle_A: 0.356 idt_A: 0.184 D_B: 0.220 G_B: 0.490 cycle_B: 0.472 idt_B: 0.166 \n",
      "(epoch: 85, iters: 560, time: 0.111, data: 0.002) D_A: 0.245 G_A: 0.258 cycle_A: 0.372 idt_A: 0.225 D_B: 0.209 G_B: 0.420 cycle_B: 0.542 idt_B: 0.161 \n",
      "(epoch: 85, iters: 760, time: 0.063, data: 0.002) D_A: 0.264 G_A: 0.258 cycle_A: 0.378 idt_A: 0.215 D_B: 0.176 G_B: 0.514 cycle_B: 0.616 idt_B: 0.158 \n",
      "(epoch: 85, iters: 960, time: 0.063, data: 0.001) D_A: 0.241 G_A: 0.286 cycle_A: 0.364 idt_A: 0.196 D_B: 0.193 G_B: 0.321 cycle_B: 0.477 idt_B: 0.168 \n",
      "(epoch: 85, iters: 1160, time: 0.063, data: 0.002) D_A: 0.266 G_A: 0.296 cycle_A: 0.379 idt_A: 0.188 D_B: 0.197 G_B: 0.377 cycle_B: 0.471 idt_B: 0.182 \n",
      "saving the model at the end of epoch 85, iters 98600\n",
      "End of epoch 85 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 86, iters: 200, time: 0.112, data: 0.085) D_A: 0.252 G_A: 0.251 cycle_A: 1.060 idt_A: 0.299 D_B: 0.228 G_B: 0.476 cycle_B: 0.705 idt_B: 0.345 \n",
      "(epoch: 86, iters: 400, time: 0.062, data: 0.001) D_A: 0.245 G_A: 0.235 cycle_A: 0.602 idt_A: 0.215 D_B: 0.182 G_B: 0.309 cycle_B: 0.613 idt_B: 0.253 \n",
      "(epoch: 86, iters: 600, time: 0.062, data: 0.002) D_A: 0.325 G_A: 0.346 cycle_A: 0.514 idt_A: 0.169 D_B: 0.257 G_B: 0.385 cycle_B: 0.460 idt_B: 0.243 \n",
      "(epoch: 86, iters: 800, time: 0.063, data: 0.002) D_A: 0.253 G_A: 0.254 cycle_A: 0.571 idt_A: 0.178 D_B: 0.244 G_B: 0.201 cycle_B: 0.517 idt_B: 0.237 \n",
      "(epoch: 86, iters: 1000, time: 0.063, data: 0.002) D_A: 0.248 G_A: 0.238 cycle_A: 0.384 idt_A: 0.230 D_B: 0.183 G_B: 0.274 cycle_B: 0.586 idt_B: 0.179 \n",
      "End of epoch 86 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 87, iters: 40, time: 0.063, data: 0.002) D_A: 0.258 G_A: 0.249 cycle_A: 0.444 idt_A: 0.191 D_B: 0.217 G_B: 0.223 cycle_B: 0.487 idt_B: 0.211 \n",
      "(epoch: 87, iters: 240, time: 0.112, data: 0.002) D_A: 0.288 G_A: 0.273 cycle_A: 0.430 idt_A: 0.153 D_B: 0.194 G_B: 0.170 cycle_B: 0.394 idt_B: 0.185 \n",
      "saving the latest model (epoch 87, total_iters 100000)\n",
      "(epoch: 87, iters: 440, time: 0.063, data: 0.001) D_A: 0.253 G_A: 0.291 cycle_A: 0.342 idt_A: 0.145 D_B: 0.216 G_B: 0.321 cycle_B: 0.422 idt_B: 0.159 \n",
      "(epoch: 87, iters: 640, time: 0.063, data: 0.002) D_A: 0.242 G_A: 0.251 cycle_A: 0.413 idt_A: 0.211 D_B: 0.209 G_B: 0.464 cycle_B: 0.542 idt_B: 0.174 \n",
      "(epoch: 87, iters: 840, time: 0.063, data: 0.002) D_A: 0.264 G_A: 0.292 cycle_A: 0.357 idt_A: 0.167 D_B: 0.159 G_B: 0.286 cycle_B: 0.598 idt_B: 0.157 \n",
      "(epoch: 87, iters: 1040, time: 0.063, data: 0.002) D_A: 0.241 G_A: 0.279 cycle_A: 0.478 idt_A: 0.154 D_B: 0.159 G_B: 0.348 cycle_B: 0.550 idt_B: 0.190 \n",
      "End of epoch 87 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 88, iters: 80, time: 0.063, data: 0.002) D_A: 0.250 G_A: 0.269 cycle_A: 0.368 idt_A: 0.159 D_B: 0.328 G_B: 0.084 cycle_B: 0.450 idt_B: 0.168 \n",
      "(epoch: 88, iters: 280, time: 0.111, data: 0.002) D_A: 0.333 G_A: 0.298 cycle_A: 0.449 idt_A: 0.202 D_B: 0.222 G_B: 0.372 cycle_B: 0.583 idt_B: 0.198 \n",
      "(epoch: 88, iters: 480, time: 0.063, data: 0.001) D_A: 0.249 G_A: 0.267 cycle_A: 0.417 idt_A: 0.179 D_B: 0.248 G_B: 0.199 cycle_B: 0.495 idt_B: 0.206 \n",
      "(epoch: 88, iters: 680, time: 0.062, data: 0.001) D_A: 0.245 G_A: 0.275 cycle_A: 0.469 idt_A: 0.220 D_B: 0.235 G_B: 0.411 cycle_B: 0.493 idt_B: 0.192 \n",
      "(epoch: 88, iters: 880, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.267 cycle_A: 0.434 idt_A: 0.164 D_B: 0.167 G_B: 0.256 cycle_B: 0.457 idt_B: 0.200 \n",
      "(epoch: 88, iters: 1080, time: 0.112, data: 0.002) D_A: 0.247 G_A: 0.284 cycle_A: 0.514 idt_A: 0.254 D_B: 0.183 G_B: 0.416 cycle_B: 0.533 idt_B: 0.205 \n",
      "End of epoch 88 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 89, iters: 120, time: 0.063, data: 0.002) D_A: 0.260 G_A: 0.266 cycle_A: 0.365 idt_A: 0.193 D_B: 0.304 G_B: 0.426 cycle_B: 0.509 idt_B: 0.170 \n",
      "(epoch: 89, iters: 320, time: 0.111, data: 0.002) D_A: 0.253 G_A: 0.272 cycle_A: 0.421 idt_A: 0.210 D_B: 0.211 G_B: 0.397 cycle_B: 0.506 idt_B: 0.200 \n",
      "(epoch: 89, iters: 520, time: 0.063, data: 0.001) D_A: 0.246 G_A: 0.288 cycle_A: 0.384 idt_A: 0.155 D_B: 0.172 G_B: 0.326 cycle_B: 0.473 idt_B: 0.203 \n",
      "(epoch: 89, iters: 720, time: 0.063, data: 0.002) D_A: 0.249 G_A: 0.253 cycle_A: 0.334 idt_A: 0.182 D_B: 0.217 G_B: 0.321 cycle_B: 0.714 idt_B: 0.141 \n",
      "(epoch: 89, iters: 920, time: 0.063, data: 0.002) D_A: 0.257 G_A: 0.304 cycle_A: 0.298 idt_A: 0.190 D_B: 0.216 G_B: 0.291 cycle_B: 0.395 idt_B: 0.121 \n",
      "(epoch: 89, iters: 1120, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.259 cycle_A: 0.650 idt_A: 0.215 D_B: 0.269 G_B: 0.776 cycle_B: 0.595 idt_B: 0.336 \n",
      "End of epoch 89 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 90, iters: 160, time: 0.063, data: 0.001) D_A: 0.264 G_A: 0.277 cycle_A: 0.366 idt_A: 0.203 D_B: 0.216 G_B: 0.402 cycle_B: 0.559 idt_B: 0.177 \n",
      "(epoch: 90, iters: 360, time: 0.112, data: 0.002) D_A: 0.274 G_A: 0.269 cycle_A: 0.441 idt_A: 0.190 D_B: 0.295 G_B: 0.077 cycle_B: 0.489 idt_B: 0.198 \n",
      "(epoch: 90, iters: 560, time: 0.063, data: 0.002) D_A: 0.253 G_A: 0.304 cycle_A: 0.383 idt_A: 0.176 D_B: 0.208 G_B: 0.291 cycle_B: 0.551 idt_B: 0.178 \n",
      "(epoch: 90, iters: 760, time: 0.126, data: 0.002) D_A: 0.253 G_A: 0.239 cycle_A: 0.399 idt_A: 0.167 D_B: 0.206 G_B: 0.345 cycle_B: 0.424 idt_B: 0.186 \n",
      "(epoch: 90, iters: 960, time: 0.063, data: 0.001) D_A: 0.266 G_A: 0.245 cycle_A: 0.412 idt_A: 0.190 D_B: 0.220 G_B: 0.410 cycle_B: 0.546 idt_B: 0.189 \n",
      "(epoch: 90, iters: 1160, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.271 cycle_A: 0.463 idt_A: 0.191 D_B: 0.233 G_B: 0.139 cycle_B: 0.510 idt_B: 0.202 \n",
      "saving the model at the end of epoch 90, iters 104400\n",
      "End of epoch 90 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 91, iters: 200, time: 0.062, data: 0.081) D_A: 0.266 G_A: 0.273 cycle_A: 0.439 idt_A: 0.176 D_B: 0.237 G_B: 0.270 cycle_B: 0.458 idt_B: 0.164 \n",
      "(epoch: 91, iters: 400, time: 0.110, data: 0.002) D_A: 0.259 G_A: 0.315 cycle_A: 0.363 idt_A: 0.163 D_B: 0.227 G_B: 0.240 cycle_B: 0.509 idt_B: 0.168 \n",
      "(epoch: 91, iters: 600, time: 0.063, data: 0.002) D_A: 0.254 G_A: 0.310 cycle_A: 0.452 idt_A: 0.182 D_B: 0.161 G_B: 0.270 cycle_B: 0.539 idt_B: 0.195 \n",
      "saving the latest model (epoch 91, total_iters 105000)\n",
      "(epoch: 91, iters: 800, time: 0.063, data: 0.001) D_A: 0.254 G_A: 0.222 cycle_A: 0.390 idt_A: 0.203 D_B: 0.196 G_B: 0.391 cycle_B: 0.496 idt_B: 0.215 \n",
      "(epoch: 91, iters: 1000, time: 0.063, data: 0.002) D_A: 0.280 G_A: 0.304 cycle_A: 0.375 idt_A: 0.231 D_B: 0.153 G_B: 0.353 cycle_B: 0.522 idt_B: 0.182 \n",
      "End of epoch 91 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 92, iters: 40, time: 0.112, data: 0.001) D_A: 0.244 G_A: 0.261 cycle_A: 0.348 idt_A: 0.217 D_B: 0.253 G_B: 0.142 cycle_B: 0.462 idt_B: 0.159 \n",
      "(epoch: 92, iters: 240, time: 0.063, data: 0.002) D_A: 0.244 G_A: 0.263 cycle_A: 0.356 idt_A: 0.194 D_B: 0.248 G_B: 0.161 cycle_B: 0.514 idt_B: 0.178 \n",
      "(epoch: 92, iters: 440, time: 0.113, data: 0.002) D_A: 0.256 G_A: 0.288 cycle_A: 0.355 idt_A: 0.196 D_B: 0.234 G_B: 0.264 cycle_B: 0.519 idt_B: 0.147 \n",
      "(epoch: 92, iters: 640, time: 0.062, data: 0.001) D_A: 0.252 G_A: 0.256 cycle_A: 0.413 idt_A: 0.157 D_B: 0.171 G_B: 0.319 cycle_B: 0.426 idt_B: 0.212 \n",
      "(epoch: 92, iters: 840, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.230 cycle_A: 0.343 idt_A: 0.136 D_B: 0.227 G_B: 0.470 cycle_B: 0.354 idt_B: 0.163 \n",
      "(epoch: 92, iters: 1040, time: 0.063, data: 0.002) D_A: 0.256 G_A: 0.231 cycle_A: 0.392 idt_A: 0.190 D_B: 0.256 G_B: 0.232 cycle_B: 0.512 idt_B: 0.171 \n",
      "End of epoch 92 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 93, iters: 80, time: 0.115, data: 0.002) D_A: 0.253 G_A: 0.278 cycle_A: 0.338 idt_A: 0.130 D_B: 0.205 G_B: 0.237 cycle_B: 0.413 idt_B: 0.136 \n",
      "(epoch: 93, iters: 280, time: 0.063, data: 0.002) D_A: 0.239 G_A: 0.239 cycle_A: 0.486 idt_A: 0.203 D_B: 0.179 G_B: 0.319 cycle_B: 0.494 idt_B: 0.157 \n",
      "(epoch: 93, iters: 480, time: 0.063, data: 0.001) D_A: 0.243 G_A: 0.245 cycle_A: 0.405 idt_A: 0.191 D_B: 0.776 G_B: 1.269 cycle_B: 0.406 idt_B: 0.165 \n",
      "(epoch: 93, iters: 680, time: 0.063, data: 0.002) D_A: 0.266 G_A: 0.236 cycle_A: 0.464 idt_A: 0.181 D_B: 0.262 G_B: 0.248 cycle_B: 0.396 idt_B: 0.211 \n",
      "(epoch: 93, iters: 880, time: 0.063, data: 0.002) D_A: 0.261 G_A: 0.309 cycle_A: 0.408 idt_A: 0.194 D_B: 0.259 G_B: 0.232 cycle_B: 0.468 idt_B: 0.179 \n",
      "(epoch: 93, iters: 1080, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.303 cycle_A: 0.585 idt_A: 0.154 D_B: 0.241 G_B: 0.271 cycle_B: 0.406 idt_B: 0.202 \n",
      "End of epoch 93 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 94, iters: 120, time: 0.115, data: 0.002) D_A: 0.248 G_A: 0.255 cycle_A: 0.324 idt_A: 0.151 D_B: 0.233 G_B: 0.263 cycle_B: 0.426 idt_B: 0.144 \n",
      "(epoch: 94, iters: 320, time: 0.063, data: 0.002) D_A: 0.262 G_A: 0.275 cycle_A: 0.362 idt_A: 0.229 D_B: 0.200 G_B: 0.292 cycle_B: 0.650 idt_B: 0.177 \n",
      "(epoch: 94, iters: 520, time: 0.063, data: 0.002) D_A: 0.256 G_A: 0.297 cycle_A: 0.378 idt_A: 0.153 D_B: 0.209 G_B: 0.224 cycle_B: 0.416 idt_B: 0.176 \n",
      "(epoch: 94, iters: 720, time: 0.063, data: 0.001) D_A: 0.257 G_A: 0.228 cycle_A: 0.380 idt_A: 0.220 D_B: 0.176 G_B: 0.352 cycle_B: 0.477 idt_B: 0.174 \n",
      "(epoch: 94, iters: 920, time: 0.063, data: 0.001) D_A: 0.242 G_A: 0.268 cycle_A: 0.393 idt_A: 0.157 D_B: 0.190 G_B: 0.405 cycle_B: 0.471 idt_B: 0.186 \n",
      "(epoch: 94, iters: 1120, time: 0.063, data: 0.001) D_A: 0.268 G_A: 0.190 cycle_A: 0.526 idt_A: 0.179 D_B: 0.204 G_B: 0.337 cycle_B: 0.501 idt_B: 0.230 \n",
      "End of epoch 94 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 95, iters: 160, time: 0.114, data: 0.001) D_A: 0.243 G_A: 0.216 cycle_A: 0.305 idt_A: 0.187 D_B: 0.165 G_B: 0.393 cycle_B: 0.414 idt_B: 0.161 \n",
      "(epoch: 95, iters: 360, time: 0.063, data: 0.002) D_A: 0.262 G_A: 0.278 cycle_A: 0.385 idt_A: 0.165 D_B: 0.281 G_B: 0.088 cycle_B: 0.460 idt_B: 0.164 \n",
      "(epoch: 95, iters: 560, time: 0.063, data: 0.002) D_A: 0.236 G_A: 0.279 cycle_A: 0.391 idt_A: 0.133 D_B: 0.245 G_B: 0.142 cycle_B: 0.373 idt_B: 0.149 \n",
      "(epoch: 95, iters: 760, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.312 cycle_A: 0.371 idt_A: 0.149 D_B: 0.191 G_B: 0.404 cycle_B: 0.440 idt_B: 0.184 \n",
      "(epoch: 95, iters: 960, time: 0.114, data: 0.001) D_A: 0.246 G_A: 0.225 cycle_A: 0.459 idt_A: 0.143 D_B: 0.181 G_B: 0.294 cycle_B: 0.503 idt_B: 0.206 \n",
      "saving the latest model (epoch 95, total_iters 110000)\n",
      "(epoch: 95, iters: 1160, time: 0.063, data: 0.001) D_A: 0.251 G_A: 0.286 cycle_A: 0.483 idt_A: 0.217 D_B: 0.185 G_B: 0.326 cycle_B: 0.581 idt_B: 0.195 \n",
      "saving the model at the end of epoch 95, iters 110200\n",
      "End of epoch 95 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 96, iters: 200, time: 0.113, data: 0.115) D_A: 0.259 G_A: 0.221 cycle_A: 0.353 idt_A: 0.209 D_B: 0.238 G_B: 0.279 cycle_B: 0.494 idt_B: 0.148 \n",
      "(epoch: 96, iters: 400, time: 0.063, data: 0.002) D_A: 0.242 G_A: 0.259 cycle_A: 0.397 idt_A: 0.144 D_B: 0.232 G_B: 0.587 cycle_B: 0.421 idt_B: 0.179 \n",
      "(epoch: 96, iters: 600, time: 0.063, data: 0.002) D_A: 0.251 G_A: 0.315 cycle_A: 0.375 idt_A: 0.128 D_B: 0.200 G_B: 0.253 cycle_B: 0.423 idt_B: 0.186 \n",
      "(epoch: 96, iters: 800, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.272 cycle_A: 0.431 idt_A: 0.181 D_B: 0.200 G_B: 0.341 cycle_B: 0.508 idt_B: 0.158 \n",
      "(epoch: 96, iters: 1000, time: 0.063, data: 0.002) D_A: 0.240 G_A: 0.262 cycle_A: 0.519 idt_A: 0.176 D_B: 0.187 G_B: 0.292 cycle_B: 0.472 idt_B: 0.207 \n",
      "End of epoch 96 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 97, iters: 40, time: 0.063, data: 0.002) D_A: 0.251 G_A: 0.302 cycle_A: 0.363 idt_A: 0.177 D_B: 0.189 G_B: 0.450 cycle_B: 0.408 idt_B: 0.167 \n",
      "(epoch: 97, iters: 240, time: 0.112, data: 0.001) D_A: 0.267 G_A: 0.278 cycle_A: 0.337 idt_A: 0.164 D_B: 0.223 G_B: 0.265 cycle_B: 0.473 idt_B: 0.164 \n",
      "(epoch: 97, iters: 440, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.278 cycle_A: 0.361 idt_A: 0.195 D_B: 0.166 G_B: 0.313 cycle_B: 0.421 idt_B: 0.151 \n",
      "(epoch: 97, iters: 640, time: 0.114, data: 0.002) D_A: 0.261 G_A: 0.302 cycle_A: 0.384 idt_A: 0.200 D_B: 0.183 G_B: 0.414 cycle_B: 0.528 idt_B: 0.193 \n",
      "(epoch: 97, iters: 840, time: 0.063, data: 0.002) D_A: 0.257 G_A: 0.257 cycle_A: 0.386 idt_A: 0.140 D_B: 0.234 G_B: 0.153 cycle_B: 0.459 idt_B: 0.220 \n",
      "(epoch: 97, iters: 1040, time: 0.063, data: 0.001) D_A: 0.260 G_A: 0.211 cycle_A: 0.392 idt_A: 0.160 D_B: 0.186 G_B: 0.621 cycle_B: 0.408 idt_B: 0.177 \n",
      "End of epoch 97 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 98, iters: 80, time: 0.063, data: 0.002) D_A: 0.261 G_A: 0.249 cycle_A: 0.388 idt_A: 0.128 D_B: 0.307 G_B: 0.156 cycle_B: 0.480 idt_B: 0.208 \n",
      "(epoch: 98, iters: 280, time: 0.127, data: 0.002) D_A: 0.267 G_A: 0.336 cycle_A: 0.417 idt_A: 0.254 D_B: 0.271 G_B: 0.196 cycle_B: 0.712 idt_B: 0.180 \n",
      "(epoch: 98, iters: 480, time: 0.063, data: 0.002) D_A: 0.314 G_A: 0.268 cycle_A: 0.368 idt_A: 0.154 D_B: 0.214 G_B: 0.326 cycle_B: 0.487 idt_B: 0.180 \n",
      "(epoch: 98, iters: 680, time: 0.063, data: 0.001) D_A: 0.251 G_A: 0.322 cycle_A: 0.352 idt_A: 0.400 D_B: 0.180 G_B: 0.334 cycle_B: 0.783 idt_B: 0.182 \n",
      "(epoch: 98, iters: 880, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.202 cycle_A: 0.476 idt_A: 0.146 D_B: 0.344 G_B: 0.102 cycle_B: 0.425 idt_B: 0.211 \n",
      "(epoch: 98, iters: 1080, time: 0.063, data: 0.002) D_A: 0.245 G_A: 0.283 cycle_A: 0.536 idt_A: 0.183 D_B: 0.220 G_B: 0.290 cycle_B: 0.482 idt_B: 0.242 \n",
      "End of epoch 98 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 99, iters: 120, time: 0.063, data: 0.002) D_A: 0.295 G_A: 0.398 cycle_A: 0.759 idt_A: 0.224 D_B: 0.192 G_B: 0.385 cycle_B: 0.545 idt_B: 0.239 \n",
      "(epoch: 99, iters: 320, time: 0.116, data: 0.002) D_A: 0.244 G_A: 0.332 cycle_A: 0.501 idt_A: 0.180 D_B: 0.169 G_B: 0.357 cycle_B: 0.472 idt_B: 0.213 \n",
      "(epoch: 99, iters: 520, time: 0.063, data: 0.002) D_A: 0.237 G_A: 0.305 cycle_A: 0.313 idt_A: 0.175 D_B: 0.163 G_B: 0.238 cycle_B: 0.434 idt_B: 0.146 \n",
      "(epoch: 99, iters: 720, time: 0.063, data: 0.001) D_A: 0.247 G_A: 0.252 cycle_A: 0.358 idt_A: 0.190 D_B: 0.185 G_B: 0.379 cycle_B: 0.485 idt_B: 0.140 \n",
      "(epoch: 99, iters: 920, time: 0.063, data: 0.002) D_A: 0.262 G_A: 0.275 cycle_A: 0.549 idt_A: 0.161 D_B: 0.162 G_B: 0.443 cycle_B: 0.460 idt_B: 0.196 \n",
      "(epoch: 99, iters: 1120, time: 0.063, data: 0.001) D_A: 0.236 G_A: 0.242 cycle_A: 0.356 idt_A: 0.223 D_B: 0.200 G_B: 0.431 cycle_B: 0.495 idt_B: 0.162 \n",
      "End of epoch 99 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0002000 -> 0.0001980\n",
      "(epoch: 100, iters: 160, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.246 cycle_A: 0.556 idt_A: 0.180 D_B: 0.245 G_B: 0.452 cycle_B: 0.409 idt_B: 0.187 \n",
      "saving the latest model (epoch 100, total_iters 115000)\n",
      "(epoch: 100, iters: 360, time: 0.115, data: 0.001) D_A: 0.240 G_A: 0.266 cycle_A: 0.348 idt_A: 0.145 D_B: 0.235 G_B: 0.334 cycle_B: 0.383 idt_B: 0.149 \n",
      "(epoch: 100, iters: 560, time: 0.062, data: 0.002) D_A: 0.247 G_A: 0.259 cycle_A: 0.373 idt_A: 0.230 D_B: 0.210 G_B: 0.271 cycle_B: 0.517 idt_B: 0.159 \n",
      "(epoch: 100, iters: 760, time: 0.063, data: 0.002) D_A: 0.245 G_A: 0.254 cycle_A: 0.396 idt_A: 0.187 D_B: 0.206 G_B: 0.449 cycle_B: 0.460 idt_B: 0.187 \n",
      "(epoch: 100, iters: 960, time: 0.063, data: 0.001) D_A: 0.244 G_A: 0.325 cycle_A: 0.391 idt_A: 0.159 D_B: 0.198 G_B: 0.309 cycle_B: 0.432 idt_B: 0.180 \n",
      "(epoch: 100, iters: 1160, time: 0.116, data: 0.002) D_A: 0.257 G_A: 0.315 cycle_A: 0.522 idt_A: 0.186 D_B: 0.208 G_B: 0.345 cycle_B: 0.475 idt_B: 0.208 \n",
      "saving the model at the end of epoch 100, iters 116000\n",
      "End of epoch 100 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001980 -> 0.0001960\n",
      "(epoch: 101, iters: 200, time: 0.063, data: 0.107) D_A: 0.301 G_A: 0.393 cycle_A: 0.330 idt_A: 0.181 D_B: 0.352 G_B: 0.110 cycle_B: 0.480 idt_B: 0.176 \n",
      "(epoch: 101, iters: 400, time: 0.113, data: 0.002) D_A: 0.240 G_A: 0.277 cycle_A: 0.465 idt_A: 0.201 D_B: 0.203 G_B: 0.195 cycle_B: 0.527 idt_B: 0.249 \n",
      "(epoch: 101, iters: 600, time: 0.063, data: 0.002) D_A: 0.257 G_A: 0.184 cycle_A: 0.431 idt_A: 0.145 D_B: 0.340 G_B: 0.048 cycle_B: 0.442 idt_B: 0.192 \n",
      "(epoch: 101, iters: 800, time: 0.063, data: 0.001) D_A: 0.243 G_A: 0.293 cycle_A: 0.473 idt_A: 0.199 D_B: 0.278 G_B: 0.136 cycle_B: 0.501 idt_B: 0.246 \n",
      "(epoch: 101, iters: 1000, time: 0.063, data: 0.002) D_A: 0.277 G_A: 0.180 cycle_A: 0.347 idt_A: 0.187 D_B: 0.246 G_B: 0.177 cycle_B: 0.671 idt_B: 0.155 \n",
      "End of epoch 101 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001960 -> 0.0001941\n",
      "(epoch: 102, iters: 40, time: 0.116, data: 0.002) D_A: 0.248 G_A: 0.302 cycle_A: 0.379 idt_A: 0.227 D_B: 0.340 G_B: 0.084 cycle_B: 0.517 idt_B: 0.177 \n",
      "(epoch: 102, iters: 240, time: 0.062, data: 0.001) D_A: 0.289 G_A: 0.461 cycle_A: 0.435 idt_A: 0.206 D_B: 0.218 G_B: 0.360 cycle_B: 0.654 idt_B: 0.206 \n",
      "(epoch: 102, iters: 440, time: 0.063, data: 0.002) D_A: 0.258 G_A: 0.308 cycle_A: 0.343 idt_A: 0.127 D_B: 0.158 G_B: 0.382 cycle_B: 0.392 idt_B: 0.157 \n",
      "(epoch: 102, iters: 640, time: 0.063, data: 0.002) D_A: 0.222 G_A: 0.308 cycle_A: 0.401 idt_A: 0.164 D_B: 0.191 G_B: 0.347 cycle_B: 0.441 idt_B: 0.176 \n",
      "(epoch: 102, iters: 840, time: 0.116, data: 0.002) D_A: 0.321 G_A: 0.324 cycle_A: 0.390 idt_A: 0.138 D_B: 0.174 G_B: 0.360 cycle_B: 0.425 idt_B: 0.168 \n",
      "(epoch: 102, iters: 1040, time: 0.063, data: 0.002) D_A: 0.244 G_A: 0.236 cycle_A: 0.304 idt_A: 0.152 D_B: 0.172 G_B: 0.427 cycle_B: 0.427 idt_B: 0.133 \n",
      "End of epoch 102 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001941 -> 0.0001921\n",
      "(epoch: 103, iters: 80, time: 0.118, data: 0.002) D_A: 0.237 G_A: 0.273 cycle_A: 0.427 idt_A: 0.183 D_B: 0.186 G_B: 0.634 cycle_B: 0.533 idt_B: 0.172 \n",
      "(epoch: 103, iters: 280, time: 0.063, data: 0.001) D_A: 0.253 G_A: 0.274 cycle_A: 0.350 idt_A: 0.149 D_B: 0.178 G_B: 0.568 cycle_B: 0.433 idt_B: 0.179 \n",
      "(epoch: 103, iters: 480, time: 0.063, data: 0.002) D_A: 0.239 G_A: 0.222 cycle_A: 0.466 idt_A: 0.280 D_B: 0.202 G_B: 0.301 cycle_B: 0.729 idt_B: 0.180 \n",
      "(epoch: 103, iters: 680, time: 0.063, data: 0.002) D_A: 0.228 G_A: 0.251 cycle_A: 0.454 idt_A: 0.148 D_B: 0.188 G_B: 0.257 cycle_B: 0.403 idt_B: 0.189 \n",
      "(epoch: 103, iters: 880, time: 0.063, data: 0.002) D_A: 0.250 G_A: 0.371 cycle_A: 0.350 idt_A: 0.150 D_B: 0.150 G_B: 0.344 cycle_B: 0.403 idt_B: 0.160 \n",
      "(epoch: 103, iters: 1080, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.218 cycle_A: 0.340 idt_A: 0.194 D_B: 0.191 G_B: 0.324 cycle_B: 0.576 idt_B: 0.157 \n",
      "End of epoch 103 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001921 -> 0.0001901\n",
      "(epoch: 104, iters: 120, time: 0.118, data: 0.002) D_A: 0.239 G_A: 0.303 cycle_A: 0.313 idt_A: 0.182 D_B: 0.198 G_B: 0.296 cycle_B: 0.452 idt_B: 0.160 \n",
      "(epoch: 104, iters: 320, time: 0.062, data: 0.001) D_A: 0.251 G_A: 0.215 cycle_A: 0.474 idt_A: 0.173 D_B: 0.214 G_B: 0.272 cycle_B: 0.413 idt_B: 0.172 \n",
      "(epoch: 104, iters: 520, time: 0.117, data: 0.002) D_A: 0.242 G_A: 0.241 cycle_A: 0.367 idt_A: 0.193 D_B: 0.237 G_B: 0.088 cycle_B: 0.429 idt_B: 0.152 \n",
      "saving the latest model (epoch 104, total_iters 120000)\n",
      "(epoch: 104, iters: 720, time: 0.063, data: 0.001) D_A: 0.246 G_A: 0.332 cycle_A: 0.534 idt_A: 0.206 D_B: 0.214 G_B: 0.249 cycle_B: 0.463 idt_B: 0.200 \n",
      "(epoch: 104, iters: 920, time: 0.063, data: 0.002) D_A: 0.242 G_A: 0.237 cycle_A: 0.406 idt_A: 0.178 D_B: 0.173 G_B: 0.345 cycle_B: 0.426 idt_B: 0.171 \n",
      "(epoch: 104, iters: 1120, time: 0.063, data: 0.002) D_A: 0.232 G_A: 0.294 cycle_A: 0.450 idt_A: 0.154 D_B: 0.156 G_B: 0.424 cycle_B: 0.470 idt_B: 0.171 \n",
      "End of epoch 104 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001901 -> 0.0001881\n",
      "(epoch: 105, iters: 160, time: 0.116, data: 0.002) D_A: 0.246 G_A: 0.282 cycle_A: 0.421 idt_A: 0.199 D_B: 0.195 G_B: 0.401 cycle_B: 0.572 idt_B: 0.190 \n",
      "(epoch: 105, iters: 360, time: 0.063, data: 0.002) D_A: 0.243 G_A: 0.348 cycle_A: 0.385 idt_A: 0.146 D_B: 0.206 G_B: 0.423 cycle_B: 0.468 idt_B: 0.149 \n",
      "(epoch: 105, iters: 560, time: 0.063, data: 0.002) D_A: 0.231 G_A: 0.362 cycle_A: 0.413 idt_A: 0.149 D_B: 0.225 G_B: 0.151 cycle_B: 0.435 idt_B: 0.173 \n",
      "(epoch: 105, iters: 760, time: 0.063, data: 0.001) D_A: 0.227 G_A: 0.321 cycle_A: 0.437 idt_A: 0.189 D_B: 0.195 G_B: 0.370 cycle_B: 0.490 idt_B: 0.199 \n",
      "(epoch: 105, iters: 960, time: 0.062, data: 0.002) D_A: 0.291 G_A: 0.497 cycle_A: 0.515 idt_A: 0.163 D_B: 0.225 G_B: 0.178 cycle_B: 0.409 idt_B: 0.162 \n",
      "(epoch: 105, iters: 1160, time: 0.063, data: 0.002) D_A: 0.245 G_A: 0.190 cycle_A: 0.393 idt_A: 0.198 D_B: 0.209 G_B: 0.247 cycle_B: 0.440 idt_B: 0.202 \n",
      "saving the model at the end of epoch 105, iters 121800\n",
      "End of epoch 105 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001881 -> 0.0001861\n",
      "(epoch: 106, iters: 200, time: 0.132, data: 0.109) D_A: 0.258 G_A: 0.373 cycle_A: 0.325 idt_A: 0.133 D_B: 0.242 G_B: 0.303 cycle_B: 0.440 idt_B: 0.197 \n",
      "(epoch: 106, iters: 400, time: 0.063, data: 0.001) D_A: 0.250 G_A: 0.378 cycle_A: 0.417 idt_A: 0.124 D_B: 0.194 G_B: 0.269 cycle_B: 0.401 idt_B: 0.175 \n",
      "(epoch: 106, iters: 600, time: 0.063, data: 0.002) D_A: 0.223 G_A: 0.238 cycle_A: 0.333 idt_A: 0.140 D_B: 0.159 G_B: 0.324 cycle_B: 0.379 idt_B: 0.147 \n",
      "(epoch: 106, iters: 800, time: 0.063, data: 0.002) D_A: 0.306 G_A: 0.515 cycle_A: 0.490 idt_A: 0.131 D_B: 0.244 G_B: 0.524 cycle_B: 0.438 idt_B: 0.216 \n",
      "(epoch: 106, iters: 1000, time: 0.063, data: 0.002) D_A: 0.300 G_A: 0.412 cycle_A: 0.401 idt_A: 0.134 D_B: 0.196 G_B: 0.398 cycle_B: 0.378 idt_B: 0.209 \n",
      "End of epoch 106 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001861 -> 0.0001842\n",
      "(epoch: 107, iters: 40, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.199 cycle_A: 0.358 idt_A: 0.163 D_B: 0.215 G_B: 0.242 cycle_B: 0.391 idt_B: 0.166 \n",
      "(epoch: 107, iters: 240, time: 0.118, data: 0.001) D_A: 0.251 G_A: 0.358 cycle_A: 0.400 idt_A: 0.147 D_B: 0.211 G_B: 0.256 cycle_B: 0.430 idt_B: 0.214 \n",
      "(epoch: 107, iters: 440, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.289 cycle_A: 0.417 idt_A: 0.204 D_B: 0.232 G_B: 0.292 cycle_B: 0.539 idt_B: 0.152 \n",
      "(epoch: 107, iters: 640, time: 0.063, data: 0.002) D_A: 0.261 G_A: 0.369 cycle_A: 0.373 idt_A: 0.142 D_B: 0.192 G_B: 0.209 cycle_B: 0.408 idt_B: 0.162 \n",
      "(epoch: 107, iters: 840, time: 0.063, data: 0.001) D_A: 0.233 G_A: 0.306 cycle_A: 0.362 idt_A: 0.122 D_B: 0.211 G_B: 0.222 cycle_B: 0.400 idt_B: 0.180 \n",
      "(epoch: 107, iters: 1040, time: 0.117, data: 0.002) D_A: 0.256 G_A: 0.204 cycle_A: 0.372 idt_A: 0.152 D_B: 0.203 G_B: 0.342 cycle_B: 0.422 idt_B: 0.155 \n",
      "End of epoch 107 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001842 -> 0.0001822\n",
      "(epoch: 108, iters: 80, time: 0.063, data: 0.002) D_A: 0.229 G_A: 0.286 cycle_A: 0.415 idt_A: 0.135 D_B: 0.171 G_B: 0.330 cycle_B: 0.410 idt_B: 0.199 \n",
      "(epoch: 108, iters: 280, time: 0.119, data: 0.002) D_A: 0.248 G_A: 0.297 cycle_A: 0.335 idt_A: 0.148 D_B: 0.213 G_B: 0.152 cycle_B: 0.372 idt_B: 0.134 \n",
      "(epoch: 108, iters: 480, time: 0.063, data: 0.001) D_A: 0.252 G_A: 0.322 cycle_A: 0.368 idt_A: 0.157 D_B: 0.224 G_B: 0.278 cycle_B: 0.453 idt_B: 0.176 \n",
      "(epoch: 108, iters: 680, time: 0.063, data: 0.001) D_A: 0.326 G_A: 0.332 cycle_A: 0.520 idt_A: 0.134 D_B: 0.201 G_B: 0.188 cycle_B: 0.429 idt_B: 0.212 \n",
      "(epoch: 108, iters: 880, time: 0.063, data: 0.002) D_A: 0.222 G_A: 0.391 cycle_A: 0.474 idt_A: 0.204 D_B: 0.174 G_B: 0.298 cycle_B: 0.624 idt_B: 0.191 \n",
      "saving the latest model (epoch 108, total_iters 125000)\n",
      "(epoch: 108, iters: 1080, time: 0.063, data: 0.001) D_A: 0.232 G_A: 0.268 cycle_A: 0.391 idt_A: 0.180 D_B: 0.223 G_B: 0.367 cycle_B: 0.548 idt_B: 0.168 \n",
      "End of epoch 108 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001822 -> 0.0001802\n",
      "(epoch: 109, iters: 120, time: 0.063, data: 0.001) D_A: 0.210 G_A: 0.328 cycle_A: 0.357 idt_A: 0.153 D_B: 0.193 G_B: 0.391 cycle_B: 0.455 idt_B: 0.139 \n",
      "(epoch: 109, iters: 320, time: 0.119, data: 0.002) D_A: 0.226 G_A: 0.347 cycle_A: 0.404 idt_A: 0.164 D_B: 0.193 G_B: 0.576 cycle_B: 0.413 idt_B: 0.162 \n",
      "(epoch: 109, iters: 520, time: 0.063, data: 0.002) D_A: 0.249 G_A: 0.325 cycle_A: 0.384 idt_A: 0.173 D_B: 0.205 G_B: 0.368 cycle_B: 0.359 idt_B: 0.155 \n",
      "(epoch: 109, iters: 720, time: 0.119, data: 0.002) D_A: 0.224 G_A: 0.239 cycle_A: 0.345 idt_A: 0.163 D_B: 0.226 G_B: 0.180 cycle_B: 0.432 idt_B: 0.135 \n",
      "(epoch: 109, iters: 920, time: 0.063, data: 0.001) D_A: 0.215 G_A: 0.294 cycle_A: 0.382 idt_A: 0.141 D_B: 0.198 G_B: 0.358 cycle_B: 0.421 idt_B: 0.181 \n",
      "(epoch: 109, iters: 1120, time: 0.062, data: 0.002) D_A: 0.212 G_A: 0.289 cycle_A: 0.303 idt_A: 0.120 D_B: 0.172 G_B: 0.448 cycle_B: 0.353 idt_B: 0.149 \n",
      "End of epoch 109 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001802 -> 0.0001782\n",
      "(epoch: 110, iters: 160, time: 0.063, data: 0.002) D_A: 0.233 G_A: 0.364 cycle_A: 0.355 idt_A: 0.144 D_B: 0.186 G_B: 0.179 cycle_B: 0.403 idt_B: 0.164 \n",
      "(epoch: 110, iters: 360, time: 0.119, data: 0.002) D_A: 0.247 G_A: 0.393 cycle_A: 0.315 idt_A: 0.177 D_B: 0.239 G_B: 0.181 cycle_B: 0.446 idt_B: 0.136 \n",
      "(epoch: 110, iters: 560, time: 0.063, data: 0.002) D_A: 0.225 G_A: 0.419 cycle_A: 0.322 idt_A: 0.143 D_B: 0.196 G_B: 0.241 cycle_B: 0.433 idt_B: 0.124 \n",
      "(epoch: 110, iters: 760, time: 0.062, data: 0.001) D_A: 0.283 G_A: 0.318 cycle_A: 0.462 idt_A: 0.191 D_B: 0.238 G_B: 0.284 cycle_B: 0.556 idt_B: 0.177 \n",
      "(epoch: 110, iters: 960, time: 0.063, data: 0.002) D_A: 0.232 G_A: 0.448 cycle_A: 0.466 idt_A: 0.207 D_B: 0.195 G_B: 0.283 cycle_B: 0.470 idt_B: 0.212 \n",
      "(epoch: 110, iters: 1160, time: 0.063, data: 0.001) D_A: 0.247 G_A: 0.412 cycle_A: 0.377 idt_A: 0.123 D_B: 0.198 G_B: 0.257 cycle_B: 0.323 idt_B: 0.170 \n",
      "saving the model at the end of epoch 110, iters 127600\n",
      "End of epoch 110 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001782 -> 0.0001762\n",
      "(epoch: 111, iters: 200, time: 0.063, data: 0.104) D_A: 0.226 G_A: 0.322 cycle_A: 0.383 idt_A: 0.164 D_B: 0.165 G_B: 0.455 cycle_B: 0.361 idt_B: 0.176 \n",
      "(epoch: 111, iters: 400, time: 0.120, data: 0.002) D_A: 0.219 G_A: 0.281 cycle_A: 0.388 idt_A: 0.192 D_B: 0.210 G_B: 0.369 cycle_B: 0.439 idt_B: 0.140 \n",
      "(epoch: 111, iters: 600, time: 0.063, data: 0.002) D_A: 0.237 G_A: 0.302 cycle_A: 0.412 idt_A: 0.131 D_B: 0.174 G_B: 0.316 cycle_B: 0.400 idt_B: 0.168 \n",
      "(epoch: 111, iters: 800, time: 0.063, data: 0.002) D_A: 0.213 G_A: 0.222 cycle_A: 0.334 idt_A: 0.120 D_B: 0.151 G_B: 0.281 cycle_B: 0.350 idt_B: 0.153 \n",
      "(epoch: 111, iters: 1000, time: 0.063, data: 0.002) D_A: 0.236 G_A: 0.384 cycle_A: 0.410 idt_A: 0.112 D_B: 0.179 G_B: 0.517 cycle_B: 0.360 idt_B: 0.192 \n",
      "End of epoch 111 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001762 -> 0.0001743\n",
      "(epoch: 112, iters: 40, time: 0.120, data: 0.001) D_A: 0.252 G_A: 0.355 cycle_A: 0.380 idt_A: 0.166 D_B: 0.175 G_B: 0.379 cycle_B: 0.461 idt_B: 0.147 \n",
      "(epoch: 112, iters: 240, time: 0.063, data: 0.001) D_A: 0.239 G_A: 0.283 cycle_A: 0.398 idt_A: 0.143 D_B: 0.176 G_B: 0.429 cycle_B: 0.394 idt_B: 0.187 \n",
      "(epoch: 112, iters: 440, time: 0.063, data: 0.002) D_A: 0.214 G_A: 0.324 cycle_A: 0.386 idt_A: 0.163 D_B: 0.180 G_B: 0.357 cycle_B: 0.429 idt_B: 0.171 \n",
      "(epoch: 112, iters: 640, time: 0.063, data: 0.001) D_A: 0.217 G_A: 0.326 cycle_A: 0.428 idt_A: 0.123 D_B: 0.173 G_B: 0.285 cycle_B: 0.359 idt_B: 0.190 \n",
      "(epoch: 112, iters: 840, time: 0.063, data: 0.002) D_A: 0.239 G_A: 0.423 cycle_A: 0.417 idt_A: 0.169 D_B: 0.187 G_B: 0.303 cycle_B: 0.457 idt_B: 0.154 \n",
      "(epoch: 112, iters: 1040, time: 0.063, data: 0.001) D_A: 0.283 G_A: 0.094 cycle_A: 0.419 idt_A: 0.142 D_B: 0.202 G_B: 0.281 cycle_B: 0.360 idt_B: 0.204 \n",
      "End of epoch 112 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001743 -> 0.0001723\n",
      "(epoch: 113, iters: 80, time: 0.121, data: 0.002) D_A: 0.215 G_A: 0.288 cycle_A: 0.426 idt_A: 0.185 D_B: 0.183 G_B: 0.306 cycle_B: 0.431 idt_B: 0.170 \n",
      "saving the latest model (epoch 113, total_iters 130000)\n",
      "(epoch: 113, iters: 280, time: 0.063, data: 0.001) D_A: 0.251 G_A: 0.254 cycle_A: 0.450 idt_A: 0.160 D_B: 0.213 G_B: 0.253 cycle_B: 0.475 idt_B: 0.172 \n",
      "(epoch: 113, iters: 480, time: 0.063, data: 0.002) D_A: 0.218 G_A: 0.324 cycle_A: 0.410 idt_A: 0.118 D_B: 0.154 G_B: 0.367 cycle_B: 0.351 idt_B: 0.205 \n",
      "(epoch: 113, iters: 680, time: 0.063, data: 0.002) D_A: 0.209 G_A: 0.294 cycle_A: 0.364 idt_A: 0.192 D_B: 0.227 G_B: 0.286 cycle_B: 0.485 idt_B: 0.159 \n",
      "(epoch: 113, iters: 880, time: 0.063, data: 0.002) D_A: 0.278 G_A: 0.577 cycle_A: 0.410 idt_A: 0.156 D_B: 0.169 G_B: 0.243 cycle_B: 0.442 idt_B: 0.159 \n",
      "(epoch: 113, iters: 1080, time: 0.063, data: 0.001) D_A: 0.296 G_A: 0.552 cycle_A: 0.362 idt_A: 0.211 D_B: 0.196 G_B: 0.279 cycle_B: 0.501 idt_B: 0.131 \n",
      "End of epoch 113 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001723 -> 0.0001703\n",
      "(epoch: 114, iters: 120, time: 0.134, data: 0.002) D_A: 0.230 G_A: 0.191 cycle_A: 0.497 idt_A: 0.169 D_B: 0.164 G_B: 0.493 cycle_B: 0.482 idt_B: 0.174 \n",
      "(epoch: 114, iters: 320, time: 0.063, data: 0.001) D_A: 0.189 G_A: 0.483 cycle_A: 0.359 idt_A: 0.130 D_B: 0.228 G_B: 0.181 cycle_B: 0.348 idt_B: 0.171 \n",
      "(epoch: 114, iters: 520, time: 0.063, data: 0.002) D_A: 0.217 G_A: 0.266 cycle_A: 0.389 idt_A: 0.175 D_B: 0.210 G_B: 0.477 cycle_B: 0.492 idt_B: 0.168 \n",
      "(epoch: 114, iters: 720, time: 0.063, data: 0.002) D_A: 0.197 G_A: 0.422 cycle_A: 0.378 idt_A: 0.140 D_B: 0.155 G_B: 0.589 cycle_B: 0.490 idt_B: 0.186 \n",
      "(epoch: 114, iters: 920, time: 0.120, data: 0.001) D_A: 0.208 G_A: 0.474 cycle_A: 0.441 idt_A: 0.158 D_B: 0.183 G_B: 0.313 cycle_B: 0.445 idt_B: 0.190 \n",
      "(epoch: 114, iters: 1120, time: 0.063, data: 0.002) D_A: 0.213 G_A: 0.385 cycle_A: 0.453 idt_A: 0.151 D_B: 0.186 G_B: 0.214 cycle_B: 0.411 idt_B: 0.194 \n",
      "End of epoch 114 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001703 -> 0.0001683\n",
      "(epoch: 115, iters: 160, time: 0.121, data: 0.001) D_A: 0.215 G_A: 0.267 cycle_A: 0.416 idt_A: 0.154 D_B: 0.272 G_B: 0.153 cycle_B: 0.373 idt_B: 0.182 \n",
      "(epoch: 115, iters: 360, time: 0.063, data: 0.002) D_A: 0.219 G_A: 0.233 cycle_A: 0.600 idt_A: 0.151 D_B: 0.200 G_B: 0.520 cycle_B: 0.362 idt_B: 0.316 \n",
      "(epoch: 115, iters: 560, time: 0.063, data: 0.002) D_A: 0.230 G_A: 0.412 cycle_A: 0.383 idt_A: 0.143 D_B: 0.193 G_B: 0.348 cycle_B: 0.415 idt_B: 0.167 \n",
      "(epoch: 115, iters: 760, time: 0.063, data: 0.002) D_A: 0.183 G_A: 0.390 cycle_A: 0.501 idt_A: 0.132 D_B: 0.203 G_B: 0.267 cycle_B: 0.378 idt_B: 0.182 \n",
      "(epoch: 115, iters: 960, time: 0.063, data: 0.002) D_A: 0.224 G_A: 0.293 cycle_A: 0.414 idt_A: 0.135 D_B: 0.176 G_B: 0.497 cycle_B: 0.395 idt_B: 0.168 \n",
      "(epoch: 115, iters: 1160, time: 0.063, data: 0.002) D_A: 0.209 G_A: 0.250 cycle_A: 0.308 idt_A: 0.164 D_B: 0.151 G_B: 0.340 cycle_B: 0.401 idt_B: 0.124 \n",
      "saving the model at the end of epoch 115, iters 133400\n",
      "End of epoch 115 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001683 -> 0.0001663\n",
      "(epoch: 116, iters: 200, time: 0.120, data: 0.083) D_A: 0.226 G_A: 0.389 cycle_A: 0.423 idt_A: 0.212 D_B: 0.241 G_B: 0.240 cycle_B: 0.501 idt_B: 0.150 \n",
      "(epoch: 116, iters: 400, time: 0.063, data: 0.002) D_A: 0.180 G_A: 0.331 cycle_A: 0.587 idt_A: 0.157 D_B: 0.184 G_B: 0.311 cycle_B: 0.391 idt_B: 0.181 \n",
      "(epoch: 116, iters: 600, time: 0.121, data: 0.002) D_A: 0.199 G_A: 0.489 cycle_A: 0.361 idt_A: 0.126 D_B: 0.172 G_B: 0.234 cycle_B: 0.351 idt_B: 0.162 \n",
      "(epoch: 116, iters: 800, time: 0.063, data: 0.001) D_A: 0.213 G_A: 0.194 cycle_A: 0.370 idt_A: 0.149 D_B: 0.178 G_B: 0.234 cycle_B: 0.433 idt_B: 0.157 \n",
      "(epoch: 116, iters: 1000, time: 0.063, data: 0.002) D_A: 0.222 G_A: 0.309 cycle_A: 0.383 idt_A: 0.162 D_B: 0.194 G_B: 0.522 cycle_B: 0.424 idt_B: 0.141 \n",
      "End of epoch 116 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001663 -> 0.0001644\n",
      "(epoch: 117, iters: 40, time: 0.063, data: 0.002) D_A: 0.218 G_A: 0.255 cycle_A: 0.422 idt_A: 0.126 D_B: 0.206 G_B: 0.244 cycle_B: 0.376 idt_B: 0.149 \n",
      "(epoch: 117, iters: 240, time: 0.123, data: 0.002) D_A: 0.206 G_A: 0.249 cycle_A: 0.396 idt_A: 0.140 D_B: 0.221 G_B: 0.584 cycle_B: 0.403 idt_B: 0.173 \n",
      "(epoch: 117, iters: 440, time: 0.063, data: 0.001) D_A: 0.185 G_A: 0.317 cycle_A: 0.411 idt_A: 0.187 D_B: 0.193 G_B: 0.272 cycle_B: 0.433 idt_B: 0.194 \n",
      "saving the latest model (epoch 117, total_iters 135000)\n",
      "(epoch: 117, iters: 640, time: 0.063, data: 0.001) D_A: 0.227 G_A: 0.193 cycle_A: 0.338 idt_A: 0.137 D_B: 0.171 G_B: 0.353 cycle_B: 0.427 idt_B: 0.133 \n",
      "(epoch: 117, iters: 840, time: 0.063, data: 0.002) D_A: 0.211 G_A: 0.380 cycle_A: 0.369 idt_A: 0.175 D_B: 0.146 G_B: 0.397 cycle_B: 0.424 idt_B: 0.130 \n",
      "(epoch: 117, iters: 1040, time: 0.063, data: 0.002) D_A: 0.188 G_A: 0.325 cycle_A: 0.504 idt_A: 0.151 D_B: 0.193 G_B: 0.454 cycle_B: 0.392 idt_B: 0.182 \n",
      "End of epoch 117 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001644 -> 0.0001624\n",
      "(epoch: 118, iters: 80, time: 0.063, data: 0.002) D_A: 0.185 G_A: 0.248 cycle_A: 0.576 idt_A: 0.164 D_B: 0.182 G_B: 0.378 cycle_B: 0.407 idt_B: 0.225 \n",
      "(epoch: 118, iters: 280, time: 0.122, data: 0.001) D_A: 0.228 G_A: 0.250 cycle_A: 0.349 idt_A: 0.126 D_B: 0.164 G_B: 0.308 cycle_B: 0.395 idt_B: 0.144 \n",
      "(epoch: 118, iters: 480, time: 0.063, data: 0.001) D_A: 0.191 G_A: 0.345 cycle_A: 0.373 idt_A: 0.177 D_B: 0.200 G_B: 0.460 cycle_B: 0.426 idt_B: 0.157 \n",
      "(epoch: 118, iters: 680, time: 0.063, data: 0.002) D_A: 0.244 G_A: 0.457 cycle_A: 0.419 idt_A: 0.142 D_B: 0.180 G_B: 0.234 cycle_B: 0.473 idt_B: 0.172 \n",
      "(epoch: 118, iters: 880, time: 0.063, data: 0.001) D_A: 0.239 G_A: 0.434 cycle_A: 0.336 idt_A: 0.146 D_B: 0.210 G_B: 0.198 cycle_B: 0.389 idt_B: 0.112 \n",
      "(epoch: 118, iters: 1080, time: 0.063, data: 0.002) D_A: 0.231 G_A: 0.315 cycle_A: 0.623 idt_A: 0.117 D_B: 0.230 G_B: 0.139 cycle_B: 0.357 idt_B: 0.254 \n",
      "End of epoch 118 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001624 -> 0.0001604\n",
      "(epoch: 119, iters: 120, time: 0.063, data: 0.002) D_A: 0.209 G_A: 0.298 cycle_A: 0.425 idt_A: 0.137 D_B: 0.180 G_B: 0.267 cycle_B: 0.402 idt_B: 0.203 \n",
      "(epoch: 119, iters: 320, time: 0.124, data: 0.002) D_A: 0.210 G_A: 0.198 cycle_A: 0.366 idt_A: 0.212 D_B: 0.204 G_B: 0.236 cycle_B: 0.579 idt_B: 0.150 \n",
      "(epoch: 119, iters: 520, time: 0.062, data: 0.002) D_A: 0.223 G_A: 0.371 cycle_A: 0.438 idt_A: 0.183 D_B: 0.216 G_B: 0.280 cycle_B: 0.439 idt_B: 0.152 \n",
      "(epoch: 119, iters: 720, time: 0.063, data: 0.002) D_A: 0.225 G_A: 0.562 cycle_A: 0.407 idt_A: 0.132 D_B: 0.227 G_B: 0.177 cycle_B: 0.366 idt_B: 0.178 \n",
      "(epoch: 119, iters: 920, time: 0.063, data: 0.002) D_A: 0.181 G_A: 0.424 cycle_A: 0.413 idt_A: 0.152 D_B: 0.165 G_B: 0.368 cycle_B: 0.395 idt_B: 0.183 \n",
      "(epoch: 119, iters: 1120, time: 0.123, data: 0.002) D_A: 0.221 G_A: 0.184 cycle_A: 0.378 idt_A: 0.184 D_B: 0.231 G_B: 0.300 cycle_B: 0.414 idt_B: 0.157 \n",
      "End of epoch 119 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001604 -> 0.0001584\n",
      "(epoch: 120, iters: 160, time: 0.063, data: 0.001) D_A: 0.219 G_A: 0.416 cycle_A: 0.459 idt_A: 0.162 D_B: 0.217 G_B: 0.339 cycle_B: 0.411 idt_B: 0.147 \n",
      "(epoch: 120, iters: 360, time: 0.136, data: 0.002) D_A: 0.234 G_A: 0.184 cycle_A: 0.416 idt_A: 0.139 D_B: 0.194 G_B: 0.302 cycle_B: 0.456 idt_B: 0.173 \n",
      "(epoch: 120, iters: 560, time: 0.063, data: 0.001) D_A: 0.181 G_A: 0.288 cycle_A: 0.381 idt_A: 0.170 D_B: 0.108 G_B: 0.517 cycle_B: 0.482 idt_B: 0.141 \n",
      "(epoch: 120, iters: 760, time: 0.063, data: 0.001) D_A: 0.215 G_A: 0.551 cycle_A: 0.382 idt_A: 0.133 D_B: 0.209 G_B: 0.303 cycle_B: 0.405 idt_B: 0.145 \n",
      "(epoch: 120, iters: 960, time: 0.063, data: 0.002) D_A: 0.221 G_A: 0.470 cycle_A: 0.397 idt_A: 0.149 D_B: 0.188 G_B: 0.196 cycle_B: 0.418 idt_B: 0.139 \n",
      "(epoch: 120, iters: 1160, time: 0.063, data: 0.001) D_A: 0.193 G_A: 0.191 cycle_A: 0.387 idt_A: 0.137 D_B: 0.172 G_B: 0.339 cycle_B: 0.382 idt_B: 0.139 \n",
      "saving the model at the end of epoch 120, iters 139200\n",
      "End of epoch 120 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001584 -> 0.0001564\n",
      "(epoch: 121, iters: 200, time: 0.062, data: 0.121) D_A: 0.225 G_A: 0.302 cycle_A: 0.436 idt_A: 0.150 D_B: 0.193 G_B: 0.302 cycle_B: 0.449 idt_B: 0.185 \n",
      "(epoch: 121, iters: 400, time: 0.124, data: 0.001) D_A: 0.234 G_A: 0.304 cycle_A: 0.453 idt_A: 0.131 D_B: 0.239 G_B: 0.249 cycle_B: 0.468 idt_B: 0.179 \n",
      "(epoch: 121, iters: 600, time: 0.063, data: 0.002) D_A: 0.181 G_A: 0.316 cycle_A: 0.398 idt_A: 0.163 D_B: 0.222 G_B: 0.277 cycle_B: 0.389 idt_B: 0.201 \n",
      "(epoch: 121, iters: 800, time: 0.121, data: 0.002) D_A: 0.229 G_A: 0.239 cycle_A: 0.376 idt_A: 0.141 D_B: 0.166 G_B: 0.213 cycle_B: 0.418 idt_B: 0.157 \n",
      "saving the latest model (epoch 121, total_iters 140000)\n",
      "(epoch: 121, iters: 1000, time: 0.063, data: 0.001) D_A: 0.209 G_A: 0.297 cycle_A: 0.457 idt_A: 0.146 D_B: 0.198 G_B: 0.226 cycle_B: 0.407 idt_B: 0.139 \n",
      "End of epoch 121 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001564 -> 0.0001545\n",
      "(epoch: 122, iters: 40, time: 0.124, data: 0.001) D_A: 0.208 G_A: 0.285 cycle_A: 0.360 idt_A: 0.159 D_B: 0.203 G_B: 0.221 cycle_B: 0.399 idt_B: 0.150 \n",
      "(epoch: 122, iters: 240, time: 0.063, data: 0.001) D_A: 0.204 G_A: 0.227 cycle_A: 0.322 idt_A: 0.128 D_B: 0.175 G_B: 0.380 cycle_B: 0.368 idt_B: 0.108 \n",
      "(epoch: 122, iters: 440, time: 0.063, data: 0.002) D_A: 0.208 G_A: 0.258 cycle_A: 0.450 idt_A: 0.168 D_B: 0.233 G_B: 0.255 cycle_B: 0.440 idt_B: 0.222 \n",
      "(epoch: 122, iters: 640, time: 0.063, data: 0.001) D_A: 0.217 G_A: 0.173 cycle_A: 0.404 idt_A: 0.145 D_B: 0.194 G_B: 0.455 cycle_B: 0.378 idt_B: 0.138 \n",
      "(epoch: 122, iters: 840, time: 0.063, data: 0.002) D_A: 0.224 G_A: 0.239 cycle_A: 0.491 idt_A: 0.125 D_B: 0.250 G_B: 0.189 cycle_B: 0.387 idt_B: 0.202 \n",
      "(epoch: 122, iters: 1040, time: 0.063, data: 0.002) D_A: 0.199 G_A: 0.478 cycle_A: 0.419 idt_A: 0.168 D_B: 0.194 G_B: 0.381 cycle_B: 0.451 idt_B: 0.153 \n",
      "End of epoch 122 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001545 -> 0.0001525\n",
      "(epoch: 123, iters: 80, time: 0.124, data: 0.002) D_A: 0.230 G_A: 0.293 cycle_A: 0.411 idt_A: 0.131 D_B: 0.244 G_B: 0.494 cycle_B: 0.395 idt_B: 0.171 \n",
      "(epoch: 123, iters: 280, time: 0.063, data: 0.002) D_A: 0.248 G_A: 0.308 cycle_A: 0.374 idt_A: 0.147 D_B: 0.361 G_B: 0.863 cycle_B: 0.441 idt_B: 0.150 \n",
      "(epoch: 123, iters: 480, time: 0.124, data: 0.002) D_A: 0.188 G_A: 0.397 cycle_A: 0.427 idt_A: 0.171 D_B: 0.201 G_B: 0.584 cycle_B: 0.439 idt_B: 0.134 \n",
      "(epoch: 123, iters: 680, time: 0.063, data: 0.001) D_A: 0.183 G_A: 0.430 cycle_A: 0.467 idt_A: 0.150 D_B: 0.163 G_B: 0.354 cycle_B: 0.432 idt_B: 0.187 \n",
      "(epoch: 123, iters: 880, time: 0.063, data: 0.002) D_A: 0.207 G_A: 0.485 cycle_A: 0.340 idt_A: 0.117 D_B: 0.210 G_B: 0.344 cycle_B: 0.336 idt_B: 0.139 \n",
      "(epoch: 123, iters: 1080, time: 0.063, data: 0.002) D_A: 0.189 G_A: 0.356 cycle_A: 0.426 idt_A: 0.205 D_B: 0.197 G_B: 0.301 cycle_B: 0.511 idt_B: 0.182 \n",
      "End of epoch 123 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001525 -> 0.0001505\n",
      "(epoch: 124, iters: 120, time: 0.125, data: 0.002) D_A: 0.207 G_A: 0.358 cycle_A: 0.394 idt_A: 0.170 D_B: 0.229 G_B: 0.229 cycle_B: 0.454 idt_B: 0.144 \n",
      "(epoch: 124, iters: 320, time: 0.063, data: 0.001) D_A: 0.220 G_A: 0.147 cycle_A: 0.398 idt_A: 0.121 D_B: 0.184 G_B: 0.466 cycle_B: 0.421 idt_B: 0.140 \n",
      "(epoch: 124, iters: 520, time: 0.063, data: 0.002) D_A: 0.206 G_A: 0.272 cycle_A: 0.415 idt_A: 0.139 D_B: 0.195 G_B: 0.175 cycle_B: 0.405 idt_B: 0.163 \n",
      "(epoch: 124, iters: 720, time: 0.063, data: 0.002) D_A: 0.199 G_A: 0.384 cycle_A: 0.365 idt_A: 0.190 D_B: 0.208 G_B: 0.369 cycle_B: 0.407 idt_B: 0.185 \n",
      "(epoch: 124, iters: 920, time: 0.063, data: 0.002) D_A: 0.161 G_A: 0.499 cycle_A: 0.407 idt_A: 0.154 D_B: 0.175 G_B: 0.348 cycle_B: 0.432 idt_B: 0.142 \n",
      "(epoch: 124, iters: 1120, time: 0.063, data: 0.001) D_A: 0.215 G_A: 0.302 cycle_A: 0.364 idt_A: 0.148 D_B: 0.205 G_B: 0.337 cycle_B: 0.394 idt_B: 0.180 \n",
      "End of epoch 124 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001505 -> 0.0001485\n",
      "(epoch: 125, iters: 160, time: 0.125, data: 0.002) D_A: 0.220 G_A: 0.223 cycle_A: 0.440 idt_A: 0.177 D_B: 0.161 G_B: 0.519 cycle_B: 0.538 idt_B: 0.157 \n",
      "(epoch: 125, iters: 360, time: 0.063, data: 0.002) D_A: 0.234 G_A: 0.161 cycle_A: 0.555 idt_A: 0.150 D_B: 0.278 G_B: 0.134 cycle_B: 0.388 idt_B: 0.195 \n",
      "(epoch: 125, iters: 560, time: 0.063, data: 0.002) D_A: 0.184 G_A: 0.403 cycle_A: 0.527 idt_A: 0.196 D_B: 0.247 G_B: 0.504 cycle_B: 0.433 idt_B: 0.171 \n",
      "(epoch: 125, iters: 760, time: 0.063, data: 0.002) D_A: 0.169 G_A: 0.345 cycle_A: 0.349 idt_A: 0.146 D_B: 0.152 G_B: 0.330 cycle_B: 0.446 idt_B: 0.168 \n",
      "(epoch: 125, iters: 960, time: 0.063, data: 0.002) D_A: 0.158 G_A: 0.422 cycle_A: 0.436 idt_A: 0.223 D_B: 0.197 G_B: 0.318 cycle_B: 0.495 idt_B: 0.176 \n",
      "(epoch: 125, iters: 1160, time: 0.063, data: 0.002) D_A: 0.236 G_A: 0.489 cycle_A: 0.454 idt_A: 0.141 D_B: 0.185 G_B: 0.354 cycle_B: 0.473 idt_B: 0.222 \n",
      "saving the latest model (epoch 125, total_iters 145000)\n",
      "saving the model at the end of epoch 125, iters 145000\n",
      "End of epoch 125 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001485 -> 0.0001465\n",
      "(epoch: 126, iters: 200, time: 0.124, data: 0.082) D_A: 0.206 G_A: 0.266 cycle_A: 0.405 idt_A: 0.140 D_B: 0.285 G_B: 0.175 cycle_B: 0.400 idt_B: 0.139 \n",
      "(epoch: 126, iters: 400, time: 0.063, data: 0.001) D_A: 0.197 G_A: 0.224 cycle_A: 0.443 idt_A: 0.150 D_B: 0.186 G_B: 0.352 cycle_B: 0.358 idt_B: 0.178 \n",
      "(epoch: 126, iters: 600, time: 0.063, data: 0.002) D_A: 0.184 G_A: 0.161 cycle_A: 0.497 idt_A: 0.178 D_B: 0.248 G_B: 0.805 cycle_B: 0.462 idt_B: 0.163 \n",
      "(epoch: 126, iters: 800, time: 0.063, data: 0.002) D_A: 0.184 G_A: 0.327 cycle_A: 0.435 idt_A: 0.135 D_B: 0.144 G_B: 0.326 cycle_B: 0.388 idt_B: 0.155 \n",
      "(epoch: 126, iters: 1000, time: 0.139, data: 0.001) D_A: 0.170 G_A: 0.260 cycle_A: 0.483 idt_A: 0.141 D_B: 0.210 G_B: 0.440 cycle_B: 0.404 idt_B: 0.170 \n",
      "End of epoch 126 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001465 -> 0.0001446\n",
      "(epoch: 127, iters: 40, time: 0.063, data: 0.002) D_A: 0.209 G_A: 0.522 cycle_A: 0.409 idt_A: 0.145 D_B: 0.196 G_B: 0.389 cycle_B: 0.364 idt_B: 0.130 \n",
      "(epoch: 127, iters: 240, time: 0.125, data: 0.001) D_A: 0.230 G_A: 0.192 cycle_A: 0.473 idt_A: 0.125 D_B: 0.156 G_B: 0.364 cycle_B: 0.469 idt_B: 0.145 \n",
      "(epoch: 127, iters: 440, time: 0.063, data: 0.002) D_A: 0.149 G_A: 0.324 cycle_A: 0.450 idt_A: 0.144 D_B: 0.157 G_B: 0.381 cycle_B: 0.412 idt_B: 0.221 \n",
      "(epoch: 127, iters: 640, time: 0.063, data: 0.002) D_A: 0.248 G_A: 0.141 cycle_A: 0.418 idt_A: 0.141 D_B: 0.213 G_B: 0.458 cycle_B: 0.369 idt_B: 0.137 \n",
      "(epoch: 127, iters: 840, time: 0.062, data: 0.002) D_A: 0.207 G_A: 0.278 cycle_A: 0.349 idt_A: 0.131 D_B: 0.190 G_B: 0.325 cycle_B: 0.381 idt_B: 0.161 \n",
      "(epoch: 127, iters: 1040, time: 0.063, data: 0.001) D_A: 0.197 G_A: 0.421 cycle_A: 0.515 idt_A: 0.171 D_B: 0.168 G_B: 0.391 cycle_B: 0.438 idt_B: 0.186 \n",
      "End of epoch 127 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001446 -> 0.0001426\n",
      "(epoch: 128, iters: 80, time: 0.063, data: 0.001) D_A: 0.210 G_A: 0.315 cycle_A: 0.393 idt_A: 0.158 D_B: 0.176 G_B: 0.578 cycle_B: 0.384 idt_B: 0.171 \n",
      "(epoch: 128, iters: 280, time: 0.126, data: 0.002) D_A: 0.213 G_A: 0.236 cycle_A: 0.398 idt_A: 0.197 D_B: 0.248 G_B: 0.360 cycle_B: 0.475 idt_B: 0.179 \n",
      "(epoch: 128, iters: 480, time: 0.063, data: 0.002) D_A: 0.221 G_A: 0.267 cycle_A: 0.398 idt_A: 0.137 D_B: 0.188 G_B: 0.421 cycle_B: 0.398 idt_B: 0.141 \n",
      "(epoch: 128, iters: 680, time: 0.127, data: 0.001) D_A: 0.243 G_A: 0.244 cycle_A: 0.429 idt_A: 0.136 D_B: 0.197 G_B: 0.387 cycle_B: 0.467 idt_B: 0.160 \n",
      "(epoch: 128, iters: 880, time: 0.063, data: 0.002) D_A: 0.305 G_A: 0.094 cycle_A: 0.432 idt_A: 0.170 D_B: 0.230 G_B: 0.323 cycle_B: 0.400 idt_B: 0.156 \n",
      "(epoch: 128, iters: 1080, time: 0.063, data: 0.001) D_A: 0.229 G_A: 0.144 cycle_A: 0.376 idt_A: 0.204 D_B: 0.266 G_B: 0.281 cycle_B: 0.513 idt_B: 0.136 \n",
      "End of epoch 128 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001426 -> 0.0001406\n",
      "(epoch: 129, iters: 120, time: 0.063, data: 0.002) D_A: 0.146 G_A: 0.326 cycle_A: 0.356 idt_A: 0.140 D_B: 0.192 G_B: 0.338 cycle_B: 0.394 idt_B: 0.143 \n",
      "(epoch: 129, iters: 320, time: 0.126, data: 0.002) D_A: 0.155 G_A: 0.524 cycle_A: 0.407 idt_A: 0.153 D_B: 0.149 G_B: 0.360 cycle_B: 0.400 idt_B: 0.164 \n",
      "(epoch: 129, iters: 520, time: 0.063, data: 0.002) D_A: 0.178 G_A: 0.330 cycle_A: 0.431 idt_A: 0.150 D_B: 0.166 G_B: 0.329 cycle_B: 0.383 idt_B: 0.138 \n",
      "(epoch: 129, iters: 720, time: 0.062, data: 0.002) D_A: 0.140 G_A: 0.461 cycle_A: 0.391 idt_A: 0.167 D_B: 0.167 G_B: 0.274 cycle_B: 0.449 idt_B: 0.152 \n",
      "(epoch: 129, iters: 920, time: 0.063, data: 0.002) D_A: 0.214 G_A: 0.444 cycle_A: 0.382 idt_A: 0.128 D_B: 0.230 G_B: 0.452 cycle_B: 0.366 idt_B: 0.189 \n",
      "(epoch: 129, iters: 1120, time: 0.063, data: 0.002) D_A: 0.186 G_A: 0.561 cycle_A: 0.522 idt_A: 0.173 D_B: 0.172 G_B: 0.346 cycle_B: 0.461 idt_B: 0.199 \n",
      "End of epoch 129 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001406 -> 0.0001386\n",
      "(epoch: 130, iters: 160, time: 0.063, data: 0.002) D_A: 0.202 G_A: 0.427 cycle_A: 0.373 idt_A: 0.162 D_B: 0.171 G_B: 0.314 cycle_B: 0.370 idt_B: 0.134 \n",
      "(epoch: 130, iters: 360, time: 0.126, data: 0.002) D_A: 0.215 G_A: 0.417 cycle_A: 0.431 idt_A: 0.163 D_B: 0.235 G_B: 0.335 cycle_B: 0.428 idt_B: 0.144 \n",
      "saving the latest model (epoch 130, total_iters 150000)\n",
      "(epoch: 130, iters: 560, time: 0.063, data: 0.001) D_A: 0.188 G_A: 0.359 cycle_A: 0.383 idt_A: 0.127 D_B: 0.274 G_B: 0.179 cycle_B: 0.357 idt_B: 0.137 \n",
      "(epoch: 130, iters: 760, time: 0.063, data: 0.002) D_A: 0.195 G_A: 0.327 cycle_A: 0.422 idt_A: 0.160 D_B: 0.196 G_B: 0.249 cycle_B: 0.466 idt_B: 0.159 \n",
      "(epoch: 130, iters: 960, time: 0.063, data: 0.001) D_A: 0.203 G_A: 0.286 cycle_A: 0.511 idt_A: 0.144 D_B: 0.217 G_B: 0.310 cycle_B: 0.423 idt_B: 0.170 \n",
      "(epoch: 130, iters: 1160, time: 0.063, data: 0.002) D_A: 0.174 G_A: 0.294 cycle_A: 0.378 idt_A: 0.151 D_B: 0.208 G_B: 0.470 cycle_B: 0.413 idt_B: 0.129 \n",
      "saving the model at the end of epoch 130, iters 150800\n",
      "End of epoch 130 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001386 -> 0.0001366\n",
      "(epoch: 131, iters: 200, time: 0.063, data: 0.109) D_A: 0.205 G_A: 0.361 cycle_A: 0.348 idt_A: 0.132 D_B: 0.237 G_B: 0.316 cycle_B: 0.378 idt_B: 0.130 \n",
      "(epoch: 131, iters: 400, time: 0.125, data: 0.002) D_A: 0.170 G_A: 0.414 cycle_A: 0.397 idt_A: 0.174 D_B: 0.223 G_B: 0.185 cycle_B: 0.460 idt_B: 0.145 \n",
      "(epoch: 131, iters: 600, time: 0.063, data: 0.002) D_A: 0.348 G_A: 0.076 cycle_A: 0.417 idt_A: 0.153 D_B: 0.176 G_B: 0.290 cycle_B: 0.389 idt_B: 0.123 \n",
      "(epoch: 131, iters: 800, time: 0.063, data: 0.001) D_A: 0.185 G_A: 0.299 cycle_A: 0.442 idt_A: 0.123 D_B: 0.184 G_B: 0.469 cycle_B: 0.374 idt_B: 0.158 \n",
      "(epoch: 131, iters: 1000, time: 0.063, data: 0.002) D_A: 0.183 G_A: 0.227 cycle_A: 0.415 idt_A: 0.140 D_B: 0.266 G_B: 0.481 cycle_B: 0.342 idt_B: 0.118 \n",
      "End of epoch 131 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001366 -> 0.0001347\n",
      "(epoch: 132, iters: 40, time: 0.124, data: 0.002) D_A: 0.197 G_A: 0.509 cycle_A: 0.474 idt_A: 0.162 D_B: 0.174 G_B: 0.256 cycle_B: 0.434 idt_B: 0.168 \n",
      "(epoch: 132, iters: 240, time: 0.063, data: 0.001) D_A: 0.204 G_A: 0.442 cycle_A: 0.377 idt_A: 0.172 D_B: 0.183 G_B: 0.420 cycle_B: 0.393 idt_B: 0.143 \n",
      "(epoch: 132, iters: 440, time: 0.063, data: 0.002) D_A: 0.174 G_A: 0.311 cycle_A: 0.415 idt_A: 0.149 D_B: 0.141 G_B: 0.453 cycle_B: 0.438 idt_B: 0.156 \n",
      "(epoch: 132, iters: 640, time: 0.063, data: 0.001) D_A: 0.187 G_A: 0.446 cycle_A: 0.421 idt_A: 0.125 D_B: 0.213 G_B: 0.252 cycle_B: 0.374 idt_B: 0.145 \n",
      "(epoch: 132, iters: 840, time: 0.063, data: 0.002) D_A: 0.152 G_A: 0.416 cycle_A: 0.385 idt_A: 0.231 D_B: 0.208 G_B: 0.244 cycle_B: 0.507 idt_B: 0.153 \n",
      "(epoch: 132, iters: 1040, time: 0.063, data: 0.001) D_A: 0.186 G_A: 0.558 cycle_A: 0.399 idt_A: 0.123 D_B: 0.149 G_B: 0.604 cycle_B: 0.353 idt_B: 0.139 \n",
      "End of epoch 132 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001347 -> 0.0001327\n",
      "(epoch: 133, iters: 80, time: 0.125, data: 0.001) D_A: 0.234 G_A: 0.418 cycle_A: 0.358 idt_A: 0.131 D_B: 0.195 G_B: 0.306 cycle_B: 0.394 idt_B: 0.108 \n",
      "(epoch: 133, iters: 280, time: 0.063, data: 0.001) D_A: 0.193 G_A: 0.420 cycle_A: 0.444 idt_A: 0.142 D_B: 0.152 G_B: 0.259 cycle_B: 0.371 idt_B: 0.159 \n",
      "(epoch: 133, iters: 480, time: 0.063, data: 0.002) D_A: 0.172 G_A: 0.347 cycle_A: 0.433 idt_A: 0.146 D_B: 0.213 G_B: 0.221 cycle_B: 0.398 idt_B: 0.128 \n",
      "(epoch: 133, iters: 680, time: 0.063, data: 0.002) D_A: 0.198 G_A: 0.255 cycle_A: 0.380 idt_A: 0.130 D_B: 0.194 G_B: 0.283 cycle_B: 0.442 idt_B: 0.123 \n",
      "(epoch: 133, iters: 880, time: 0.139, data: 0.001) D_A: 0.181 G_A: 0.460 cycle_A: 0.476 idt_A: 0.172 D_B: 0.168 G_B: 0.301 cycle_B: 0.386 idt_B: 0.131 \n",
      "(epoch: 133, iters: 1080, time: 0.063, data: 0.002) D_A: 0.249 G_A: 0.151 cycle_A: 0.420 idt_A: 0.131 D_B: 0.194 G_B: 0.374 cycle_B: 0.407 idt_B: 0.164 \n",
      "End of epoch 133 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001327 -> 0.0001307\n",
      "(epoch: 134, iters: 120, time: 0.126, data: 0.001) D_A: 0.192 G_A: 0.381 cycle_A: 0.475 idt_A: 0.187 D_B: 0.164 G_B: 0.451 cycle_B: 0.465 idt_B: 0.143 \n",
      "(epoch: 134, iters: 320, time: 0.063, data: 0.001) D_A: 0.215 G_A: 0.438 cycle_A: 0.389 idt_A: 0.135 D_B: 0.260 G_B: 0.253 cycle_B: 0.417 idt_B: 0.175 \n",
      "(epoch: 134, iters: 520, time: 0.063, data: 0.002) D_A: 0.217 G_A: 0.174 cycle_A: 0.350 idt_A: 0.146 D_B: 0.223 G_B: 0.542 cycle_B: 0.390 idt_B: 0.126 \n",
      "(epoch: 134, iters: 720, time: 0.063, data: 0.002) D_A: 0.208 G_A: 0.263 cycle_A: 0.394 idt_A: 0.177 D_B: 0.204 G_B: 0.204 cycle_B: 0.399 idt_B: 0.137 \n",
      "saving the latest model (epoch 134, total_iters 155000)\n",
      "(epoch: 134, iters: 920, time: 0.063, data: 0.001) D_A: 0.196 G_A: 0.203 cycle_A: 0.492 idt_A: 0.133 D_B: 0.193 G_B: 0.317 cycle_B: 0.341 idt_B: 0.142 \n",
      "(epoch: 134, iters: 1120, time: 0.063, data: 0.002) D_A: 0.218 G_A: 0.319 cycle_A: 0.418 idt_A: 0.130 D_B: 0.186 G_B: 0.314 cycle_B: 0.354 idt_B: 0.114 \n",
      "End of epoch 134 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001307 -> 0.0001287\n",
      "(epoch: 135, iters: 160, time: 0.127, data: 0.002) D_A: 0.167 G_A: 0.341 cycle_A: 0.343 idt_A: 0.120 D_B: 0.223 G_B: 0.487 cycle_B: 0.351 idt_B: 0.136 \n",
      "(epoch: 135, iters: 360, time: 0.063, data: 0.002) D_A: 0.180 G_A: 0.487 cycle_A: 0.374 idt_A: 0.112 D_B: 0.181 G_B: 0.411 cycle_B: 0.318 idt_B: 0.136 \n",
      "(epoch: 135, iters: 560, time: 0.126, data: 0.002) D_A: 0.192 G_A: 0.451 cycle_A: 0.418 idt_A: 0.149 D_B: 0.153 G_B: 0.455 cycle_B: 0.398 idt_B: 0.130 \n",
      "(epoch: 135, iters: 760, time: 0.063, data: 0.002) D_A: 0.171 G_A: 0.361 cycle_A: 0.384 idt_A: 0.200 D_B: 0.167 G_B: 0.307 cycle_B: 0.433 idt_B: 0.130 \n",
      "(epoch: 135, iters: 960, time: 0.063, data: 0.002) D_A: 0.163 G_A: 0.385 cycle_A: 0.480 idt_A: 0.135 D_B: 0.170 G_B: 0.483 cycle_B: 0.361 idt_B: 0.156 \n",
      "(epoch: 135, iters: 1160, time: 0.063, data: 0.002) D_A: 0.190 G_A: 0.225 cycle_A: 0.564 idt_A: 0.126 D_B: 0.200 G_B: 0.441 cycle_B: 0.363 idt_B: 0.175 \n",
      "saving the model at the end of epoch 135, iters 156600\n",
      "End of epoch 135 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001287 -> 0.0001267\n",
      "(epoch: 136, iters: 200, time: 0.127, data: 0.089) D_A: 0.199 G_A: 0.310 cycle_A: 0.424 idt_A: 0.120 D_B: 0.181 G_B: 0.237 cycle_B: 0.368 idt_B: 0.143 \n",
      "(epoch: 136, iters: 400, time: 0.063, data: 0.002) D_A: 0.167 G_A: 0.388 cycle_A: 0.547 idt_A: 0.118 D_B: 0.246 G_B: 0.291 cycle_B: 0.355 idt_B: 0.276 \n",
      "(epoch: 136, iters: 600, time: 0.063, data: 0.002) D_A: 0.224 G_A: 0.467 cycle_A: 0.439 idt_A: 0.117 D_B: 0.193 G_B: 0.234 cycle_B: 0.343 idt_B: 0.171 \n",
      "(epoch: 136, iters: 800, time: 0.062, data: 0.002) D_A: 0.198 G_A: 0.439 cycle_A: 0.399 idt_A: 0.138 D_B: 0.240 G_B: 0.429 cycle_B: 0.366 idt_B: 0.138 \n",
      "(epoch: 136, iters: 1000, time: 0.063, data: 0.002) D_A: 0.166 G_A: 0.280 cycle_A: 0.374 idt_A: 0.190 D_B: 0.151 G_B: 0.321 cycle_B: 0.475 idt_B: 0.120 \n",
      "End of epoch 136 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001267 -> 0.0001248\n",
      "(epoch: 137, iters: 40, time: 0.063, data: 0.002) D_A: 0.191 G_A: 0.280 cycle_A: 0.403 idt_A: 0.135 D_B: 0.201 G_B: 0.292 cycle_B: 0.391 idt_B: 0.166 \n",
      "(epoch: 137, iters: 240, time: 0.128, data: 0.001) D_A: 0.163 G_A: 0.285 cycle_A: 0.351 idt_A: 0.134 D_B: 0.140 G_B: 0.318 cycle_B: 0.368 idt_B: 0.153 \n",
      "(epoch: 137, iters: 440, time: 0.063, data: 0.002) D_A: 0.227 G_A: 0.273 cycle_A: 0.406 idt_A: 0.152 D_B: 0.228 G_B: 0.356 cycle_B: 0.415 idt_B: 0.119 \n",
      "(epoch: 137, iters: 640, time: 0.063, data: 0.001) D_A: 0.198 G_A: 0.289 cycle_A: 0.368 idt_A: 0.172 D_B: 0.195 G_B: 0.144 cycle_B: 0.443 idt_B: 0.131 \n",
      "(epoch: 137, iters: 840, time: 0.063, data: 0.002) D_A: 0.179 G_A: 0.320 cycle_A: 0.407 idt_A: 0.109 D_B: 0.175 G_B: 0.256 cycle_B: 0.328 idt_B: 0.140 \n",
      "(epoch: 137, iters: 1040, time: 0.063, data: 0.002) D_A: 0.182 G_A: 0.331 cycle_A: 0.402 idt_A: 0.122 D_B: 0.237 G_B: 0.311 cycle_B: 0.388 idt_B: 0.144 \n",
      "End of epoch 137 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001248 -> 0.0001228\n",
      "(epoch: 138, iters: 80, time: 0.063, data: 0.002) D_A: 0.152 G_A: 0.333 cycle_A: 0.401 idt_A: 0.124 D_B: 0.210 G_B: 0.313 cycle_B: 0.350 idt_B: 0.126 \n",
      "(epoch: 138, iters: 280, time: 0.128, data: 0.002) D_A: 0.224 G_A: 0.278 cycle_A: 0.359 idt_A: 0.112 D_B: 0.198 G_B: 0.414 cycle_B: 0.325 idt_B: 0.115 \n",
      "(epoch: 138, iters: 480, time: 0.063, data: 0.001) D_A: 0.184 G_A: 0.389 cycle_A: 0.407 idt_A: 0.108 D_B: 0.273 G_B: 0.170 cycle_B: 0.349 idt_B: 0.130 \n",
      "(epoch: 138, iters: 680, time: 0.063, data: 0.002) D_A: 0.216 G_A: 0.331 cycle_A: 0.441 idt_A: 0.138 D_B: 0.181 G_B: 0.272 cycle_B: 0.390 idt_B: 0.134 \n",
      "(epoch: 138, iters: 880, time: 0.063, data: 0.002) D_A: 0.206 G_A: 0.287 cycle_A: 0.412 idt_A: 0.151 D_B: 0.232 G_B: 0.283 cycle_B: 0.406 idt_B: 0.186 \n",
      "(epoch: 138, iters: 1080, time: 0.129, data: 0.002) D_A: 0.217 G_A: 0.279 cycle_A: 0.369 idt_A: 0.129 D_B: 0.227 G_B: 0.146 cycle_B: 0.374 idt_B: 0.147 \n",
      "saving the latest model (epoch 138, total_iters 160000)\n",
      "End of epoch 138 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001228 -> 0.0001208\n",
      "(epoch: 139, iters: 120, time: 0.063, data: 0.001) D_A: 0.203 G_A: 0.415 cycle_A: 0.344 idt_A: 0.154 D_B: 0.236 G_B: 0.368 cycle_B: 0.413 idt_B: 0.133 \n",
      "(epoch: 139, iters: 320, time: 0.144, data: 0.002) D_A: 0.169 G_A: 0.308 cycle_A: 0.386 idt_A: 0.149 D_B: 0.223 G_B: 0.465 cycle_B: 0.350 idt_B: 0.125 \n",
      "(epoch: 139, iters: 520, time: 0.063, data: 0.002) D_A: 0.176 G_A: 0.316 cycle_A: 0.433 idt_A: 0.185 D_B: 0.197 G_B: 0.256 cycle_B: 0.438 idt_B: 0.173 \n",
      "(epoch: 139, iters: 720, time: 0.063, data: 0.002) D_A: 0.211 G_A: 0.187 cycle_A: 0.427 idt_A: 0.143 D_B: 0.180 G_B: 0.448 cycle_B: 0.410 idt_B: 0.155 \n",
      "(epoch: 139, iters: 920, time: 0.063, data: 0.001) D_A: 0.154 G_A: 0.397 cycle_A: 0.415 idt_A: 0.173 D_B: 0.198 G_B: 0.368 cycle_B: 0.428 idt_B: 0.131 \n",
      "(epoch: 139, iters: 1120, time: 0.063, data: 0.002) D_A: 0.132 G_A: 0.412 cycle_A: 0.365 idt_A: 0.123 D_B: 0.169 G_B: 0.290 cycle_B: 0.375 idt_B: 0.127 \n",
      "End of epoch 139 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001208 -> 0.0001188\n",
      "(epoch: 140, iters: 160, time: 0.063, data: 0.002) D_A: 0.168 G_A: 0.406 cycle_A: 0.359 idt_A: 0.116 D_B: 0.177 G_B: 0.419 cycle_B: 0.356 idt_B: 0.123 \n",
      "(epoch: 140, iters: 360, time: 0.130, data: 0.002) D_A: 0.231 G_A: 0.432 cycle_A: 0.386 idt_A: 0.139 D_B: 0.171 G_B: 0.362 cycle_B: 0.364 idt_B: 0.130 \n",
      "(epoch: 140, iters: 560, time: 0.063, data: 0.001) D_A: 0.212 G_A: 0.617 cycle_A: 0.349 idt_A: 0.144 D_B: 0.217 G_B: 0.475 cycle_B: 0.420 idt_B: 0.120 \n",
      "(epoch: 140, iters: 760, time: 0.129, data: 0.002) D_A: 0.216 G_A: 0.266 cycle_A: 0.467 idt_A: 0.135 D_B: 0.245 G_B: 0.329 cycle_B: 0.376 idt_B: 0.155 \n",
      "(epoch: 140, iters: 960, time: 0.063, data: 0.001) D_A: 0.393 G_A: 0.970 cycle_A: 0.459 idt_A: 0.139 D_B: 0.230 G_B: 0.351 cycle_B: 0.364 idt_B: 0.137 \n",
      "(epoch: 140, iters: 1160, time: 0.063, data: 0.001) D_A: 0.224 G_A: 0.349 cycle_A: 0.385 idt_A: 0.141 D_B: 0.236 G_B: 0.442 cycle_B: 0.379 idt_B: 0.146 \n",
      "saving the model at the end of epoch 140, iters 162400\n",
      "End of epoch 140 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001188 -> 0.0001168\n",
      "(epoch: 141, iters: 200, time: 0.063, data: 0.155) D_A: 0.132 G_A: 0.377 cycle_A: 0.388 idt_A: 0.137 D_B: 0.193 G_B: 0.403 cycle_B: 0.338 idt_B: 0.135 \n",
      "(epoch: 141, iters: 400, time: 0.129, data: 0.002) D_A: 0.135 G_A: 0.406 cycle_A: 0.377 idt_A: 0.127 D_B: 0.163 G_B: 0.272 cycle_B: 0.365 idt_B: 0.134 \n",
      "(epoch: 141, iters: 600, time: 0.063, data: 0.002) D_A: 0.207 G_A: 0.313 cycle_A: 0.374 idt_A: 0.122 D_B: 0.199 G_B: 0.318 cycle_B: 0.349 idt_B: 0.115 \n",
      "(epoch: 141, iters: 800, time: 0.063, data: 0.002) D_A: 0.177 G_A: 0.171 cycle_A: 0.372 idt_A: 0.153 D_B: 0.200 G_B: 0.345 cycle_B: 0.464 idt_B: 0.124 \n",
      "(epoch: 141, iters: 1000, time: 0.063, data: 0.002) D_A: 0.178 G_A: 0.424 cycle_A: 0.573 idt_A: 0.136 D_B: 0.226 G_B: 0.450 cycle_B: 0.351 idt_B: 0.189 \n",
      "End of epoch 141 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001168 -> 0.0001149\n",
      "(epoch: 142, iters: 40, time: 0.130, data: 0.001) D_A: 0.314 G_A: 0.906 cycle_A: 0.396 idt_A: 0.117 D_B: 0.212 G_B: 0.271 cycle_B: 0.334 idt_B: 0.118 \n",
      "(epoch: 142, iters: 240, time: 0.063, data: 0.001) D_A: 0.206 G_A: 0.352 cycle_A: 0.371 idt_A: 0.140 D_B: 0.167 G_B: 0.360 cycle_B: 0.363 idt_B: 0.111 \n",
      "(epoch: 142, iters: 440, time: 0.129, data: 0.002) D_A: 0.194 G_A: 0.188 cycle_A: 0.359 idt_A: 0.134 D_B: 0.209 G_B: 0.308 cycle_B: 0.437 idt_B: 0.130 \n",
      "(epoch: 142, iters: 640, time: 0.063, data: 0.002) D_A: 0.190 G_A: 0.297 cycle_A: 0.376 idt_A: 0.131 D_B: 0.219 G_B: 0.313 cycle_B: 0.426 idt_B: 0.145 \n",
      "(epoch: 142, iters: 840, time: 0.063, data: 0.002) D_A: 0.135 G_A: 0.438 cycle_A: 0.394 idt_A: 0.122 D_B: 0.180 G_B: 0.387 cycle_B: 0.325 idt_B: 0.157 \n",
      "(epoch: 142, iters: 1040, time: 0.063, data: 0.002) D_A: 0.239 G_A: 0.770 cycle_A: 0.408 idt_A: 0.159 D_B: 0.185 G_B: 0.282 cycle_B: 0.387 idt_B: 0.125 \n",
      "End of epoch 142 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001149 -> 0.0001129\n",
      "(epoch: 143, iters: 80, time: 0.130, data: 0.002) D_A: 0.168 G_A: 0.360 cycle_A: 0.355 idt_A: 0.111 D_B: 0.179 G_B: 0.361 cycle_B: 0.369 idt_B: 0.126 \n",
      "(epoch: 143, iters: 280, time: 0.063, data: 0.002) D_A: 0.190 G_A: 0.414 cycle_A: 0.368 idt_A: 0.114 D_B: 0.191 G_B: 0.385 cycle_B: 0.361 idt_B: 0.133 \n",
      "saving the latest model (epoch 143, total_iters 165000)\n",
      "(epoch: 143, iters: 480, time: 0.063, data: 0.001) D_A: 0.155 G_A: 0.423 cycle_A: 0.381 idt_A: 0.117 D_B: 0.230 G_B: 0.319 cycle_B: 0.361 idt_B: 0.129 \n",
      "(epoch: 143, iters: 680, time: 0.063, data: 0.002) D_A: 0.203 G_A: 0.312 cycle_A: 0.352 idt_A: 0.119 D_B: 0.167 G_B: 0.420 cycle_B: 0.344 idt_B: 0.142 \n",
      "(epoch: 143, iters: 880, time: 0.063, data: 0.002) D_A: 0.200 G_A: 0.366 cycle_A: 0.389 idt_A: 0.135 D_B: 0.172 G_B: 0.374 cycle_B: 0.411 idt_B: 0.133 \n",
      "(epoch: 143, iters: 1080, time: 0.063, data: 0.001) D_A: 0.184 G_A: 0.583 cycle_A: 0.491 idt_A: 0.175 D_B: 0.174 G_B: 0.412 cycle_B: 0.387 idt_B: 0.130 \n",
      "End of epoch 143 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001129 -> 0.0001109\n",
      "(epoch: 144, iters: 120, time: 0.144, data: 0.002) D_A: 0.176 G_A: 0.241 cycle_A: 0.368 idt_A: 0.142 D_B: 0.154 G_B: 0.337 cycle_B: 0.393 idt_B: 0.136 \n",
      "(epoch: 144, iters: 320, time: 0.063, data: 0.001) D_A: 0.154 G_A: 0.253 cycle_A: 0.358 idt_A: 0.127 D_B: 0.184 G_B: 0.308 cycle_B: 0.389 idt_B: 0.094 \n",
      "(epoch: 144, iters: 520, time: 0.063, data: 0.002) D_A: 0.405 G_A: 0.984 cycle_A: 0.426 idt_A: 0.142 D_B: 0.221 G_B: 0.170 cycle_B: 0.356 idt_B: 0.168 \n",
      "(epoch: 144, iters: 720, time: 0.063, data: 0.002) D_A: 0.286 G_A: 0.328 cycle_A: 0.389 idt_A: 0.161 D_B: 0.147 G_B: 0.319 cycle_B: 0.377 idt_B: 0.136 \n",
      "(epoch: 144, iters: 920, time: 0.063, data: 0.002) D_A: 0.256 G_A: 0.260 cycle_A: 0.402 idt_A: 0.144 D_B: 0.214 G_B: 0.315 cycle_B: 0.419 idt_B: 0.156 \n",
      "(epoch: 144, iters: 1120, time: 0.063, data: 0.002) D_A: 0.253 G_A: 0.303 cycle_A: 0.360 idt_A: 0.129 D_B: 0.197 G_B: 0.412 cycle_B: 0.374 idt_B: 0.129 \n",
      "End of epoch 144 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001109 -> 0.0001089\n",
      "(epoch: 145, iters: 160, time: 0.129, data: 0.002) D_A: 0.258 G_A: 0.301 cycle_A: 0.400 idt_A: 0.118 D_B: 0.180 G_B: 0.299 cycle_B: 0.352 idt_B: 0.134 \n",
      "(epoch: 145, iters: 360, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.288 cycle_A: 0.293 idt_A: 0.141 D_B: 0.198 G_B: 0.498 cycle_B: 0.401 idt_B: 0.100 \n",
      "(epoch: 145, iters: 560, time: 0.063, data: 0.002) D_A: 0.258 G_A: 0.260 cycle_A: 0.294 idt_A: 0.155 D_B: 0.214 G_B: 0.364 cycle_B: 0.346 idt_B: 0.104 \n",
      "(epoch: 145, iters: 760, time: 0.063, data: 0.002) D_A: 0.249 G_A: 0.276 cycle_A: 0.339 idt_A: 0.154 D_B: 0.207 G_B: 0.295 cycle_B: 0.411 idt_B: 0.152 \n",
      "(epoch: 145, iters: 960, time: 0.129, data: 0.002) D_A: 0.247 G_A: 0.261 cycle_A: 0.316 idt_A: 0.115 D_B: 0.209 G_B: 0.287 cycle_B: 0.328 idt_B: 0.127 \n",
      "(epoch: 145, iters: 1160, time: 0.063, data: 0.002) D_A: 0.260 G_A: 0.277 cycle_A: 0.402 idt_A: 0.145 D_B: 0.183 G_B: 0.249 cycle_B: 0.433 idt_B: 0.139 \n",
      "saving the model at the end of epoch 145, iters 168200\n",
      "End of epoch 145 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001089 -> 0.0001069\n",
      "(epoch: 146, iters: 200, time: 0.131, data: 0.117) D_A: 0.259 G_A: 0.275 cycle_A: 0.289 idt_A: 0.132 D_B: 0.188 G_B: 0.386 cycle_B: 0.347 idt_B: 0.146 \n",
      "(epoch: 146, iters: 400, time: 0.063, data: 0.002) D_A: 0.245 G_A: 0.265 cycle_A: 0.340 idt_A: 0.117 D_B: 0.208 G_B: 0.306 cycle_B: 0.370 idt_B: 0.152 \n",
      "(epoch: 146, iters: 600, time: 0.063, data: 0.002) D_A: 0.264 G_A: 0.224 cycle_A: 0.347 idt_A: 0.147 D_B: 0.179 G_B: 0.367 cycle_B: 0.435 idt_B: 0.132 \n",
      "(epoch: 146, iters: 800, time: 0.063, data: 0.001) D_A: 0.250 G_A: 0.284 cycle_A: 0.313 idt_A: 0.166 D_B: 0.181 G_B: 0.480 cycle_B: 0.400 idt_B: 0.141 \n",
      "(epoch: 146, iters: 1000, time: 0.063, data: 0.002) D_A: 0.258 G_A: 0.253 cycle_A: 0.292 idt_A: 0.130 D_B: 0.166 G_B: 0.307 cycle_B: 0.353 idt_B: 0.123 \n",
      "End of epoch 146 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001069 -> 0.0001050\n",
      "(epoch: 147, iters: 40, time: 0.063, data: 0.002) D_A: 0.260 G_A: 0.255 cycle_A: 0.304 idt_A: 0.122 D_B: 0.186 G_B: 0.328 cycle_B: 0.428 idt_B: 0.110 \n",
      "(epoch: 147, iters: 240, time: 0.130, data: 0.002) D_A: 0.244 G_A: 0.255 cycle_A: 0.282 idt_A: 0.126 D_B: 0.207 G_B: 0.385 cycle_B: 0.369 idt_B: 0.109 \n",
      "(epoch: 147, iters: 440, time: 0.063, data: 0.002) D_A: 0.255 G_A: 0.263 cycle_A: 0.328 idt_A: 0.181 D_B: 0.197 G_B: 0.216 cycle_B: 0.463 idt_B: 0.137 \n",
      "(epoch: 147, iters: 640, time: 0.130, data: 0.002) D_A: 0.244 G_A: 0.276 cycle_A: 0.388 idt_A: 0.135 D_B: 0.167 G_B: 0.305 cycle_B: 0.344 idt_B: 0.165 \n",
      "saving the latest model (epoch 147, total_iters 170000)\n",
      "(epoch: 147, iters: 840, time: 0.063, data: 0.002) D_A: 0.258 G_A: 0.256 cycle_A: 0.362 idt_A: 0.122 D_B: 0.188 G_B: 0.357 cycle_B: 0.340 idt_B: 0.147 \n",
      "(epoch: 147, iters: 1040, time: 0.063, data: 0.001) D_A: 0.248 G_A: 0.276 cycle_A: 0.279 idt_A: 0.111 D_B: 0.181 G_B: 0.324 cycle_B: 0.367 idt_B: 0.116 \n",
      "End of epoch 147 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001050 -> 0.0001030\n",
      "(epoch: 148, iters: 80, time: 0.063, data: 0.002) D_A: 0.244 G_A: 0.251 cycle_A: 0.296 idt_A: 0.184 D_B: 0.206 G_B: 0.339 cycle_B: 0.406 idt_B: 0.126 \n",
      "(epoch: 148, iters: 280, time: 0.130, data: 0.002) D_A: 0.260 G_A: 0.265 cycle_A: 0.349 idt_A: 0.170 D_B: 0.180 G_B: 0.286 cycle_B: 0.408 idt_B: 0.151 \n",
      "(epoch: 148, iters: 480, time: 0.063, data: 0.002) D_A: 0.251 G_A: 0.266 cycle_A: 0.313 idt_A: 0.108 D_B: 0.227 G_B: 0.314 cycle_B: 0.354 idt_B: 0.111 \n",
      "(epoch: 148, iters: 680, time: 0.063, data: 0.002) D_A: 0.261 G_A: 0.264 cycle_A: 0.284 idt_A: 0.143 D_B: 0.181 G_B: 0.311 cycle_B: 0.334 idt_B: 0.115 \n",
      "(epoch: 148, iters: 880, time: 0.063, data: 0.002) D_A: 0.263 G_A: 0.240 cycle_A: 0.299 idt_A: 0.123 D_B: 0.185 G_B: 0.415 cycle_B: 0.330 idt_B: 0.124 \n",
      "(epoch: 148, iters: 1080, time: 0.063, data: 0.002) D_A: 0.274 G_A: 0.253 cycle_A: 0.304 idt_A: 0.114 D_B: 0.223 G_B: 0.299 cycle_B: 0.391 idt_B: 0.123 \n",
      "End of epoch 148 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001030 -> 0.0001010\n",
      "(epoch: 149, iters: 120, time: 0.063, data: 0.002) D_A: 0.263 G_A: 0.250 cycle_A: 0.314 idt_A: 0.124 D_B: 0.209 G_B: 0.244 cycle_B: 0.353 idt_B: 0.120 \n",
      "(epoch: 149, iters: 320, time: 0.131, data: 0.002) D_A: 0.260 G_A: 0.250 cycle_A: 0.315 idt_A: 0.129 D_B: 0.253 G_B: 0.229 cycle_B: 0.343 idt_B: 0.143 \n",
      "(epoch: 149, iters: 520, time: 0.063, data: 0.001) D_A: 0.254 G_A: 0.271 cycle_A: 0.266 idt_A: 0.112 D_B: 0.166 G_B: 0.380 cycle_B: 0.339 idt_B: 0.111 \n",
      "(epoch: 149, iters: 720, time: 0.063, data: 0.001) D_A: 0.245 G_A: 0.281 cycle_A: 0.309 idt_A: 0.142 D_B: 0.174 G_B: 0.396 cycle_B: 0.399 idt_B: 0.149 \n",
      "(epoch: 149, iters: 920, time: 0.063, data: 0.002) D_A: 0.246 G_A: 0.268 cycle_A: 0.356 idt_A: 0.121 D_B: 0.174 G_B: 0.293 cycle_B: 0.374 idt_B: 0.154 \n",
      "(epoch: 149, iters: 1120, time: 0.063, data: 0.002) D_A: 0.242 G_A: 0.254 cycle_A: 0.265 idt_A: 0.130 D_B: 0.201 G_B: 0.266 cycle_B: 0.333 idt_B: 0.105 \n",
      "End of epoch 149 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001010 -> 0.0000990\n",
      "(epoch: 150, iters: 160, time: 0.063, data: 0.002) D_A: 0.258 G_A: 0.254 cycle_A: 0.249 idt_A: 0.107 D_B: 0.177 G_B: 0.206 cycle_B: 0.358 idt_B: 0.102 \n",
      "(epoch: 150, iters: 360, time: 0.145, data: 0.001) D_A: 0.248 G_A: 0.273 cycle_A: 0.311 idt_A: 0.119 D_B: 0.173 G_B: 0.431 cycle_B: 0.366 idt_B: 0.119 \n",
      "(epoch: 150, iters: 560, time: 0.063, data: 0.001) D_A: 0.260 G_A: 0.259 cycle_A: 0.334 idt_A: 0.111 D_B: 0.189 G_B: 0.493 cycle_B: 0.360 idt_B: 0.122 \n",
      "(epoch: 150, iters: 760, time: 0.063, data: 0.001) D_A: 0.244 G_A: 0.272 cycle_A: 0.291 idt_A: 0.137 D_B: 0.184 G_B: 0.456 cycle_B: 0.365 idt_B: 0.121 \n",
      "(epoch: 150, iters: 960, time: 0.063, data: 0.002) D_A: 0.256 G_A: 0.275 cycle_A: 0.284 idt_A: 0.123 D_B: 0.196 G_B: 0.199 cycle_B: 0.345 idt_B: 0.131 \n",
      "(epoch: 150, iters: 1160, time: 0.132, data: 0.001) D_A: 0.244 G_A: 0.270 cycle_A: 0.301 idt_A: 0.111 D_B: 0.176 G_B: 0.380 cycle_B: 0.331 idt_B: 0.124 \n",
      "saving the model at the end of epoch 150, iters 174000\n",
      "End of epoch 150 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000990 -> 0.0000970\n",
      "(epoch: 151, iters: 200, time: 0.063, data: 0.086) D_A: 0.229 G_A: 0.251 cycle_A: 0.297 idt_A: 0.133 D_B: 0.194 G_B: 0.349 cycle_B: 0.366 idt_B: 0.116 \n",
      "(epoch: 151, iters: 400, time: 0.131, data: 0.002) D_A: 0.244 G_A: 0.250 cycle_A: 0.257 idt_A: 0.124 D_B: 0.201 G_B: 0.348 cycle_B: 0.373 idt_B: 0.097 \n",
      "(epoch: 151, iters: 600, time: 0.063, data: 0.001) D_A: 0.240 G_A: 0.294 cycle_A: 0.256 idt_A: 0.123 D_B: 0.160 G_B: 0.291 cycle_B: 0.387 idt_B: 0.116 \n",
      "(epoch: 151, iters: 800, time: 0.063, data: 0.002) D_A: 0.245 G_A: 0.307 cycle_A: 0.293 idt_A: 0.120 D_B: 0.210 G_B: 0.349 cycle_B: 0.330 idt_B: 0.132 \n",
      "(epoch: 151, iters: 1000, time: 0.063, data: 0.001) D_A: 0.242 G_A: 0.240 cycle_A: 0.287 idt_A: 0.112 D_B: 0.142 G_B: 0.385 cycle_B: 0.353 idt_B: 0.108 \n",
      "saving the latest model (epoch 151, total_iters 175000)\n",
      "End of epoch 151 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000970 -> 0.0000950\n",
      "(epoch: 152, iters: 40, time: 0.133, data: 0.001) D_A: 0.232 G_A: 0.285 cycle_A: 0.426 idt_A: 0.108 D_B: 0.107 G_B: 0.370 cycle_B: 0.332 idt_B: 0.126 \n",
      "(epoch: 152, iters: 240, time: 0.063, data: 0.001) D_A: 0.222 G_A: 0.279 cycle_A: 0.323 idt_A: 0.137 D_B: 0.177 G_B: 0.275 cycle_B: 0.403 idt_B: 0.169 \n",
      "(epoch: 152, iters: 440, time: 0.063, data: 0.002) D_A: 0.231 G_A: 0.244 cycle_A: 0.342 idt_A: 0.121 D_B: 0.222 G_B: 0.435 cycle_B: 0.404 idt_B: 0.141 \n",
      "(epoch: 152, iters: 640, time: 0.063, data: 0.002) D_A: 0.218 G_A: 0.325 cycle_A: 0.341 idt_A: 0.119 D_B: 0.156 G_B: 0.349 cycle_B: 0.363 idt_B: 0.141 \n",
      "(epoch: 152, iters: 840, time: 0.133, data: 0.002) D_A: 0.257 G_A: 0.259 cycle_A: 0.266 idt_A: 0.129 D_B: 0.198 G_B: 0.306 cycle_B: 0.390 idt_B: 0.095 \n",
      "(epoch: 152, iters: 1040, time: 0.063, data: 0.002) D_A: 0.214 G_A: 0.302 cycle_A: 0.315 idt_A: 0.135 D_B: 0.192 G_B: 0.321 cycle_B: 0.383 idt_B: 0.123 \n",
      "End of epoch 152 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000950 -> 0.0000931\n",
      "(epoch: 153, iters: 80, time: 0.132, data: 0.002) D_A: 0.266 G_A: 0.342 cycle_A: 0.273 idt_A: 0.123 D_B: 0.176 G_B: 0.363 cycle_B: 0.363 idt_B: 0.103 \n",
      "(epoch: 153, iters: 280, time: 0.063, data: 0.002) D_A: 0.247 G_A: 0.306 cycle_A: 0.316 idt_A: 0.121 D_B: 0.185 G_B: 0.284 cycle_B: 0.352 idt_B: 0.121 \n",
      "(epoch: 153, iters: 480, time: 0.063, data: 0.002) D_A: 0.269 G_A: 0.294 cycle_A: 0.298 idt_A: 0.111 D_B: 0.183 G_B: 0.254 cycle_B: 0.364 idt_B: 0.122 \n",
      "(epoch: 153, iters: 680, time: 0.063, data: 0.002) D_A: 0.195 G_A: 0.309 cycle_A: 0.303 idt_A: 0.102 D_B: 0.195 G_B: 0.414 cycle_B: 0.290 idt_B: 0.107 \n",
      "(epoch: 153, iters: 880, time: 0.063, data: 0.002) D_A: 0.216 G_A: 0.353 cycle_A: 0.294 idt_A: 0.127 D_B: 0.206 G_B: 0.455 cycle_B: 0.357 idt_B: 0.108 \n",
      "(epoch: 153, iters: 1080, time: 0.063, data: 0.002) D_A: 0.227 G_A: 0.357 cycle_A: 0.294 idt_A: 0.107 D_B: 0.190 G_B: 0.562 cycle_B: 0.311 idt_B: 0.117 \n",
      "End of epoch 153 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000931 -> 0.0000911\n",
      "(epoch: 154, iters: 120, time: 0.132, data: 0.002) D_A: 0.231 G_A: 0.406 cycle_A: 0.433 idt_A: 0.112 D_B: 0.170 G_B: 0.365 cycle_B: 0.338 idt_B: 0.159 \n",
      "(epoch: 154, iters: 320, time: 0.063, data: 0.002) D_A: 0.215 G_A: 0.280 cycle_A: 0.339 idt_A: 0.102 D_B: 0.249 G_B: 0.259 cycle_B: 0.349 idt_B: 0.132 \n",
      "(epoch: 154, iters: 520, time: 0.145, data: 0.002) D_A: 0.185 G_A: 0.238 cycle_A: 0.324 idt_A: 0.137 D_B: 0.214 G_B: 0.281 cycle_B: 0.435 idt_B: 0.125 \n",
      "(epoch: 154, iters: 720, time: 0.063, data: 0.001) D_A: 0.208 G_A: 0.314 cycle_A: 0.318 idt_A: 0.115 D_B: 0.197 G_B: 0.303 cycle_B: 0.382 idt_B: 0.128 \n",
      "(epoch: 154, iters: 920, time: 0.063, data: 0.002) D_A: 0.212 G_A: 0.381 cycle_A: 0.340 idt_A: 0.120 D_B: 0.187 G_B: 0.312 cycle_B: 0.306 idt_B: 0.142 \n",
      "(epoch: 154, iters: 1120, time: 0.063, data: 0.002) D_A: 0.236 G_A: 0.253 cycle_A: 0.301 idt_A: 0.112 D_B: 0.221 G_B: 0.263 cycle_B: 0.338 idt_B: 0.108 \n",
      "End of epoch 154 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000911 -> 0.0000891\n",
      "(epoch: 155, iters: 160, time: 0.135, data: 0.001) D_A: 0.196 G_A: 0.291 cycle_A: 0.296 idt_A: 0.109 D_B: 0.216 G_B: 0.346 cycle_B: 0.330 idt_B: 0.105 \n",
      "(epoch: 155, iters: 360, time: 0.063, data: 0.002) D_A: 0.220 G_A: 0.306 cycle_A: 0.368 idt_A: 0.122 D_B: 0.208 G_B: 0.338 cycle_B: 0.341 idt_B: 0.116 \n",
      "(epoch: 155, iters: 560, time: 0.063, data: 0.002) D_A: 0.220 G_A: 0.281 cycle_A: 0.302 idt_A: 0.126 D_B: 0.165 G_B: 0.401 cycle_B: 0.370 idt_B: 0.098 \n",
      "(epoch: 155, iters: 760, time: 0.063, data: 0.002) D_A: 0.197 G_A: 0.382 cycle_A: 0.323 idt_A: 0.117 D_B: 0.190 G_B: 0.352 cycle_B: 0.355 idt_B: 0.126 \n",
      "(epoch: 155, iters: 960, time: 0.063, data: 0.002) D_A: 0.203 G_A: 0.271 cycle_A: 0.269 idt_A: 0.119 D_B: 0.192 G_B: 0.215 cycle_B: 0.379 idt_B: 0.101 \n",
      "(epoch: 155, iters: 1160, time: 0.063, data: 0.002) D_A: 0.198 G_A: 0.278 cycle_A: 0.345 idt_A: 0.104 D_B: 0.184 G_B: 0.302 cycle_B: 0.336 idt_B: 0.126 \n",
      "saving the model at the end of epoch 155, iters 179800\n",
      "End of epoch 155 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000891 -> 0.0000871\n",
      "(epoch: 156, iters: 200, time: 0.135, data: 0.100) D_A: 0.198 G_A: 0.345 cycle_A: 0.327 idt_A: 0.099 D_B: 0.170 G_B: 0.296 cycle_B: 0.324 idt_B: 0.137 \n",
      "saving the latest model (epoch 156, total_iters 180000)\n",
      "(epoch: 156, iters: 400, time: 0.063, data: 0.001) D_A: 0.182 G_A: 0.329 cycle_A: 0.308 idt_A: 0.111 D_B: 0.209 G_B: 0.413 cycle_B: 0.369 idt_B: 0.107 \n",
      "(epoch: 156, iters: 600, time: 0.062, data: 0.002) D_A: 0.157 G_A: 0.359 cycle_A: 0.338 idt_A: 0.105 D_B: 0.181 G_B: 0.262 cycle_B: 0.352 idt_B: 0.129 \n",
      "(epoch: 156, iters: 800, time: 0.062, data: 0.002) D_A: 0.229 G_A: 0.225 cycle_A: 0.408 idt_A: 0.144 D_B: 0.142 G_B: 0.385 cycle_B: 0.390 idt_B: 0.143 \n",
      "(epoch: 156, iters: 1000, time: 0.063, data: 0.002) D_A: 0.197 G_A: 0.289 cycle_A: 0.332 idt_A: 0.110 D_B: 0.209 G_B: 0.261 cycle_B: 0.345 idt_B: 0.126 \n",
      "End of epoch 156 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000871 -> 0.0000851\n",
      "(epoch: 157, iters: 40, time: 0.063, data: 0.001) D_A: 0.206 G_A: 0.297 cycle_A: 0.317 idt_A: 0.137 D_B: 0.194 G_B: 0.241 cycle_B: 0.337 idt_B: 0.105 \n",
      "(epoch: 157, iters: 240, time: 0.133, data: 0.002) D_A: 0.208 G_A: 0.252 cycle_A: 0.312 idt_A: 0.124 D_B: 0.175 G_B: 0.376 cycle_B: 0.347 idt_B: 0.107 \n",
      "(epoch: 157, iters: 440, time: 0.063, data: 0.002) D_A: 0.173 G_A: 0.448 cycle_A: 0.350 idt_A: 0.113 D_B: 0.221 G_B: 0.280 cycle_B: 0.330 idt_B: 0.122 \n",
      "(epoch: 157, iters: 640, time: 0.063, data: 0.002) D_A: 0.204 G_A: 0.357 cycle_A: 0.293 idt_A: 0.111 D_B: 0.208 G_B: 0.186 cycle_B: 0.328 idt_B: 0.112 \n",
      "(epoch: 157, iters: 840, time: 0.063, data: 0.002) D_A: 0.207 G_A: 0.272 cycle_A: 0.296 idt_A: 0.158 D_B: 0.202 G_B: 0.354 cycle_B: 0.374 idt_B: 0.110 \n",
      "(epoch: 157, iters: 1040, time: 0.134, data: 0.001) D_A: 0.196 G_A: 0.310 cycle_A: 0.337 idt_A: 0.120 D_B: 0.200 G_B: 0.333 cycle_B: 0.355 idt_B: 0.107 \n",
      "End of epoch 157 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000851 -> 0.0000832\n",
      "(epoch: 158, iters: 80, time: 0.063, data: 0.002) D_A: 0.197 G_A: 0.308 cycle_A: 0.299 idt_A: 0.113 D_B: 0.168 G_B: 0.353 cycle_B: 0.356 idt_B: 0.107 \n",
      "(epoch: 158, iters: 280, time: 0.136, data: 0.002) D_A: 0.182 G_A: 0.384 cycle_A: 0.350 idt_A: 0.113 D_B: 0.185 G_B: 0.339 cycle_B: 0.303 idt_B: 0.130 \n",
      "(epoch: 158, iters: 480, time: 0.062, data: 0.001) D_A: 0.209 G_A: 0.238 cycle_A: 0.483 idt_A: 0.136 D_B: 0.210 G_B: 0.356 cycle_B: 0.326 idt_B: 0.167 \n",
      "(epoch: 158, iters: 680, time: 0.063, data: 0.001) D_A: 0.198 G_A: 0.186 cycle_A: 0.339 idt_A: 0.121 D_B: 0.210 G_B: 0.291 cycle_B: 0.316 idt_B: 0.122 \n",
      "(epoch: 158, iters: 880, time: 0.063, data: 0.002) D_A: 0.225 G_A: 0.286 cycle_A: 0.370 idt_A: 0.116 D_B: 0.201 G_B: 0.365 cycle_B: 0.338 idt_B: 0.128 \n",
      "(epoch: 158, iters: 1080, time: 0.063, data: 0.002) D_A: 0.170 G_A: 0.348 cycle_A: 0.388 idt_A: 0.129 D_B: 0.183 G_B: 0.357 cycle_B: 0.394 idt_B: 0.126 \n",
      "End of epoch 158 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000832 -> 0.0000812\n",
      "(epoch: 159, iters: 120, time: 0.063, data: 0.002) D_A: 0.202 G_A: 0.333 cycle_A: 0.326 idt_A: 0.155 D_B: 0.231 G_B: 0.400 cycle_B: 0.406 idt_B: 0.111 \n",
      "(epoch: 159, iters: 320, time: 0.135, data: 0.002) D_A: 0.178 G_A: 0.283 cycle_A: 0.377 idt_A: 0.151 D_B: 0.224 G_B: 0.319 cycle_B: 0.385 idt_B: 0.154 \n",
      "(epoch: 159, iters: 520, time: 0.063, data: 0.001) D_A: 0.178 G_A: 0.365 cycle_A: 0.309 idt_A: 0.101 D_B: 0.234 G_B: 0.423 cycle_B: 0.341 idt_B: 0.111 \n",
      "(epoch: 159, iters: 720, time: 0.148, data: 0.002) D_A: 0.176 G_A: 0.370 cycle_A: 0.346 idt_A: 0.129 D_B: 0.198 G_B: 0.290 cycle_B: 0.364 idt_B: 0.124 \n",
      "(epoch: 159, iters: 920, time: 0.063, data: 0.002) D_A: 0.202 G_A: 0.266 cycle_A: 0.315 idt_A: 0.129 D_B: 0.178 G_B: 0.311 cycle_B: 0.375 idt_B: 0.118 \n",
      "(epoch: 159, iters: 1120, time: 0.063, data: 0.002) D_A: 0.196 G_A: 0.417 cycle_A: 0.312 idt_A: 0.115 D_B: 0.174 G_B: 0.370 cycle_B: 0.318 idt_B: 0.112 \n",
      "End of epoch 159 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000812 -> 0.0000792\n",
      "(epoch: 160, iters: 160, time: 0.063, data: 0.002) D_A: 0.209 G_A: 0.520 cycle_A: 0.356 idt_A: 0.123 D_B: 0.187 G_B: 0.335 cycle_B: 0.357 idt_B: 0.132 \n",
      "(epoch: 160, iters: 360, time: 0.136, data: 0.001) D_A: 0.211 G_A: 0.319 cycle_A: 0.354 idt_A: 0.111 D_B: 0.175 G_B: 0.233 cycle_B: 0.325 idt_B: 0.130 \n",
      "(epoch: 160, iters: 560, time: 0.063, data: 0.002) D_A: 0.156 G_A: 0.317 cycle_A: 0.335 idt_A: 0.156 D_B: 0.181 G_B: 0.373 cycle_B: 0.406 idt_B: 0.138 \n",
      "saving the latest model (epoch 160, total_iters 185000)\n",
      "(epoch: 160, iters: 760, time: 0.063, data: 0.002) D_A: 0.192 G_A: 0.357 cycle_A: 0.350 idt_A: 0.114 D_B: 0.206 G_B: 0.251 cycle_B: 0.360 idt_B: 0.127 \n",
      "(epoch: 160, iters: 960, time: 0.063, data: 0.002) D_A: 0.190 G_A: 0.332 cycle_A: 0.323 idt_A: 0.128 D_B: 0.200 G_B: 0.207 cycle_B: 0.381 idt_B: 0.131 \n",
      "(epoch: 160, iters: 1160, time: 0.063, data: 0.002) D_A: 0.232 G_A: 0.336 cycle_A: 0.369 idt_A: 0.096 D_B: 0.145 G_B: 0.228 cycle_B: 0.326 idt_B: 0.111 \n",
      "saving the model at the end of epoch 160, iters 185600\n",
      "End of epoch 160 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000792 -> 0.0000772\n",
      "(epoch: 161, iters: 200, time: 0.063, data: 0.172) D_A: 0.211 G_A: 0.206 cycle_A: 0.314 idt_A: 0.102 D_B: 0.232 G_B: 0.392 cycle_B: 0.324 idt_B: 0.103 \n",
      "(epoch: 161, iters: 400, time: 0.137, data: 0.002) D_A: 0.188 G_A: 0.312 cycle_A: 0.351 idt_A: 0.105 D_B: 0.176 G_B: 0.442 cycle_B: 0.347 idt_B: 0.118 \n",
      "(epoch: 161, iters: 600, time: 0.063, data: 0.002) D_A: 0.228 G_A: 0.430 cycle_A: 0.330 idt_A: 0.150 D_B: 0.156 G_B: 0.442 cycle_B: 0.365 idt_B: 0.110 \n",
      "(epoch: 161, iters: 800, time: 0.063, data: 0.002) D_A: 0.172 G_A: 0.334 cycle_A: 0.326 idt_A: 0.129 D_B: 0.238 G_B: 0.163 cycle_B: 0.344 idt_B: 0.131 \n",
      "(epoch: 161, iters: 1000, time: 0.063, data: 0.002) D_A: 0.199 G_A: 0.312 cycle_A: 0.360 idt_A: 0.109 D_B: 0.193 G_B: 0.277 cycle_B: 0.363 idt_B: 0.100 \n",
      "End of epoch 161 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000772 -> 0.0000752\n",
      "(epoch: 162, iters: 40, time: 0.138, data: 0.002) D_A: 0.232 G_A: 0.326 cycle_A: 0.290 idt_A: 0.113 D_B: 0.183 G_B: 0.401 cycle_B: 0.346 idt_B: 0.106 \n",
      "(epoch: 162, iters: 240, time: 0.063, data: 0.001) D_A: 0.206 G_A: 0.368 cycle_A: 0.305 idt_A: 0.125 D_B: 0.209 G_B: 0.326 cycle_B: 0.326 idt_B: 0.095 \n",
      "(epoch: 162, iters: 440, time: 0.063, data: 0.002) D_A: 0.253 G_A: 0.178 cycle_A: 0.308 idt_A: 0.118 D_B: 0.178 G_B: 0.429 cycle_B: 0.356 idt_B: 0.102 \n",
      "(epoch: 162, iters: 640, time: 0.063, data: 0.002) D_A: 0.172 G_A: 0.353 cycle_A: 0.339 idt_A: 0.116 D_B: 0.164 G_B: 0.380 cycle_B: 0.365 idt_B: 0.120 \n",
      "(epoch: 162, iters: 840, time: 0.063, data: 0.001) D_A: 0.220 G_A: 0.151 cycle_A: 0.385 idt_A: 0.123 D_B: 0.194 G_B: 0.533 cycle_B: 0.384 idt_B: 0.172 \n",
      "(epoch: 162, iters: 1040, time: 0.063, data: 0.002) D_A: 0.174 G_A: 0.308 cycle_A: 0.326 idt_A: 0.106 D_B: 0.139 G_B: 0.382 cycle_B: 0.316 idt_B: 0.122 \n",
      "End of epoch 162 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000752 -> 0.0000733\n",
      "(epoch: 163, iters: 80, time: 0.138, data: 0.002) D_A: 0.206 G_A: 0.276 cycle_A: 0.367 idt_A: 0.113 D_B: 0.196 G_B: 0.326 cycle_B: 0.367 idt_B: 0.131 \n",
      "(epoch: 163, iters: 280, time: 0.062, data: 0.002) D_A: 0.169 G_A: 0.390 cycle_A: 0.390 idt_A: 0.114 D_B: 0.208 G_B: 0.387 cycle_B: 0.349 idt_B: 0.134 \n",
      "(epoch: 163, iters: 480, time: 0.063, data: 0.002) D_A: 0.204 G_A: 0.280 cycle_A: 0.355 idt_A: 0.123 D_B: 0.165 G_B: 0.296 cycle_B: 0.392 idt_B: 0.119 \n",
      "(epoch: 163, iters: 680, time: 0.063, data: 0.001) D_A: 0.178 G_A: 0.350 cycle_A: 0.349 idt_A: 0.105 D_B: 0.194 G_B: 0.335 cycle_B: 0.336 idt_B: 0.108 \n",
      "(epoch: 163, iters: 880, time: 0.063, data: 0.001) D_A: 0.204 G_A: 0.342 cycle_A: 0.315 idt_A: 0.117 D_B: 0.221 G_B: 0.210 cycle_B: 0.353 idt_B: 0.123 \n",
      "(epoch: 163, iters: 1080, time: 0.063, data: 0.002) D_A: 0.161 G_A: 0.431 cycle_A: 0.330 idt_A: 0.126 D_B: 0.203 G_B: 0.500 cycle_B: 0.348 idt_B: 0.111 \n",
      "End of epoch 163 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000733 -> 0.0000713\n",
      "(epoch: 164, iters: 120, time: 0.136, data: 0.002) D_A: 0.161 G_A: 0.413 cycle_A: 0.327 idt_A: 0.180 D_B: 0.171 G_B: 0.394 cycle_B: 0.461 idt_B: 0.114 \n",
      "(epoch: 164, iters: 320, time: 0.063, data: 0.002) D_A: 0.209 G_A: 0.310 cycle_A: 0.300 idt_A: 0.121 D_B: 0.228 G_B: 0.258 cycle_B: 0.322 idt_B: 0.110 \n",
      "(epoch: 164, iters: 520, time: 0.063, data: 0.001) D_A: 0.160 G_A: 0.320 cycle_A: 0.357 idt_A: 0.110 D_B: 0.223 G_B: 0.516 cycle_B: 0.342 idt_B: 0.116 \n",
      "(epoch: 164, iters: 720, time: 0.063, data: 0.001) D_A: 0.200 G_A: 0.375 cycle_A: 0.322 idt_A: 0.104 D_B: 0.190 G_B: 0.358 cycle_B: 0.369 idt_B: 0.108 \n",
      "(epoch: 164, iters: 920, time: 0.137, data: 0.002) D_A: 0.177 G_A: 0.387 cycle_A: 0.376 idt_A: 0.130 D_B: 0.154 G_B: 0.322 cycle_B: 0.356 idt_B: 0.122 \n",
      "saving the latest model (epoch 164, total_iters 190000)\n",
      "(epoch: 164, iters: 1120, time: 0.063, data: 0.001) D_A: 0.248 G_A: 0.271 cycle_A: 0.395 idt_A: 0.119 D_B: 0.231 G_B: 0.335 cycle_B: 0.328 idt_B: 0.119 \n",
      "End of epoch 164 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000713 -> 0.0000693\n",
      "(epoch: 165, iters: 160, time: 0.151, data: 0.001) D_A: 0.170 G_A: 0.376 cycle_A: 0.347 idt_A: 0.155 D_B: 0.181 G_B: 0.309 cycle_B: 0.431 idt_B: 0.134 \n",
      "(epoch: 165, iters: 360, time: 0.063, data: 0.002) D_A: 0.206 G_A: 0.495 cycle_A: 0.333 idt_A: 0.119 D_B: 0.190 G_B: 0.469 cycle_B: 0.335 idt_B: 0.101 \n",
      "(epoch: 165, iters: 560, time: 0.063, data: 0.002) D_A: 0.176 G_A: 0.372 cycle_A: 0.328 idt_A: 0.142 D_B: 0.196 G_B: 0.314 cycle_B: 0.374 idt_B: 0.121 \n",
      "(epoch: 165, iters: 760, time: 0.063, data: 0.002) D_A: 0.213 G_A: 0.339 cycle_A: 0.322 idt_A: 0.126 D_B: 0.164 G_B: 0.364 cycle_B: 0.347 idt_B: 0.108 \n",
      "(epoch: 165, iters: 960, time: 0.063, data: 0.002) D_A: 0.191 G_A: 0.386 cycle_A: 0.335 idt_A: 0.119 D_B: 0.212 G_B: 0.351 cycle_B: 0.330 idt_B: 0.114 \n",
      "(epoch: 165, iters: 1160, time: 0.063, data: 0.002) D_A: 0.196 G_A: 0.351 cycle_A: 0.342 idt_A: 0.123 D_B: 0.197 G_B: 0.436 cycle_B: 0.335 idt_B: 0.130 \n",
      "saving the model at the end of epoch 165, iters 191400\n",
      "End of epoch 165 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000693 -> 0.0000673\n",
      "(epoch: 166, iters: 200, time: 0.137, data: 0.081) D_A: 0.170 G_A: 0.461 cycle_A: 0.331 idt_A: 0.119 D_B: 0.188 G_B: 0.433 cycle_B: 0.327 idt_B: 0.103 \n",
      "(epoch: 166, iters: 400, time: 0.063, data: 0.002) D_A: 0.217 G_A: 0.350 cycle_A: 0.313 idt_A: 0.108 D_B: 0.245 G_B: 0.289 cycle_B: 0.321 idt_B: 0.101 \n",
      "(epoch: 166, iters: 600, time: 0.137, data: 0.002) D_A: 0.160 G_A: 0.493 cycle_A: 0.337 idt_A: 0.084 D_B: 0.166 G_B: 0.251 cycle_B: 0.311 idt_B: 0.133 \n",
      "(epoch: 166, iters: 800, time: 0.063, data: 0.002) D_A: 0.198 G_A: 0.464 cycle_A: 0.314 idt_A: 0.101 D_B: 0.187 G_B: 0.361 cycle_B: 0.321 idt_B: 0.100 \n",
      "(epoch: 166, iters: 1000, time: 0.063, data: 0.001) D_A: 0.283 G_A: 0.606 cycle_A: 0.341 idt_A: 0.139 D_B: 0.210 G_B: 0.327 cycle_B: 0.312 idt_B: 0.122 \n",
      "End of epoch 166 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000673 -> 0.0000653\n",
      "(epoch: 167, iters: 40, time: 0.063, data: 0.002) D_A: 0.205 G_A: 0.483 cycle_A: 0.317 idt_A: 0.133 D_B: 0.131 G_B: 0.396 cycle_B: 0.391 idt_B: 0.147 \n",
      "(epoch: 167, iters: 240, time: 0.135, data: 0.001) D_A: 0.153 G_A: 0.417 cycle_A: 0.315 idt_A: 0.124 D_B: 0.178 G_B: 0.450 cycle_B: 0.360 idt_B: 0.099 \n",
      "(epoch: 167, iters: 440, time: 0.062, data: 0.002) D_A: 0.210 G_A: 0.167 cycle_A: 0.293 idt_A: 0.121 D_B: 0.198 G_B: 0.368 cycle_B: 0.362 idt_B: 0.103 \n",
      "(epoch: 167, iters: 640, time: 0.063, data: 0.002) D_A: 0.224 G_A: 0.410 cycle_A: 0.349 idt_A: 0.112 D_B: 0.205 G_B: 0.264 cycle_B: 0.335 idt_B: 0.108 \n",
      "(epoch: 167, iters: 840, time: 0.062, data: 0.002) D_A: 0.182 G_A: 0.483 cycle_A: 0.342 idt_A: 0.131 D_B: 0.180 G_B: 0.372 cycle_B: 0.379 idt_B: 0.106 \n",
      "(epoch: 167, iters: 1040, time: 0.063, data: 0.001) D_A: 0.175 G_A: 0.564 cycle_A: 0.329 idt_A: 0.121 D_B: 0.207 G_B: 0.282 cycle_B: 0.384 idt_B: 0.113 \n",
      "End of epoch 167 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000653 -> 0.0000634\n",
      "(epoch: 168, iters: 80, time: 0.063, data: 0.002) D_A: 0.145 G_A: 0.527 cycle_A: 0.291 idt_A: 0.099 D_B: 0.198 G_B: 0.367 cycle_B: 0.336 idt_B: 0.111 \n",
      "(epoch: 168, iters: 280, time: 0.138, data: 0.002) D_A: 0.208 G_A: 0.402 cycle_A: 0.297 idt_A: 0.088 D_B: 0.187 G_B: 0.433 cycle_B: 0.300 idt_B: 0.122 \n",
      "(epoch: 168, iters: 480, time: 0.063, data: 0.002) D_A: 0.153 G_A: 0.328 cycle_A: 0.406 idt_A: 0.102 D_B: 0.211 G_B: 0.281 cycle_B: 0.355 idt_B: 0.144 \n",
      "(epoch: 168, iters: 680, time: 0.063, data: 0.002) D_A: 0.194 G_A: 0.372 cycle_A: 0.346 idt_A: 0.111 D_B: 0.175 G_B: 0.421 cycle_B: 0.343 idt_B: 0.112 \n",
      "(epoch: 168, iters: 880, time: 0.063, data: 0.002) D_A: 0.182 G_A: 0.291 cycle_A: 0.342 idt_A: 0.134 D_B: 0.153 G_B: 0.343 cycle_B: 0.358 idt_B: 0.128 \n",
      "(epoch: 168, iters: 1080, time: 0.063, data: 0.002) D_A: 0.210 G_A: 0.466 cycle_A: 0.310 idt_A: 0.089 D_B: 0.223 G_B: 0.276 cycle_B: 0.288 idt_B: 0.105 \n",
      "End of epoch 168 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000634 -> 0.0000614\n",
      "(epoch: 169, iters: 120, time: 0.063, data: 0.002) D_A: 0.212 G_A: 0.289 cycle_A: 0.304 idt_A: 0.140 D_B: 0.210 G_B: 0.344 cycle_B: 0.395 idt_B: 0.095 \n",
      "saving the latest model (epoch 169, total_iters 195000)\n",
      "(epoch: 169, iters: 320, time: 0.138, data: 0.001) D_A: 0.184 G_A: 0.444 cycle_A: 0.386 idt_A: 0.124 D_B: 0.172 G_B: 0.402 cycle_B: 0.335 idt_B: 0.112 \n",
      "(epoch: 169, iters: 520, time: 0.063, data: 0.001) D_A: 0.170 G_A: 0.353 cycle_A: 0.307 idt_A: 0.097 D_B: 0.174 G_B: 0.471 cycle_B: 0.330 idt_B: 0.110 \n",
      "(epoch: 169, iters: 720, time: 0.063, data: 0.002) D_A: 0.180 G_A: 0.297 cycle_A: 0.314 idt_A: 0.106 D_B: 0.174 G_B: 0.325 cycle_B: 0.345 idt_B: 0.121 \n",
      "(epoch: 169, iters: 920, time: 0.063, data: 0.001) D_A: 0.159 G_A: 0.345 cycle_A: 0.313 idt_A: 0.117 D_B: 0.175 G_B: 0.366 cycle_B: 0.350 idt_B: 0.108 \n",
      "(epoch: 169, iters: 1120, time: 0.152, data: 0.001) D_A: 0.195 G_A: 0.281 cycle_A: 0.351 idt_A: 0.102 D_B: 0.174 G_B: 0.324 cycle_B: 0.299 idt_B: 0.136 \n",
      "End of epoch 169 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000614 -> 0.0000594\n",
      "(epoch: 170, iters: 160, time: 0.062, data: 0.002) D_A: 0.188 G_A: 0.337 cycle_A: 0.329 idt_A: 0.118 D_B: 0.268 G_B: 0.198 cycle_B: 0.357 idt_B: 0.139 \n",
      "(epoch: 170, iters: 360, time: 0.138, data: 0.002) D_A: 0.211 G_A: 0.368 cycle_A: 0.308 idt_A: 0.096 D_B: 0.180 G_B: 0.321 cycle_B: 0.315 idt_B: 0.105 \n",
      "(epoch: 170, iters: 560, time: 0.063, data: 0.002) D_A: 0.199 G_A: 0.376 cycle_A: 0.321 idt_A: 0.104 D_B: 0.207 G_B: 0.363 cycle_B: 0.318 idt_B: 0.129 \n",
      "(epoch: 170, iters: 760, time: 0.062, data: 0.002) D_A: 0.167 G_A: 0.302 cycle_A: 0.358 idt_A: 0.122 D_B: 0.160 G_B: 0.441 cycle_B: 0.371 idt_B: 0.112 \n",
      "(epoch: 170, iters: 960, time: 0.063, data: 0.002) D_A: 0.231 G_A: 0.168 cycle_A: 0.279 idt_A: 0.100 D_B: 0.187 G_B: 0.386 cycle_B: 0.307 idt_B: 0.096 \n",
      "(epoch: 170, iters: 1160, time: 0.063, data: 0.001) D_A: 0.226 G_A: 0.238 cycle_A: 0.305 idt_A: 0.101 D_B: 0.210 G_B: 0.363 cycle_B: 0.311 idt_B: 0.104 \n",
      "saving the model at the end of epoch 170, iters 197200\n",
      "End of epoch 170 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000594 -> 0.0000574\n",
      "(epoch: 171, iters: 200, time: 0.063, data: 0.118) D_A: 0.202 G_A: 0.466 cycle_A: 0.303 idt_A: 0.098 D_B: 0.229 G_B: 0.346 cycle_B: 0.330 idt_B: 0.106 \n",
      "(epoch: 171, iters: 400, time: 0.140, data: 0.002) D_A: 0.214 G_A: 0.347 cycle_A: 0.341 idt_A: 0.110 D_B: 0.194 G_B: 0.345 cycle_B: 0.344 idt_B: 0.116 \n",
      "(epoch: 171, iters: 600, time: 0.062, data: 0.002) D_A: 0.212 G_A: 0.554 cycle_A: 0.353 idt_A: 0.126 D_B: 0.170 G_B: 0.352 cycle_B: 0.356 idt_B: 0.155 \n",
      "(epoch: 171, iters: 800, time: 0.140, data: 0.001) D_A: 0.161 G_A: 0.360 cycle_A: 0.365 idt_A: 0.109 D_B: 0.202 G_B: 0.349 cycle_B: 0.317 idt_B: 0.127 \n",
      "(epoch: 171, iters: 1000, time: 0.063, data: 0.002) D_A: 0.207 G_A: 0.348 cycle_A: 0.341 idt_A: 0.112 D_B: 0.217 G_B: 0.296 cycle_B: 0.314 idt_B: 0.100 \n",
      "End of epoch 171 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000574 -> 0.0000554\n",
      "(epoch: 172, iters: 40, time: 0.138, data: 0.001) D_A: 0.199 G_A: 0.453 cycle_A: 0.345 idt_A: 0.103 D_B: 0.180 G_B: 0.341 cycle_B: 0.300 idt_B: 0.110 \n",
      "(epoch: 172, iters: 240, time: 0.063, data: 0.001) D_A: 0.165 G_A: 0.458 cycle_A: 0.351 idt_A: 0.115 D_B: 0.177 G_B: 0.326 cycle_B: 0.345 idt_B: 0.123 \n",
      "(epoch: 172, iters: 440, time: 0.063, data: 0.002) D_A: 0.174 G_A: 0.380 cycle_A: 0.331 idt_A: 0.102 D_B: 0.213 G_B: 0.344 cycle_B: 0.298 idt_B: 0.114 \n",
      "(epoch: 172, iters: 640, time: 0.063, data: 0.002) D_A: 0.172 G_A: 0.460 cycle_A: 0.299 idt_A: 0.104 D_B: 0.223 G_B: 0.321 cycle_B: 0.307 idt_B: 0.113 \n",
      "(epoch: 172, iters: 840, time: 0.063, data: 0.001) D_A: 0.171 G_A: 0.468 cycle_A: 0.310 idt_A: 0.167 D_B: 0.143 G_B: 0.332 cycle_B: 0.411 idt_B: 0.111 \n",
      "(epoch: 172, iters: 1040, time: 0.063, data: 0.001) D_A: 0.180 G_A: 0.478 cycle_A: 0.340 idt_A: 0.133 D_B: 0.162 G_B: 0.376 cycle_B: 0.357 idt_B: 0.112 \n",
      "End of epoch 172 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000554 -> 0.0000535\n",
      "(epoch: 173, iters: 80, time: 0.141, data: 0.002) D_A: 0.189 G_A: 0.324 cycle_A: 0.325 idt_A: 0.093 D_B: 0.194 G_B: 0.286 cycle_B: 0.317 idt_B: 0.111 \n",
      "(epoch: 173, iters: 280, time: 0.063, data: 0.002) D_A: 0.168 G_A: 0.415 cycle_A: 0.324 idt_A: 0.119 D_B: 0.183 G_B: 0.354 cycle_B: 0.337 idt_B: 0.096 \n",
      "(epoch: 173, iters: 480, time: 0.139, data: 0.002) D_A: 0.204 G_A: 0.273 cycle_A: 0.342 idt_A: 0.117 D_B: 0.185 G_B: 0.262 cycle_B: 0.328 idt_B: 0.110 \n",
      "saving the latest model (epoch 173, total_iters 200000)\n",
      "(epoch: 173, iters: 680, time: 0.063, data: 0.001) D_A: 0.175 G_A: 0.396 cycle_A: 0.376 idt_A: 0.097 D_B: 0.165 G_B: 0.300 cycle_B: 0.323 idt_B: 0.145 \n",
      "(epoch: 173, iters: 880, time: 0.063, data: 0.002) D_A: 0.182 G_A: 0.365 cycle_A: 0.281 idt_A: 0.106 D_B: 0.189 G_B: 0.445 cycle_B: 0.322 idt_B: 0.103 \n",
      "(epoch: 173, iters: 1080, time: 0.063, data: 0.002) D_A: 0.183 G_A: 0.367 cycle_A: 0.341 idt_A: 0.131 D_B: 0.215 G_B: 0.311 cycle_B: 0.349 idt_B: 0.107 \n",
      "End of epoch 173 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000535 -> 0.0000515\n",
      "(epoch: 174, iters: 120, time: 0.155, data: 0.002) D_A: 0.179 G_A: 0.430 cycle_A: 0.331 idt_A: 0.105 D_B: 0.164 G_B: 0.409 cycle_B: 0.312 idt_B: 0.112 \n",
      "(epoch: 174, iters: 320, time: 0.063, data: 0.002) D_A: 0.204 G_A: 0.293 cycle_A: 0.269 idt_A: 0.109 D_B: 0.177 G_B: 0.348 cycle_B: 0.313 idt_B: 0.091 \n",
      "(epoch: 174, iters: 520, time: 0.062, data: 0.002) D_A: 0.170 G_A: 0.242 cycle_A: 0.358 idt_A: 0.096 D_B: 0.200 G_B: 0.211 cycle_B: 0.314 idt_B: 0.117 \n",
      "(epoch: 174, iters: 720, time: 0.063, data: 0.002) D_A: 0.174 G_A: 0.361 cycle_A: 0.339 idt_A: 0.092 D_B: 0.216 G_B: 0.328 cycle_B: 0.314 idt_B: 0.128 \n",
      "(epoch: 174, iters: 920, time: 0.063, data: 0.002) D_A: 0.243 G_A: 0.475 cycle_A: 0.302 idt_A: 0.140 D_B: 0.210 G_B: 0.220 cycle_B: 0.389 idt_B: 0.092 \n",
      "(epoch: 174, iters: 1120, time: 0.063, data: 0.002) D_A: 0.185 G_A: 0.291 cycle_A: 0.419 idt_A: 0.113 D_B: 0.222 G_B: 0.257 cycle_B: 0.336 idt_B: 0.129 \n",
      "End of epoch 174 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000515 -> 0.0000495\n",
      "(epoch: 175, iters: 160, time: 0.141, data: 0.001) D_A: 0.190 G_A: 0.309 cycle_A: 0.285 idt_A: 0.119 D_B: 0.171 G_B: 0.369 cycle_B: 0.351 idt_B: 0.106 \n",
      "(epoch: 175, iters: 360, time: 0.063, data: 0.002) D_A: 0.193 G_A: 0.369 cycle_A: 0.332 idt_A: 0.092 D_B: 0.170 G_B: 0.285 cycle_B: 0.285 idt_B: 0.102 \n",
      "(epoch: 175, iters: 560, time: 0.063, data: 0.002) D_A: 0.180 G_A: 0.280 cycle_A: 0.316 idt_A: 0.097 D_B: 0.181 G_B: 0.317 cycle_B: 0.301 idt_B: 0.106 \n",
      "(epoch: 175, iters: 760, time: 0.063, data: 0.002) D_A: 0.241 G_A: 0.364 cycle_A: 0.333 idt_A: 0.128 D_B: 0.211 G_B: 0.421 cycle_B: 0.341 idt_B: 0.117 \n",
      "(epoch: 175, iters: 960, time: 0.063, data: 0.001) D_A: 0.169 G_A: 0.447 cycle_A: 0.278 idt_A: 0.123 D_B: 0.208 G_B: 0.398 cycle_B: 0.342 idt_B: 0.092 \n",
      "(epoch: 175, iters: 1160, time: 0.063, data: 0.002) D_A: 0.175 G_A: 0.300 cycle_A: 0.278 idt_A: 0.115 D_B: 0.216 G_B: 0.376 cycle_B: 0.332 idt_B: 0.095 \n",
      "saving the model at the end of epoch 175, iters 203000\n",
      "End of epoch 175 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000495 -> 0.0000475\n",
      "(epoch: 176, iters: 200, time: 0.141, data: 0.081) D_A: 0.205 G_A: 0.305 cycle_A: 0.329 idt_A: 0.093 D_B: 0.203 G_B: 0.314 cycle_B: 0.297 idt_B: 0.099 \n",
      "(epoch: 176, iters: 400, time: 0.063, data: 0.002) D_A: 0.180 G_A: 0.527 cycle_A: 0.315 idt_A: 0.114 D_B: 0.185 G_B: 0.274 cycle_B: 0.332 idt_B: 0.113 \n",
      "(epoch: 176, iters: 600, time: 0.063, data: 0.002) D_A: 0.210 G_A: 0.333 cycle_A: 0.317 idt_A: 0.097 D_B: 0.167 G_B: 0.387 cycle_B: 0.322 idt_B: 0.099 \n",
      "(epoch: 176, iters: 800, time: 0.062, data: 0.002) D_A: 0.163 G_A: 0.367 cycle_A: 0.350 idt_A: 0.119 D_B: 0.223 G_B: 0.232 cycle_B: 0.355 idt_B: 0.135 \n",
      "(epoch: 176, iters: 1000, time: 0.140, data: 0.002) D_A: 0.170 G_A: 0.363 cycle_A: 0.303 idt_A: 0.115 D_B: 0.201 G_B: 0.291 cycle_B: 0.318 idt_B: 0.102 \n",
      "End of epoch 176 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000475 -> 0.0000455\n",
      "(epoch: 177, iters: 40, time: 0.063, data: 0.002) D_A: 0.160 G_A: 0.369 cycle_A: 0.301 idt_A: 0.094 D_B: 0.196 G_B: 0.274 cycle_B: 0.304 idt_B: 0.109 \n",
      "(epoch: 177, iters: 240, time: 0.142, data: 0.001) D_A: 0.237 G_A: 0.257 cycle_A: 0.331 idt_A: 0.094 D_B: 0.216 G_B: 0.303 cycle_B: 0.308 idt_B: 0.104 \n",
      "(epoch: 177, iters: 440, time: 0.063, data: 0.002) D_A: 0.214 G_A: 0.393 cycle_A: 0.314 idt_A: 0.104 D_B: 0.226 G_B: 0.316 cycle_B: 0.279 idt_B: 0.105 \n",
      "(epoch: 177, iters: 640, time: 0.062, data: 0.002) D_A: 0.173 G_A: 0.310 cycle_A: 0.316 idt_A: 0.105 D_B: 0.237 G_B: 0.351 cycle_B: 0.328 idt_B: 0.102 \n",
      "(epoch: 177, iters: 840, time: 0.063, data: 0.002) D_A: 0.207 G_A: 0.470 cycle_A: 0.325 idt_A: 0.107 D_B: 0.136 G_B: 0.332 cycle_B: 0.315 idt_B: 0.119 \n",
      "saving the latest model (epoch 177, total_iters 205000)\n",
      "(epoch: 177, iters: 1040, time: 0.063, data: 0.001) D_A: 0.165 G_A: 0.422 cycle_A: 0.279 idt_A: 0.108 D_B: 0.208 G_B: 0.384 cycle_B: 0.314 idt_B: 0.111 \n",
      "End of epoch 177 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000455 -> 0.0000436\n",
      "(epoch: 178, iters: 80, time: 0.063, data: 0.002) D_A: 0.160 G_A: 0.350 cycle_A: 0.324 idt_A: 0.109 D_B: 0.210 G_B: 0.393 cycle_B: 0.328 idt_B: 0.113 \n",
      "(epoch: 178, iters: 280, time: 0.142, data: 0.002) D_A: 0.158 G_A: 0.435 cycle_A: 0.329 idt_A: 0.097 D_B: 0.164 G_B: 0.389 cycle_B: 0.309 idt_B: 0.097 \n",
      "(epoch: 178, iters: 480, time: 0.062, data: 0.002) D_A: 0.207 G_A: 0.273 cycle_A: 0.358 idt_A: 0.103 D_B: 0.157 G_B: 0.337 cycle_B: 0.293 idt_B: 0.128 \n",
      "(epoch: 178, iters: 680, time: 0.154, data: 0.002) D_A: 0.207 G_A: 0.286 cycle_A: 0.294 idt_A: 0.121 D_B: 0.188 G_B: 0.275 cycle_B: 0.297 idt_B: 0.093 \n",
      "(epoch: 178, iters: 880, time: 0.063, data: 0.001) D_A: 0.237 G_A: 0.358 cycle_A: 0.326 idt_A: 0.096 D_B: 0.221 G_B: 0.252 cycle_B: 0.328 idt_B: 0.118 \n",
      "(epoch: 178, iters: 1080, time: 0.063, data: 0.002) D_A: 0.182 G_A: 0.426 cycle_A: 0.312 idt_A: 0.106 D_B: 0.203 G_B: 0.321 cycle_B: 0.328 idt_B: 0.106 \n",
      "End of epoch 178 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000436 -> 0.0000416\n",
      "(epoch: 179, iters: 120, time: 0.062, data: 0.002) D_A: 0.181 G_A: 0.357 cycle_A: 0.352 idt_A: 0.105 D_B: 0.199 G_B: 0.375 cycle_B: 0.339 idt_B: 0.149 \n",
      "(epoch: 179, iters: 320, time: 0.143, data: 0.002) D_A: 0.210 G_A: 0.292 cycle_A: 0.335 idt_A: 0.116 D_B: 0.205 G_B: 0.330 cycle_B: 0.358 idt_B: 0.119 \n",
      "(epoch: 179, iters: 520, time: 0.063, data: 0.002) D_A: 0.210 G_A: 0.326 cycle_A: 0.312 idt_A: 0.097 D_B: 0.197 G_B: 0.346 cycle_B: 0.310 idt_B: 0.106 \n",
      "(epoch: 179, iters: 720, time: 0.063, data: 0.002) D_A: 0.202 G_A: 0.356 cycle_A: 0.320 idt_A: 0.130 D_B: 0.179 G_B: 0.463 cycle_B: 0.341 idt_B: 0.106 \n",
      "(epoch: 179, iters: 920, time: 0.063, data: 0.002) D_A: 0.155 G_A: 0.328 cycle_A: 0.336 idt_A: 0.107 D_B: 0.150 G_B: 0.300 cycle_B: 0.322 idt_B: 0.105 \n",
      "(epoch: 179, iters: 1120, time: 0.063, data: 0.002) D_A: 0.211 G_A: 0.390 cycle_A: 0.292 idt_A: 0.095 D_B: 0.202 G_B: 0.362 cycle_B: 0.334 idt_B: 0.093 \n",
      "End of epoch 179 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000416 -> 0.0000396\n",
      "(epoch: 180, iters: 160, time: 0.063, data: 0.001) D_A: 0.174 G_A: 0.361 cycle_A: 0.283 idt_A: 0.105 D_B: 0.204 G_B: 0.331 cycle_B: 0.319 idt_B: 0.092 \n",
      "(epoch: 180, iters: 360, time: 0.142, data: 0.002) D_A: 0.214 G_A: 0.326 cycle_A: 0.307 idt_A: 0.099 D_B: 0.195 G_B: 0.283 cycle_B: 0.329 idt_B: 0.119 \n",
      "(epoch: 180, iters: 560, time: 0.063, data: 0.002) D_A: 0.183 G_A: 0.451 cycle_A: 0.363 idt_A: 0.111 D_B: 0.200 G_B: 0.339 cycle_B: 0.339 idt_B: 0.126 \n",
      "(epoch: 180, iters: 760, time: 0.063, data: 0.002) D_A: 0.188 G_A: 0.347 cycle_A: 0.325 idt_A: 0.086 D_B: 0.181 G_B: 0.375 cycle_B: 0.282 idt_B: 0.114 \n",
      "(epoch: 180, iters: 960, time: 0.063, data: 0.001) D_A: 0.203 G_A: 0.524 cycle_A: 0.360 idt_A: 0.113 D_B: 0.194 G_B: 0.288 cycle_B: 0.338 idt_B: 0.102 \n",
      "(epoch: 180, iters: 1160, time: 0.063, data: 0.002) D_A: 0.175 G_A: 0.327 cycle_A: 0.315 idt_A: 0.120 D_B: 0.197 G_B: 0.338 cycle_B: 0.337 idt_B: 0.097 \n",
      "saving the model at the end of epoch 180, iters 208800\n",
      "End of epoch 180 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000396 -> 0.0000376\n",
      "(epoch: 181, iters: 200, time: 0.063, data: 0.082) D_A: 0.205 G_A: 0.390 cycle_A: 0.339 idt_A: 0.085 D_B: 0.180 G_B: 0.362 cycle_B: 0.276 idt_B: 0.105 \n",
      "(epoch: 181, iters: 400, time: 0.143, data: 0.002) D_A: 0.184 G_A: 0.430 cycle_A: 0.314 idt_A: 0.099 D_B: 0.241 G_B: 0.258 cycle_B: 0.338 idt_B: 0.096 \n",
      "(epoch: 181, iters: 600, time: 0.063, data: 0.002) D_A: 0.153 G_A: 0.411 cycle_A: 0.330 idt_A: 0.092 D_B: 0.230 G_B: 0.281 cycle_B: 0.298 idt_B: 0.109 \n",
      "(epoch: 181, iters: 800, time: 0.063, data: 0.001) D_A: 0.194 G_A: 0.298 cycle_A: 0.318 idt_A: 0.105 D_B: 0.218 G_B: 0.321 cycle_B: 0.326 idt_B: 0.106 \n",
      "(epoch: 181, iters: 1000, time: 0.063, data: 0.002) D_A: 0.228 G_A: 0.274 cycle_A: 0.308 idt_A: 0.095 D_B: 0.230 G_B: 0.298 cycle_B: 0.303 idt_B: 0.107 \n",
      "End of epoch 181 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000376 -> 0.0000356\n",
      "(epoch: 182, iters: 40, time: 0.142, data: 0.001) D_A: 0.146 G_A: 0.353 cycle_A: 0.298 idt_A: 0.111 D_B: 0.208 G_B: 0.278 cycle_B: 0.312 idt_B: 0.109 \n",
      "saving the latest model (epoch 182, total_iters 210000)\n",
      "(epoch: 182, iters: 240, time: 0.063, data: 0.002) D_A: 0.167 G_A: 0.394 cycle_A: 0.292 idt_A: 0.101 D_B: 0.195 G_B: 0.297 cycle_B: 0.304 idt_B: 0.095 \n",
      "(epoch: 182, iters: 440, time: 0.063, data: 0.002) D_A: 0.189 G_A: 0.314 cycle_A: 0.324 idt_A: 0.092 D_B: 0.189 G_B: 0.401 cycle_B: 0.318 idt_B: 0.119 \n",
      "(epoch: 182, iters: 640, time: 0.063, data: 0.002) D_A: 0.186 G_A: 0.328 cycle_A: 0.335 idt_A: 0.125 D_B: 0.191 G_B: 0.370 cycle_B: 0.348 idt_B: 0.109 \n",
      "(epoch: 182, iters: 840, time: 0.063, data: 0.001) D_A: 0.170 G_A: 0.336 cycle_A: 0.323 idt_A: 0.111 D_B: 0.184 G_B: 0.297 cycle_B: 0.306 idt_B: 0.102 \n",
      "(epoch: 182, iters: 1040, time: 0.063, data: 0.002) D_A: 0.225 G_A: 0.283 cycle_A: 0.297 idt_A: 0.111 D_B: 0.184 G_B: 0.322 cycle_B: 0.337 idt_B: 0.095 \n",
      "End of epoch 182 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000356 -> 0.0000337\n",
      "(epoch: 183, iters: 80, time: 0.141, data: 0.001) D_A: 0.162 G_A: 0.304 cycle_A: 0.316 idt_A: 0.129 D_B: 0.198 G_B: 0.400 cycle_B: 0.325 idt_B: 0.103 \n",
      "(epoch: 183, iters: 280, time: 0.063, data: 0.002) D_A: 0.160 G_A: 0.388 cycle_A: 0.295 idt_A: 0.092 D_B: 0.238 G_B: 0.330 cycle_B: 0.286 idt_B: 0.099 \n",
      "(epoch: 183, iters: 480, time: 0.063, data: 0.002) D_A: 0.186 G_A: 0.317 cycle_A: 0.304 idt_A: 0.115 D_B: 0.182 G_B: 0.376 cycle_B: 0.324 idt_B: 0.121 \n",
      "(epoch: 183, iters: 680, time: 0.063, data: 0.002) D_A: 0.218 G_A: 0.350 cycle_A: 0.297 idt_A: 0.100 D_B: 0.202 G_B: 0.282 cycle_B: 0.262 idt_B: 0.091 \n",
      "(epoch: 183, iters: 880, time: 0.154, data: 0.002) D_A: 0.143 G_A: 0.425 cycle_A: 0.345 idt_A: 0.102 D_B: 0.213 G_B: 0.265 cycle_B: 0.312 idt_B: 0.110 \n",
      "(epoch: 183, iters: 1080, time: 0.063, data: 0.001) D_A: 0.153 G_A: 0.422 cycle_A: 0.307 idt_A: 0.111 D_B: 0.215 G_B: 0.318 cycle_B: 0.316 idt_B: 0.103 \n",
      "End of epoch 183 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000337 -> 0.0000317\n",
      "(epoch: 184, iters: 120, time: 0.143, data: 0.002) D_A: 0.185 G_A: 0.314 cycle_A: 0.320 idt_A: 0.099 D_B: 0.197 G_B: 0.415 cycle_B: 0.316 idt_B: 0.091 \n",
      "(epoch: 184, iters: 320, time: 0.063, data: 0.002) D_A: 0.218 G_A: 0.311 cycle_A: 0.314 idt_A: 0.098 D_B: 0.203 G_B: 0.353 cycle_B: 0.306 idt_B: 0.121 \n",
      "(epoch: 184, iters: 520, time: 0.063, data: 0.002) D_A: 0.186 G_A: 0.478 cycle_A: 0.312 idt_A: 0.096 D_B: 0.165 G_B: 0.320 cycle_B: 0.308 idt_B: 0.101 \n",
      "(epoch: 184, iters: 720, time: 0.063, data: 0.002) D_A: 0.172 G_A: 0.301 cycle_A: 0.291 idt_A: 0.102 D_B: 0.201 G_B: 0.316 cycle_B: 0.321 idt_B: 0.098 \n",
      "(epoch: 184, iters: 920, time: 0.063, data: 0.002) D_A: 0.179 G_A: 0.397 cycle_A: 0.314 idt_A: 0.117 D_B: 0.187 G_B: 0.381 cycle_B: 0.300 idt_B: 0.119 \n",
      "(epoch: 184, iters: 1120, time: 0.063, data: 0.002) D_A: 0.159 G_A: 0.357 cycle_A: 0.287 idt_A: 0.092 D_B: 0.211 G_B: 0.260 cycle_B: 0.283 idt_B: 0.096 \n",
      "End of epoch 184 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000317 -> 0.0000297\n",
      "(epoch: 185, iters: 160, time: 0.143, data: 0.002) D_A: 0.191 G_A: 0.471 cycle_A: 0.286 idt_A: 0.101 D_B: 0.202 G_B: 0.331 cycle_B: 0.316 idt_B: 0.079 \n",
      "(epoch: 185, iters: 360, time: 0.062, data: 0.002) D_A: 0.173 G_A: 0.371 cycle_A: 0.292 idt_A: 0.099 D_B: 0.190 G_B: 0.345 cycle_B: 0.287 idt_B: 0.083 \n",
      "(epoch: 185, iters: 560, time: 0.143, data: 0.002) D_A: 0.180 G_A: 0.561 cycle_A: 0.314 idt_A: 0.114 D_B: 0.206 G_B: 0.279 cycle_B: 0.337 idt_B: 0.109 \n",
      "(epoch: 185, iters: 760, time: 0.062, data: 0.002) D_A: 0.169 G_A: 0.459 cycle_A: 0.314 idt_A: 0.088 D_B: 0.190 G_B: 0.258 cycle_B: 0.280 idt_B: 0.099 \n",
      "(epoch: 185, iters: 960, time: 0.063, data: 0.001) D_A: 0.173 G_A: 0.443 cycle_A: 0.330 idt_A: 0.112 D_B: 0.167 G_B: 0.361 cycle_B: 0.328 idt_B: 0.112 \n",
      "(epoch: 185, iters: 1160, time: 0.063, data: 0.001) D_A: 0.181 G_A: 0.351 cycle_A: 0.314 idt_A: 0.109 D_B: 0.173 G_B: 0.481 cycle_B: 0.329 idt_B: 0.115 \n",
      "saving the model at the end of epoch 185, iters 214600\n",
      "End of epoch 185 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000297 -> 0.0000277\n",
      "(epoch: 186, iters: 200, time: 0.146, data: 0.085) D_A: 0.176 G_A: 0.387 cycle_A: 0.345 idt_A: 0.107 D_B: 0.194 G_B: 0.395 cycle_B: 0.312 idt_B: 0.109 \n",
      "(epoch: 186, iters: 400, time: 0.063, data: 0.002) D_A: 0.210 G_A: 0.321 cycle_A: 0.301 idt_A: 0.093 D_B: 0.166 G_B: 0.459 cycle_B: 0.293 idt_B: 0.088 \n",
      "saving the latest model (epoch 186, total_iters 215000)\n",
      "(epoch: 186, iters: 600, time: 0.063, data: 0.001) D_A: 0.193 G_A: 0.403 cycle_A: 0.314 idt_A: 0.096 D_B: 0.200 G_B: 0.314 cycle_B: 0.328 idt_B: 0.108 \n",
      "(epoch: 186, iters: 800, time: 0.063, data: 0.002) D_A: 0.176 G_A: 0.326 cycle_A: 0.285 idt_A: 0.110 D_B: 0.163 G_B: 0.330 cycle_B: 0.298 idt_B: 0.093 \n",
      "(epoch: 186, iters: 1000, time: 0.063, data: 0.002) D_A: 0.199 G_A: 0.339 cycle_A: 0.300 idt_A: 0.091 D_B: 0.230 G_B: 0.306 cycle_B: 0.292 idt_B: 0.105 \n",
      "End of epoch 186 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000277 -> 0.0000257\n",
      "(epoch: 187, iters: 40, time: 0.063, data: 0.002) D_A: 0.186 G_A: 0.422 cycle_A: 0.322 idt_A: 0.083 D_B: 0.186 G_B: 0.327 cycle_B: 0.305 idt_B: 0.104 \n",
      "(epoch: 187, iters: 240, time: 0.144, data: 0.002) D_A: 0.194 G_A: 0.358 cycle_A: 0.288 idt_A: 0.127 D_B: 0.213 G_B: 0.311 cycle_B: 0.326 idt_B: 0.101 \n",
      "(epoch: 187, iters: 440, time: 0.063, data: 0.002) D_A: 0.162 G_A: 0.344 cycle_A: 0.319 idt_A: 0.101 D_B: 0.207 G_B: 0.326 cycle_B: 0.299 idt_B: 0.102 \n",
      "(epoch: 187, iters: 640, time: 0.063, data: 0.002) D_A: 0.187 G_A: 0.438 cycle_A: 0.324 idt_A: 0.106 D_B: 0.185 G_B: 0.374 cycle_B: 0.304 idt_B: 0.116 \n",
      "(epoch: 187, iters: 840, time: 0.063, data: 0.001) D_A: 0.192 G_A: 0.342 cycle_A: 0.298 idt_A: 0.133 D_B: 0.200 G_B: 0.352 cycle_B: 0.346 idt_B: 0.100 \n",
      "(epoch: 187, iters: 1040, time: 0.063, data: 0.002) D_A: 0.158 G_A: 0.438 cycle_A: 0.281 idt_A: 0.097 D_B: 0.203 G_B: 0.390 cycle_B: 0.290 idt_B: 0.097 \n",
      "End of epoch 187 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000257 -> 0.0000238\n",
      "(epoch: 188, iters: 80, time: 0.063, data: 0.001) D_A: 0.167 G_A: 0.442 cycle_A: 0.304 idt_A: 0.102 D_B: 0.217 G_B: 0.324 cycle_B: 0.302 idt_B: 0.098 \n",
      "(epoch: 188, iters: 280, time: 0.157, data: 0.002) D_A: 0.176 G_A: 0.349 cycle_A: 0.310 idt_A: 0.091 D_B: 0.176 G_B: 0.312 cycle_B: 0.296 idt_B: 0.096 \n",
      "(epoch: 188, iters: 480, time: 0.063, data: 0.001) D_A: 0.181 G_A: 0.434 cycle_A: 0.337 idt_A: 0.092 D_B: 0.202 G_B: 0.332 cycle_B: 0.292 idt_B: 0.104 \n",
      "(epoch: 188, iters: 680, time: 0.063, data: 0.002) D_A: 0.225 G_A: 0.375 cycle_A: 0.300 idt_A: 0.134 D_B: 0.215 G_B: 0.332 cycle_B: 0.329 idt_B: 0.098 \n",
      "(epoch: 188, iters: 880, time: 0.063, data: 0.002) D_A: 0.221 G_A: 0.296 cycle_A: 0.301 idt_A: 0.093 D_B: 0.197 G_B: 0.354 cycle_B: 0.292 idt_B: 0.107 \n",
      "(epoch: 188, iters: 1080, time: 0.142, data: 0.002) D_A: 0.213 G_A: 0.434 cycle_A: 0.309 idt_A: 0.090 D_B: 0.178 G_B: 0.360 cycle_B: 0.275 idt_B: 0.099 \n",
      "End of epoch 188 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000238 -> 0.0000218\n",
      "(epoch: 189, iters: 120, time: 0.063, data: 0.002) D_A: 0.138 G_A: 0.500 cycle_A: 0.296 idt_A: 0.093 D_B: 0.177 G_B: 0.347 cycle_B: 0.305 idt_B: 0.097 \n",
      "(epoch: 189, iters: 320, time: 0.144, data: 0.002) D_A: 0.156 G_A: 0.459 cycle_A: 0.271 idt_A: 0.104 D_B: 0.184 G_B: 0.328 cycle_B: 0.286 idt_B: 0.086 \n",
      "(epoch: 189, iters: 520, time: 0.063, data: 0.002) D_A: 0.198 G_A: 0.372 cycle_A: 0.311 idt_A: 0.095 D_B: 0.200 G_B: 0.308 cycle_B: 0.300 idt_B: 0.102 \n",
      "(epoch: 189, iters: 720, time: 0.063, data: 0.002) D_A: 0.158 G_A: 0.337 cycle_A: 0.280 idt_A: 0.092 D_B: 0.226 G_B: 0.360 cycle_B: 0.308 idt_B: 0.087 \n",
      "(epoch: 189, iters: 920, time: 0.063, data: 0.002) D_A: 0.167 G_A: 0.315 cycle_A: 0.285 idt_A: 0.120 D_B: 0.226 G_B: 0.351 cycle_B: 0.344 idt_B: 0.098 \n",
      "(epoch: 189, iters: 1120, time: 0.063, data: 0.001) D_A: 0.167 G_A: 0.326 cycle_A: 0.256 idt_A: 0.107 D_B: 0.189 G_B: 0.351 cycle_B: 0.304 idt_B: 0.087 \n",
      "End of epoch 189 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000218 -> 0.0000198\n",
      "(epoch: 190, iters: 160, time: 0.063, data: 0.001) D_A: 0.197 G_A: 0.459 cycle_A: 0.296 idt_A: 0.100 D_B: 0.206 G_B: 0.391 cycle_B: 0.306 idt_B: 0.092 \n",
      "(epoch: 190, iters: 360, time: 0.144, data: 0.002) D_A: 0.196 G_A: 0.336 cycle_A: 0.300 idt_A: 0.084 D_B: 0.182 G_B: 0.342 cycle_B: 0.265 idt_B: 0.112 \n",
      "(epoch: 190, iters: 560, time: 0.063, data: 0.002) D_A: 0.168 G_A: 0.391 cycle_A: 0.296 idt_A: 0.098 D_B: 0.199 G_B: 0.340 cycle_B: 0.295 idt_B: 0.104 \n",
      "(epoch: 190, iters: 760, time: 0.143, data: 0.002) D_A: 0.177 G_A: 0.378 cycle_A: 0.292 idt_A: 0.089 D_B: 0.197 G_B: 0.360 cycle_B: 0.282 idt_B: 0.091 \n",
      "saving the latest model (epoch 190, total_iters 220000)\n",
      "(epoch: 190, iters: 960, time: 0.063, data: 0.001) D_A: 0.173 G_A: 0.300 cycle_A: 0.284 idt_A: 0.105 D_B: 0.182 G_B: 0.364 cycle_B: 0.300 idt_B: 0.091 \n",
      "(epoch: 190, iters: 1160, time: 0.063, data: 0.002) D_A: 0.192 G_A: 0.415 cycle_A: 0.292 idt_A: 0.092 D_B: 0.180 G_B: 0.374 cycle_B: 0.281 idt_B: 0.125 \n",
      "saving the model at the end of epoch 190, iters 220400\n",
      "End of epoch 190 / 200 \t Time Taken: 64 sec\n",
      "learning rate 0.0000198 -> 0.0000178\n",
      "(epoch: 191, iters: 200, time: 0.063, data: 0.081) D_A: 0.203 G_A: 0.335 cycle_A: 0.284 idt_A: 0.095 D_B: 0.222 G_B: 0.341 cycle_B: 0.284 idt_B: 0.091 \n",
      "(epoch: 191, iters: 400, time: 0.144, data: 0.002) D_A: 0.147 G_A: 0.478 cycle_A: 0.293 idt_A: 0.100 D_B: 0.184 G_B: 0.374 cycle_B: 0.307 idt_B: 0.089 \n",
      "(epoch: 191, iters: 600, time: 0.063, data: 0.001) D_A: 0.168 G_A: 0.379 cycle_A: 0.280 idt_A: 0.089 D_B: 0.245 G_B: 0.381 cycle_B: 0.279 idt_B: 0.089 \n",
      "(epoch: 191, iters: 800, time: 0.063, data: 0.001) D_A: 0.246 G_A: 0.321 cycle_A: 0.307 idt_A: 0.116 D_B: 0.235 G_B: 0.328 cycle_B: 0.318 idt_B: 0.106 \n",
      "(epoch: 191, iters: 1000, time: 0.063, data: 0.002) D_A: 0.163 G_A: 0.400 cycle_A: 0.287 idt_A: 0.084 D_B: 0.188 G_B: 0.414 cycle_B: 0.280 idt_B: 0.101 \n",
      "End of epoch 191 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000178 -> 0.0000158\n",
      "(epoch: 192, iters: 40, time: 0.158, data: 0.001) D_A: 0.177 G_A: 0.454 cycle_A: 0.299 idt_A: 0.101 D_B: 0.189 G_B: 0.340 cycle_B: 0.298 idt_B: 0.084 \n",
      "(epoch: 192, iters: 240, time: 0.063, data: 0.001) D_A: 0.226 G_A: 0.294 cycle_A: 0.329 idt_A: 0.089 D_B: 0.210 G_B: 0.332 cycle_B: 0.282 idt_B: 0.100 \n",
      "(epoch: 192, iters: 440, time: 0.143, data: 0.001) D_A: 0.148 G_A: 0.417 cycle_A: 0.306 idt_A: 0.119 D_B: 0.195 G_B: 0.407 cycle_B: 0.335 idt_B: 0.094 \n",
      "(epoch: 192, iters: 640, time: 0.063, data: 0.002) D_A: 0.140 G_A: 0.350 cycle_A: 0.297 idt_A: 0.115 D_B: 0.185 G_B: 0.375 cycle_B: 0.332 idt_B: 0.099 \n",
      "(epoch: 192, iters: 840, time: 0.063, data: 0.002) D_A: 0.152 G_A: 0.364 cycle_A: 0.303 idt_A: 0.130 D_B: 0.194 G_B: 0.359 cycle_B: 0.325 idt_B: 0.092 \n",
      "(epoch: 192, iters: 1040, time: 0.063, data: 0.002) D_A: 0.168 G_A: 0.352 cycle_A: 0.271 idt_A: 0.111 D_B: 0.193 G_B: 0.358 cycle_B: 0.297 idt_B: 0.090 \n",
      "End of epoch 192 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000158 -> 0.0000139\n",
      "(epoch: 193, iters: 80, time: 0.146, data: 0.002) D_A: 0.159 G_A: 0.406 cycle_A: 0.260 idt_A: 0.113 D_B: 0.194 G_B: 0.376 cycle_B: 0.319 idt_B: 0.081 \n",
      "(epoch: 193, iters: 280, time: 0.063, data: 0.001) D_A: 0.171 G_A: 0.360 cycle_A: 0.274 idt_A: 0.154 D_B: 0.223 G_B: 0.365 cycle_B: 0.390 idt_B: 0.095 \n",
      "(epoch: 193, iters: 480, time: 0.063, data: 0.002) D_A: 0.180 G_A: 0.409 cycle_A: 0.318 idt_A: 0.111 D_B: 0.166 G_B: 0.376 cycle_B: 0.329 idt_B: 0.125 \n",
      "(epoch: 193, iters: 680, time: 0.063, data: 0.002) D_A: 0.151 G_A: 0.487 cycle_A: 0.325 idt_A: 0.097 D_B: 0.171 G_B: 0.391 cycle_B: 0.288 idt_B: 0.109 \n",
      "(epoch: 193, iters: 880, time: 0.063, data: 0.002) D_A: 0.200 G_A: 0.349 cycle_A: 0.295 idt_A: 0.108 D_B: 0.199 G_B: 0.301 cycle_B: 0.294 idt_B: 0.094 \n",
      "(epoch: 193, iters: 1080, time: 0.063, data: 0.002) D_A: 0.171 G_A: 0.349 cycle_A: 0.287 idt_A: 0.113 D_B: 0.184 G_B: 0.397 cycle_B: 0.307 idt_B: 0.092 \n",
      "End of epoch 193 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000139 -> 0.0000119\n",
      "(epoch: 194, iters: 120, time: 0.146, data: 0.002) D_A: 0.194 G_A: 0.335 cycle_A: 0.296 idt_A: 0.105 D_B: 0.184 G_B: 0.346 cycle_B: 0.309 idt_B: 0.100 \n",
      "(epoch: 194, iters: 320, time: 0.063, data: 0.002) D_A: 0.185 G_A: 0.398 cycle_A: 0.309 idt_A: 0.102 D_B: 0.217 G_B: 0.322 cycle_B: 0.293 idt_B: 0.105 \n",
      "(epoch: 194, iters: 520, time: 0.063, data: 0.002) D_A: 0.201 G_A: 0.330 cycle_A: 0.295 idt_A: 0.084 D_B: 0.196 G_B: 0.297 cycle_B: 0.273 idt_B: 0.089 \n",
      "(epoch: 194, iters: 720, time: 0.063, data: 0.003) D_A: 0.159 G_A: 0.464 cycle_A: 0.275 idt_A: 0.081 D_B: 0.194 G_B: 0.346 cycle_B: 0.265 idt_B: 0.102 \n",
      "(epoch: 194, iters: 920, time: 0.063, data: 0.001) D_A: 0.151 G_A: 0.449 cycle_A: 0.303 idt_A: 0.092 D_B: 0.194 G_B: 0.320 cycle_B: 0.293 idt_B: 0.093 \n",
      "(epoch: 194, iters: 1120, time: 0.063, data: 0.002) D_A: 0.239 G_A: 0.323 cycle_A: 0.285 idt_A: 0.089 D_B: 0.220 G_B: 0.361 cycle_B: 0.283 idt_B: 0.093 \n",
      "saving the latest model (epoch 194, total_iters 225000)\n",
      "End of epoch 194 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000119 -> 0.0000099\n",
      "(epoch: 195, iters: 160, time: 0.145, data: 0.002) D_A: 0.180 G_A: 0.317 cycle_A: 0.284 idt_A: 0.090 D_B: 0.185 G_B: 0.373 cycle_B: 0.294 idt_B: 0.092 \n",
      "(epoch: 195, iters: 360, time: 0.063, data: 0.002) D_A: 0.169 G_A: 0.370 cycle_A: 0.295 idt_A: 0.110 D_B: 0.204 G_B: 0.335 cycle_B: 0.323 idt_B: 0.091 \n",
      "(epoch: 195, iters: 560, time: 0.063, data: 0.002) D_A: 0.182 G_A: 0.402 cycle_A: 0.316 idt_A: 0.077 D_B: 0.185 G_B: 0.371 cycle_B: 0.271 idt_B: 0.099 \n",
      "(epoch: 195, iters: 760, time: 0.063, data: 0.002) D_A: 0.177 G_A: 0.403 cycle_A: 0.311 idt_A: 0.105 D_B: 0.210 G_B: 0.380 cycle_B: 0.290 idt_B: 0.109 \n",
      "(epoch: 195, iters: 960, time: 0.158, data: 0.002) D_A: 0.198 G_A: 0.465 cycle_A: 0.277 idt_A: 0.126 D_B: 0.200 G_B: 0.427 cycle_B: 0.331 idt_B: 0.087 \n",
      "(epoch: 195, iters: 1160, time: 0.063, data: 0.001) D_A: 0.189 G_A: 0.444 cycle_A: 0.296 idt_A: 0.093 D_B: 0.220 G_B: 0.364 cycle_B: 0.286 idt_B: 0.095 \n",
      "saving the model at the end of epoch 195, iters 226200\n",
      "End of epoch 195 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000099 -> 0.0000079\n",
      "(epoch: 196, iters: 200, time: 0.146, data: 0.100) D_A: 0.176 G_A: 0.395 cycle_A: 0.275 idt_A: 0.100 D_B: 0.166 G_B: 0.444 cycle_B: 0.292 idt_B: 0.088 \n",
      "(epoch: 196, iters: 400, time: 0.063, data: 0.002) D_A: 0.176 G_A: 0.357 cycle_A: 0.243 idt_A: 0.091 D_B: 0.247 G_B: 0.339 cycle_B: 0.291 idt_B: 0.088 \n",
      "(epoch: 196, iters: 600, time: 0.062, data: 0.002) D_A: 0.151 G_A: 0.481 cycle_A: 0.286 idt_A: 0.113 D_B: 0.208 G_B: 0.321 cycle_B: 0.301 idt_B: 0.092 \n",
      "(epoch: 196, iters: 800, time: 0.063, data: 0.002) D_A: 0.170 G_A: 0.404 cycle_A: 0.296 idt_A: 0.092 D_B: 0.203 G_B: 0.362 cycle_B: 0.277 idt_B: 0.105 \n",
      "(epoch: 196, iters: 1000, time: 0.063, data: 0.001) D_A: 0.162 G_A: 0.441 cycle_A: 0.305 idt_A: 0.094 D_B: 0.170 G_B: 0.341 cycle_B: 0.278 idt_B: 0.094 \n",
      "End of epoch 196 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000079 -> 0.0000059\n",
      "(epoch: 197, iters: 40, time: 0.063, data: 0.002) D_A: 0.169 G_A: 0.489 cycle_A: 0.306 idt_A: 0.109 D_B: 0.182 G_B: 0.385 cycle_B: 0.286 idt_B: 0.092 \n",
      "(epoch: 197, iters: 240, time: 0.147, data: 0.001) D_A: 0.169 G_A: 0.446 cycle_A: 0.299 idt_A: 0.103 D_B: 0.208 G_B: 0.358 cycle_B: 0.301 idt_B: 0.098 \n",
      "(epoch: 197, iters: 440, time: 0.063, data: 0.002) D_A: 0.197 G_A: 0.394 cycle_A: 0.288 idt_A: 0.131 D_B: 0.197 G_B: 0.379 cycle_B: 0.328 idt_B: 0.092 \n",
      "(epoch: 197, iters: 640, time: 0.146, data: 0.002) D_A: 0.173 G_A: 0.443 cycle_A: 0.253 idt_A: 0.083 D_B: 0.170 G_B: 0.357 cycle_B: 0.259 idt_B: 0.087 \n",
      "(epoch: 197, iters: 840, time: 0.063, data: 0.002) D_A: 0.171 G_A: 0.420 cycle_A: 0.323 idt_A: 0.096 D_B: 0.164 G_B: 0.347 cycle_B: 0.283 idt_B: 0.098 \n",
      "(epoch: 197, iters: 1040, time: 0.063, data: 0.001) D_A: 0.214 G_A: 0.315 cycle_A: 0.290 idt_A: 0.107 D_B: 0.202 G_B: 0.378 cycle_B: 0.293 idt_B: 0.093 \n",
      "End of epoch 197 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0000059 -> 0.0000040\n",
      "(epoch: 198, iters: 80, time: 0.063, data: 0.002) D_A: 0.181 G_A: 0.325 cycle_A: 0.274 idt_A: 0.074 D_B: 0.223 G_B: 0.354 cycle_B: 0.252 idt_B: 0.089 \n",
      "(epoch: 198, iters: 280, time: 0.145, data: 0.001) D_A: 0.212 G_A: 0.380 cycle_A: 0.258 idt_A: 0.101 D_B: 0.192 G_B: 0.316 cycle_B: 0.278 idt_B: 0.084 \n",
      "(epoch: 198, iters: 480, time: 0.063, data: 0.002) D_A: 0.163 G_A: 0.461 cycle_A: 0.321 idt_A: 0.079 D_B: 0.184 G_B: 0.355 cycle_B: 0.279 idt_B: 0.104 \n",
      "(epoch: 198, iters: 680, time: 0.063, data: 0.001) D_A: 0.195 G_A: 0.423 cycle_A: 0.322 idt_A: 0.098 D_B: 0.245 G_B: 0.359 cycle_B: 0.283 idt_B: 0.096 \n",
      "(epoch: 198, iters: 880, time: 0.063, data: 0.002) D_A: 0.196 G_A: 0.458 cycle_A: 0.304 idt_A: 0.086 D_B: 0.198 G_B: 0.320 cycle_B: 0.279 idt_B: 0.093 \n",
      "(epoch: 198, iters: 1080, time: 0.063, data: 0.002) D_A: 0.167 G_A: 0.455 cycle_A: 0.293 idt_A: 0.109 D_B: 0.190 G_B: 0.346 cycle_B: 0.305 idt_B: 0.106 \n",
      "End of epoch 198 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000040 -> 0.0000020\n",
      "(epoch: 199, iters: 120, time: 0.063, data: 0.001) D_A: 0.184 G_A: 0.412 cycle_A: 0.290 idt_A: 0.086 D_B: 0.219 G_B: 0.318 cycle_B: 0.275 idt_B: 0.085 \n",
      "(epoch: 199, iters: 320, time: 0.145, data: 0.002) D_A: 0.191 G_A: 0.406 cycle_A: 0.311 idt_A: 0.109 D_B: 0.206 G_B: 0.352 cycle_B: 0.302 idt_B: 0.105 \n",
      "saving the latest model (epoch 199, total_iters 230000)\n",
      "(epoch: 199, iters: 520, time: 0.063, data: 0.001) D_A: 0.156 G_A: 0.432 cycle_A: 0.273 idt_A: 0.088 D_B: 0.210 G_B: 0.358 cycle_B: 0.288 idt_B: 0.089 \n",
      "(epoch: 199, iters: 720, time: 0.063, data: 0.002) D_A: 0.156 G_A: 0.379 cycle_A: 0.286 idt_A: 0.082 D_B: 0.194 G_B: 0.364 cycle_B: 0.270 idt_B: 0.093 \n",
      "(epoch: 199, iters: 920, time: 0.063, data: 0.002) D_A: 0.156 G_A: 0.424 cycle_A: 0.279 idt_A: 0.094 D_B: 0.198 G_B: 0.361 cycle_B: 0.306 idt_B: 0.087 \n",
      "(epoch: 199, iters: 1120, time: 0.063, data: 0.002) D_A: 0.181 G_A: 0.400 cycle_A: 0.287 idt_A: 0.098 D_B: 0.199 G_B: 0.372 cycle_B: 0.283 idt_B: 0.099 \n",
      "End of epoch 199 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000020 -> 0.0000000\n",
      "(epoch: 200, iters: 160, time: 0.063, data: 0.002) D_A: 0.229 G_A: 0.381 cycle_A: 0.309 idt_A: 0.114 D_B: 0.178 G_B: 0.383 cycle_B: 0.320 idt_B: 0.090 \n",
      "(epoch: 200, iters: 360, time: 0.162, data: 0.002) D_A: 0.220 G_A: 0.370 cycle_A: 0.303 idt_A: 0.072 D_B: 0.218 G_B: 0.373 cycle_B: 0.245 idt_B: 0.098 \n",
      "(epoch: 200, iters: 560, time: 0.063, data: 0.001) D_A: 0.187 G_A: 0.418 cycle_A: 0.286 idt_A: 0.126 D_B: 0.199 G_B: 0.386 cycle_B: 0.301 idt_B: 0.092 \n",
      "(epoch: 200, iters: 760, time: 0.063, data: 0.002) D_A: 0.195 G_A: 0.382 cycle_A: 0.308 idt_A: 0.097 D_B: 0.179 G_B: 0.342 cycle_B: 0.288 idt_B: 0.098 \n",
      "(epoch: 200, iters: 960, time: 0.063, data: 0.002) D_A: 0.183 G_A: 0.387 cycle_A: 0.310 idt_A: 0.090 D_B: 0.181 G_B: 0.411 cycle_B: 0.299 idt_B: 0.097 \n",
      "(epoch: 200, iters: 1160, time: 0.145, data: 0.002) D_A: 0.195 G_A: 0.399 cycle_A: 0.296 idt_A: 0.130 D_B: 0.186 G_B: 0.428 cycle_B: 0.343 idt_B: 0.113 \n",
      "saving the model at the end of epoch 200, iters 232000\n",
      "End of epoch 200 / 200 \t Time Taken: 63 sec\n"
     ]
    }
   ],
   "source": [
    "# !python train.py --dataroot ./datasets/students --name horse2zebra --model cycle_gan --gpu_ids 1 --batch_size 8 --display_id -1\n",
    "!python train.py --dataroot ./datasets/students --name students_cycle_gan --model cycle_gan --gpu_ids 1 --batch_size 8 --display_id -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout`\n",
    "\n",
    "Change the `--dataroot` and `--name` to be consistent with your trained model's configuration.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory.\n",
    "\n",
    "> For your own experiments, you might want to specify --netG, --norm, --no_dropout to match the generator architecture of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/students           \t[default: None]\n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 1                             \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: students_cycle_gan            \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [UnalignedDataset] was created\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n",
      "loading the model from ./checkpoints/students_cycle_gan/latest_net_G_A.pth\n",
      "loading the model from ./checkpoints/students_cycle_gan/latest_net_G_B.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G_A] Total number of parameters : 11.378 M\n",
      "[Network G_B] Total number of parameters : 11.378 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/students_cycle_gan/test_latest\n",
      "processing (0000)-th image... ['./datasets/students/testA/person_10_person_10_low_11.jpg']\n",
      "processing (0005)-th image... ['./datasets/students/testA/person_10_person_10_low_18.jpg']\n",
      "processing (0010)-th image... ['./datasets/students/testA/person_11_person_11_low_10.jpg']\n",
      "processing (0015)-th image... ['./datasets/students/testA/person_11_person_11_low_47.jpg']\n",
      "processing (0020)-th image... ['./datasets/students/testA/person_12_person_12_low_18.jpg']\n",
      "processing (0025)-th image... ['./datasets/students/testA/person_12_person_12_low_50.jpg']\n",
      "processing (0030)-th image... ['./datasets/students/testA/person_13_person_13_low_10.jpg']\n",
      "processing (0035)-th image... ['./datasets/students/testA/person_13_person_13_low_36.jpg']\n",
      "processing (0040)-th image... ['./datasets/students/testA/person_1_person_1_low_10.jpg']\n",
      "processing (0045)-th image... ['./datasets/students/testA/person_1_person_1_low_30.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot ./datasets/students --name students_cycle_gan --model cycle_gan --no_dropout --gpu_ids 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_fake.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_real.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CycleGAN",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "cycleGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
